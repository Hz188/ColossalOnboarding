[2024-05-07 08:06:17,099] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-05-07 08:06:17,100] torch.distributed.run: [WARNING] 
[2024-05-07 08:06:17,100] torch.distributed.run: [WARNING] *****************************************
[2024-05-07 08:06:17,100] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-07 08:06:17,100] torch.distributed.run: [WARNING] *****************************************
====================initialize the distributed env====================
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.93s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:33<00:33, 33.10s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:33<00:33, 33.29s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:35<00:35, 35.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 20.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.52s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 20.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.52s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 21.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.64s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:47<00:00, 21.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:47<00:00, 23.91s/it]
====================get the model with lora====================
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
====================Use auto mixed precision training====================
====================Use distributed data parallel====================
====================get the dataset====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
====================get the dataloader====================
====================start train====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Step: 1	 Data: torch.Size([10, 384])	 Training Loss: 1.0071955919265747
Step: 2	 Data: torch.Size([10, 384])	 Training Loss: 1.045760989189148
Step: 3	 Data: torch.Size([10, 384])	 Training Loss: 1.1253570318222046
Step: 4	 Data: torch.Size([10, 384])	 Training Loss: 1.0781497955322266
Step: 5	 Data: torch.Size([10, 384])	 Training Loss: 1.0078004598617554
Step: 6	 Data: torch.Size([10, 384])	 Training Loss: 1.1446142196655273
Step: 7	 Data: torch.Size([10, 384])	 Training Loss: 1.0277587175369263
Step: 8	 Data: torch.Size([10, 384])	 Training Loss: 1.2210657596588135
Step: 9	 Data: torch.Size([10, 384])	 Training Loss: 1.082646369934082
Step: 10	 Data: torch.Size([10, 384])	 Training Loss: 1.086905837059021
Step: 11	 Data: torch.Size([10, 384])	 Training Loss: 1.013844609260559
Step: 12	 Data: torch.Size([10, 384])	 Training Loss: 1.0503935813903809
Step: 13	 Data: torch.Size([10, 384])	 Training Loss: 1.0890862941741943
Step: 14	 Data: torch.Size([10, 384])	 Training Loss: 1.2323522567749023
Step: 15	 Data: torch.Size([10, 384])	 Training Loss: 1.0377390384674072
Step: 16	 Data: torch.Size([10, 384])	 Training Loss: 1.1246185302734375
Step: 17	 Data: torch.Size([10, 384])	 Training Loss: 1.1545791625976562
Step: 18	 Data: torch.Size([10, 384])	 Training Loss: 1.0535247325897217
Step: 19	 Data: torch.Size([10, 384])	 Training Loss: 1.2129892110824585
Step: 20	 Data: torch.Size([10, 384])	 Training Loss: 1.0159326791763306
Step: 21	 Data: torch.Size([10, 384])	 Training Loss: 1.0224390029907227
Step: 22	 Data: torch.Size([10, 384])	 Training Loss: 1.0416233539581299
Step: 23	 Data: torch.Size([10, 384])	 Training Loss: 1.1336780786514282
Step: 24	 Data: torch.Size([10, 384])	 Training Loss: 1.1639617681503296
Step: 25	 Data: torch.Size([10, 384])	 Training Loss: 0.9760693311691284
Step: 26	 Data: torch.Size([10, 384])	 Training Loss: 0.9518563747406006
Step: 27	 Data: torch.Size([10, 384])	 Training Loss: 1.2121018171310425
Step: 28	 Data: torch.Size([10, 384])	 Training Loss: 1.1049866676330566
Step: 29	 Data: torch.Size([10, 384])	 Training Loss: 1.1101783514022827
Step: 30	 Data: torch.Size([10, 384])	 Training Loss: 0.9708536267280579
Step: 31	 Data: torch.Size([10, 384])	 Training Loss: 1.1117802858352661
Step: 32	 Data: torch.Size([10, 384])	 Training Loss: 1.1106021404266357
Step: 33	 Data: torch.Size([10, 384])	 Training Loss: 1.015649437904358
Step: 34	 Data: torch.Size([10, 384])	 Training Loss: 0.8904293179512024
Step: 35	 Data: torch.Size([10, 384])	 Training Loss: 1.020521879196167
Step: 36	 Data: torch.Size([10, 384])	 Training Loss: 1.0476669073104858
Step: 37	 Data: torch.Size([10, 384])	 Training Loss: 1.0963929891586304
Step: 38	 Data: torch.Size([10, 384])	 Training Loss: 0.9482670426368713
Step: 39	 Data: torch.Size([10, 384])	 Training Loss: 0.994999349117279
Step: 40	 Data: torch.Size([10, 384])	 Training Loss: 1.0212112665176392
Step: 41	 Data: torch.Size([10, 384])	 Training Loss: 1.1540688276290894
Step: 42	 Data: torch.Size([10, 384])	 Training Loss: 0.9949543476104736
Step: 43	 Data: torch.Size([10, 384])	 Training Loss: 1.0802520513534546
Step: 44	 Data: torch.Size([10, 384])	 Training Loss: 1.230650544166565
Step: 45	 Data: torch.Size([10, 384])	 Training Loss: 1.0816453695297241
Step: 46	 Data: torch.Size([10, 384])	 Training Loss: 0.960970401763916
Step: 47	 Data: torch.Size([10, 384])	 Training Loss: 0.9648337364196777
Step: 48	 Data: torch.Size([10, 384])	 Training Loss: 1.190568447113037
Step: 49	 Data: torch.Size([10, 384])	 Training Loss: 1.1341171264648438
Step: 50	 Data: torch.Size([10, 384])	 Training Loss: 1.1856563091278076
Step: 51	 Data: torch.Size([10, 384])	 Training Loss: 0.9987735748291016
Step: 52	 Data: torch.Size([10, 384])	 Training Loss: 1.004456639289856
Step: 53	 Data: torch.Size([10, 384])	 Training Loss: 1.0796033143997192
Step: 54	 Data: torch.Size([10, 384])	 Training Loss: 1.0605467557907104
Step: 55	 Data: torch.Size([10, 384])	 Training Loss: 0.9641479253768921
Step: 56	 Data: torch.Size([10, 384])	 Training Loss: 1.1024497747421265
Step: 57	 Data: torch.Size([10, 384])	 Training Loss: 0.9596728086471558
Step: 58	 Data: torch.Size([10, 384])	 Training Loss: 0.8873233199119568
Step: 59	 Data: torch.Size([10, 384])	 Training Loss: 1.1134116649627686
Step: 60	 Data: torch.Size([10, 384])	 Training Loss: 1.1052736043930054
Step: 61	 Data: torch.Size([10, 384])	 Training Loss: 0.9399327039718628
Step: 62	 Data: torch.Size([10, 384])	 Training Loss: 1.1760504245758057
Step: 63	 Data: torch.Size([10, 384])	 Training Loss: 1.0578950643539429
Step: 64	 Data: torch.Size([10, 384])	 Training Loss: 0.9921804666519165
Step: 65	 Data: torch.Size([10, 384])	 Training Loss: 0.9803370237350464
Step: 66	 Data: torch.Size([10, 384])	 Training Loss: 1.007163643836975
Step: 67	 Data: torch.Size([10, 384])	 Training Loss: 1.0118759870529175
Step: 68	 Data: torch.Size([10, 384])	 Training Loss: 1.1454815864562988
Step: 69	 Data: torch.Size([10, 384])	 Training Loss: 1.1703879833221436
Step: 70	 Data: torch.Size([10, 384])	 Training Loss: 0.9279459118843079
Step: 71	 Data: torch.Size([10, 384])	 Training Loss: 0.9442636370658875
Step: 72	 Data: torch.Size([10, 350])	 Training Loss: 1.4264986515045166
Step: 73	 Data: torch.Size([10, 384])	 Training Loss: 0.9277794361114502
Step: 74	 Data: torch.Size([10, 384])	 Training Loss: 1.0652480125427246
Step: 75	 Data: torch.Size([10, 384])	 Training Loss: 0.9765066504478455
Step: 76	 Data: torch.Size([10, 384])	 Training Loss: 0.861038088798523
Step: 77	 Data: torch.Size([10, 384])	 Training Loss: 1.1095423698425293
Step: 78	 Data: torch.Size([10, 384])	 Training Loss: 1.0210843086242676
Step: 79	 Data: torch.Size([10, 384])	 Training Loss: 1.2303663492202759
Step: 80	 Data: torch.Size([10, 384])	 Training Loss: 1.0594778060913086
Step: 81	 Data: torch.Size([10, 384])	 Training Loss: 1.031229853630066
Step: 82	 Data: torch.Size([10, 384])	 Training Loss: 1.0633667707443237
Step: 83	 Data: torch.Size([10, 384])	 Training Loss: 1.0380322933197021
Step: 84	 Data: torch.Size([10, 384])	 Training Loss: 0.861550509929657
Step: 85	 Data: torch.Size([10, 384])	 Training Loss: 0.9634339809417725
Step: 86	 Data: torch.Size([10, 384])	 Training Loss: 1.1007153987884521
Step: 87	 Data: torch.Size([10, 384])	 Training Loss: 1.0220284461975098
Step: 88	 Data: torch.Size([10, 384])	 Training Loss: 0.8788577914237976
Step: 89	 Data: torch.Size([10, 384])	 Training Loss: 1.07548987865448
Step: 90	 Data: torch.Size([10, 384])	 Training Loss: 1.0455220937728882
Step: 91	 Data: torch.Size([10, 384])	 Training Loss: 0.8983268141746521
Step: 92	 Data: torch.Size([10, 384])	 Training Loss: 0.8831021785736084
Step: 93	 Data: torch.Size([10, 384])	 Training Loss: 0.995835542678833
Step: 94	 Data: torch.Size([10, 384])	 Training Loss: 1.094243049621582
Step: 95	 Data: torch.Size([10, 384])	 Training Loss: 0.9550889134407043
Step: 96	 Data: torch.Size([10, 384])	 Training Loss: 0.8923563361167908
Step: 97	 Data: torch.Size([10, 384])	 Training Loss: 1.0485557317733765
Step: 98	 Data: torch.Size([10, 384])	 Training Loss: 0.9087758660316467
Step: 99	 Data: torch.Size([10, 384])	 Training Loss: 0.9779828786849976
Step: 100	 Data: torch.Size([10, 384])	 Training Loss: 1.1373553276062012
Step: 101	 Data: torch.Size([10, 384])	 Training Loss: 0.959317684173584
Step: 102	 Data: torch.Size([10, 384])	 Training Loss: 0.9679639339447021
Step: 103	 Data: torch.Size([10, 384])	 Training Loss: 0.9940349459648132
Step: 104	 Data: torch.Size([10, 384])	 Training Loss: 0.9363511800765991
Step: 105	 Data: torch.Size([10, 384])	 Training Loss: 0.9816906452178955
Step: 106	 Data: torch.Size([10, 384])	 Training Loss: 1.1099060773849487
Step: 107	 Data: torch.Size([10, 384])	 Training Loss: 0.9305835366249084
Step: 108	 Data: torch.Size([10, 384])	 Training Loss: 0.9025744795799255
Step: 109	 Data: torch.Size([10, 384])	 Training Loss: 0.9968782067298889
Step: 110	 Data: torch.Size([10, 384])	 Training Loss: 0.9095801115036011
Step: 111	 Data: torch.Size([10, 384])	 Training Loss: 1.1943310499191284
Step: 112	 Data: torch.Size([10, 384])	 Training Loss: 1.1882314682006836
Step: 113	 Data: torch.Size([10, 384])	 Training Loss: 1.0579791069030762
Step: 114	 Data: torch.Size([10, 384])	 Training Loss: 0.9688760042190552
Step: 115	 Data: torch.Size([10, 384])	 Training Loss: 0.8874596357345581
Step: 116	 Data: torch.Size([10, 384])	 Training Loss: 0.9108060002326965
Step: 117	 Data: torch.Size([10, 384])	 Training Loss: 0.8900279998779297
Step: 118	 Data: torch.Size([10, 384])	 Training Loss: 0.9333996176719666
Step: 119	 Data: torch.Size([10, 384])	 Training Loss: 1.31320059299469
Step: 120	 Data: torch.Size([10, 384])	 Training Loss: 0.8663981556892395
Step: 121	 Data: torch.Size([10, 307])	 Training Loss: 1.070326805114746
Step: 122	 Data: torch.Size([10, 384])	 Training Loss: 1.125817060470581
Step: 123	 Data: torch.Size([10, 384])	 Training Loss: 0.9690839648246765
Step: 124	 Data: torch.Size([10, 384])	 Training Loss: 0.8569906949996948
Step: 125	 Data: torch.Size([10, 384])	 Training Loss: 0.878443717956543
Step: 126	 Data: torch.Size([10, 384])	 Training Loss: 0.9081610441207886
Step: 127	 Data: torch.Size([10, 384])	 Training Loss: 1.0365532636642456
Step: 128	 Data: torch.Size([10, 384])	 Training Loss: 0.8292039632797241
Step: 129	 Data: torch.Size([10, 384])	 Training Loss: 1.0759282112121582
Step: 130	 Data: torch.Size([10, 384])	 Training Loss: 0.9637182950973511
Step: 131	 Data: torch.Size([10, 384])	 Training Loss: 0.9619278311729431
Step: 132	 Data: torch.Size([10, 384])	 Training Loss: 0.952750563621521
Step: 133	 Data: torch.Size([10, 384])	 Training Loss: 0.9910734295845032
Step: 134	 Data: torch.Size([10, 384])	 Training Loss: 1.0573657751083374
Step: 135	 Data: torch.Size([10, 384])	 Training Loss: 0.975691556930542
Step: 136	 Data: torch.Size([10, 384])	 Training Loss: 0.9296319484710693
Step: 137	 Data: torch.Size([10, 384])	 Training Loss: 1.0536843538284302
Step: 138	 Data: torch.Size([10, 384])	 Training Loss: 0.9150962233543396
Step: 139	 Data: torch.Size([10, 384])	 Training Loss: 0.9988073706626892
Step: 140	 Data: torch.Size([10, 384])	 Training Loss: 0.9565348625183105
Step: 141	 Data: torch.Size([10, 384])	 Training Loss: 0.9834851622581482
Step: 142	 Data: torch.Size([10, 384])	 Training Loss: 0.9661545157432556
Step: 143	 Data: torch.Size([10, 384])	 Training Loss: 1.0068233013153076
Step: 144	 Data: torch.Size([10, 384])	 Training Loss: 1.0078051090240479
Step: 145	 Data: torch.Size([10, 384])	 Training Loss: 0.9448525905609131
Step: 146	 Data: torch.Size([10, 384])	 Training Loss: 1.0028783082962036
Step: 147	 Data: torch.Size([10, 384])	 Training Loss: 0.9822753071784973
Step: 148	 Data: torch.Size([10, 384])	 Training Loss: 0.9317699074745178
Step: 149	 Data: torch.Size([10, 384])	 Training Loss: 0.8983104228973389
Step: 150	 Data: torch.Size([10, 384])	 Training Loss: 0.9670284986495972
Step: 151	 Data: torch.Size([10, 384])	 Training Loss: 1.052380084991455
Step: 152	 Data: torch.Size([10, 384])	 Training Loss: 0.8930205702781677
Step: 153	 Data: torch.Size([10, 384])	 Training Loss: 1.1080875396728516
Step: 154	 Data: torch.Size([10, 384])	 Training Loss: 1.0231990814208984
Step: 155	 Data: torch.Size([10, 384])	 Training Loss: 0.9305671453475952
Step: 156	 Data: torch.Size([10, 384])	 Training Loss: 0.8392113447189331
Step: 157	 Data: torch.Size([10, 384])	 Training Loss: 0.8586048483848572
Step: 158	 Data: torch.Size([10, 384])	 Training Loss: 0.9780280590057373
Step: 159	 Data: torch.Size([10, 384])	 Training Loss: 1.0541890859603882
Step: 160	 Data: torch.Size([10, 384])	 Training Loss: 0.8695658445358276
Step: 161	 Data: torch.Size([10, 384])	 Training Loss: 1.0346031188964844
Step: 162	 Data: torch.Size([10, 384])	 Training Loss: 1.0001823902130127
Step: 163	 Data: torch.Size([10, 384])	 Training Loss: 0.9819589257240295
Step: 164	 Data: torch.Size([10, 384])	 Training Loss: 0.9489361643791199
Step: 165	 Data: torch.Size([10, 384])	 Training Loss: 0.9055234789848328
Step: 166	 Data: torch.Size([10, 384])	 Training Loss: 1.0797656774520874
Step: 167	 Data: torch.Size([10, 384])	 Training Loss: 0.9238030910491943
Step: 168	 Data: torch.Size([10, 384])	 Training Loss: 1.0212576389312744
Step: 169	 Data: torch.Size([10, 384])	 Training Loss: 0.9638053178787231
Step: 170	 Data: torch.Size([10, 384])	 Training Loss: 1.0711579322814941
Step: 171	 Data: torch.Size([10, 384])	 Training Loss: 0.9116533398628235
Step: 172	 Data: torch.Size([10, 384])	 Training Loss: 0.8482396006584167
Step: 173	 Data: torch.Size([10, 384])	 Training Loss: 0.9153106212615967
Step: 174	 Data: torch.Size([10, 384])	 Training Loss: 0.901991605758667
Step: 175	 Data: torch.Size([10, 384])	 Training Loss: 1.0372638702392578
Step: 176	 Data: torch.Size([10, 384])	 Training Loss: 0.9506891369819641
Step: 177	 Data: torch.Size([10, 384])	 Training Loss: 0.9924464821815491
Step: 178	 Data: torch.Size([10, 384])	 Training Loss: 0.9003143906593323
Step: 179	 Data: torch.Size([10, 384])	 Training Loss: 0.8351529836654663
Step: 180	 Data: torch.Size([10, 384])	 Training Loss: 1.0472586154937744
Step: 181	 Data: torch.Size([10, 384])	 Training Loss: 0.736497700214386
Step: 182	 Data: torch.Size([10, 384])	 Training Loss: 1.0796626806259155
Step: 183	 Data: torch.Size([10, 384])	 Training Loss: 0.8632761836051941
Step: 184	 Data: torch.Size([10, 384])	 Training Loss: 0.9487982392311096
Step: 185	 Data: torch.Size([10, 384])	 Training Loss: 0.8500189185142517
Step: 186	 Data: torch.Size([10, 384])	 Training Loss: 0.9863290190696716
Step: 187	 Data: torch.Size([10, 384])	 Training Loss: 0.8680511713027954
Step: 188	 Data: torch.Size([10, 384])	 Training Loss: 0.968634307384491
Step: 189	 Data: torch.Size([10, 384])	 Training Loss: 0.9283848404884338
Step: 190	 Data: torch.Size([10, 384])	 Training Loss: 1.097333550453186
Step: 191	 Data: torch.Size([10, 384])	 Training Loss: 0.8910257816314697
Step: 192	 Data: torch.Size([10, 384])	 Training Loss: 1.0062326192855835
Step: 193	 Data: torch.Size([10, 384])	 Training Loss: 0.9359580278396606
Step: 194	 Data: torch.Size([10, 384])	 Training Loss: 0.8805710077285767
Step: 195	 Data: torch.Size([10, 384])	 Training Loss: 0.9393864274024963
Step: 196	 Data: torch.Size([10, 384])	 Training Loss: 0.9148902893066406
Step: 197	 Data: torch.Size([10, 384])	 Training Loss: 0.8390507698059082
Step: 198	 Data: torch.Size([10, 384])	 Training Loss: 1.015590786933899
Step: 199	 Data: torch.Size([10, 384])	 Training Loss: 1.0055702924728394
Step: 200	 Data: torch.Size([10, 384])	 Training Loss: 0.9037507772445679
Step: 201	 Data: torch.Size([10, 384])	 Training Loss: 0.9704297184944153
Step: 202	 Data: torch.Size([10, 384])	 Training Loss: 0.8990432620048523
Step: 203	 Data: torch.Size([10, 384])	 Training Loss: 1.0075329542160034
Step: 204	 Data: torch.Size([10, 384])	 Training Loss: 0.9763590693473816
Step: 205	 Data: torch.Size([10, 384])	 Training Loss: 0.9947332143783569
Step: 206	 Data: torch.Size([10, 384])	 Training Loss: 0.8996820449829102
Step: 207	 Data: torch.Size([10, 384])	 Training Loss: 0.8748704791069031
Step: 208	 Data: torch.Size([10, 384])	 Training Loss: 0.9839489459991455
Step: 209	 Data: torch.Size([10, 384])	 Training Loss: 0.9528181552886963
Step: 210	 Data: torch.Size([10, 384])	 Training Loss: 0.9877488613128662
Step: 211	 Data: torch.Size([10, 384])	 Training Loss: 0.8952076435089111
Step: 212	 Data: torch.Size([10, 384])	 Training Loss: 0.8834763765335083
Step: 213	 Data: torch.Size([10, 384])	 Training Loss: 0.9288169741630554
Step: 214	 Data: torch.Size([10, 384])	 Training Loss: 1.0793304443359375
Step: 215	 Data: torch.Size([10, 384])	 Training Loss: 0.9043568968772888
Step: 216	 Data: torch.Size([10, 384])	 Training Loss: 0.9153915047645569
Step: 217	 Data: torch.Size([10, 384])	 Training Loss: 1.0369081497192383
Step: 218	 Data: torch.Size([10, 384])	 Training Loss: 0.9830293655395508
Step: 219	 Data: torch.Size([10, 384])	 Training Loss: 1.0439482927322388
Step: 220	 Data: torch.Size([10, 384])	 Training Loss: 0.8747360706329346
Step: 221	 Data: torch.Size([10, 384])	 Training Loss: 1.0090993642807007
Step: 222	 Data: torch.Size([10, 384])	 Training Loss: 0.8540470004081726
Step: 223	 Data: torch.Size([10, 384])	 Training Loss: 0.929907500743866
Step: 224	 Data: torch.Size([10, 384])	 Training Loss: 0.9321509003639221
Step: 225	 Data: torch.Size([10, 384])	 Training Loss: 0.8138032555580139
Step: 226	 Data: torch.Size([10, 384])	 Training Loss: 0.8576463460922241
Step: 227	 Data: torch.Size([10, 384])	 Training Loss: 0.983363687992096
Step: 228	 Data: torch.Size([10, 384])	 Training Loss: 0.9071925282478333
Step: 229	 Data: torch.Size([10, 384])	 Training Loss: 0.8965808749198914
Step: 230	 Data: torch.Size([10, 384])	 Training Loss: 0.8230928182601929
Step: 231	 Data: torch.Size([10, 384])	 Training Loss: 0.9436182975769043
Step: 232	 Data: torch.Size([10, 384])	 Training Loss: 0.9847649931907654
Step: 233	 Data: torch.Size([10, 384])	 Training Loss: 0.9733747243881226
Step: 234	 Data: torch.Size([10, 384])	 Training Loss: 0.821651816368103
Step: 235	 Data: torch.Size([10, 384])	 Training Loss: 0.8216564655303955
Step: 236	 Data: torch.Size([10, 384])	 Training Loss: 0.9461072087287903
Step: 237	 Data: torch.Size([10, 384])	 Training Loss: 1.0218455791473389
Step: 238	 Data: torch.Size([10, 384])	 Training Loss: 1.0354911088943481
Step: 239	 Data: torch.Size([10, 384])	 Training Loss: 0.9322606921195984
Step: 240	 Data: torch.Size([10, 384])	 Training Loss: 0.9466806650161743
Step: 241	 Data: torch.Size([10, 384])	 Training Loss: 1.0203347206115723
Step: 242	 Data: torch.Size([10, 384])	 Training Loss: 0.907311201095581
Step: 243	 Data: torch.Size([10, 384])	 Training Loss: 1.0617784261703491
Step: 244	 Data: torch.Size([10, 384])	 Training Loss: 1.0021494626998901
Step: 245	 Data: torch.Size([10, 384])	 Training Loss: 0.9567065238952637
Step: 246	 Data: torch.Size([10, 384])	 Training Loss: 1.0233707427978516
Step: 247	 Data: torch.Size([10, 384])	 Training Loss: 0.8966228365898132
Step: 248	 Data: torch.Size([10, 384])	 Training Loss: 0.8278898000717163
Step: 249	 Data: torch.Size([10, 384])	 Training Loss: 0.8984231352806091
Step: 250	 Data: torch.Size([10, 384])	 Training Loss: 1.0330733060836792
Step: 251	 Data: torch.Size([10, 384])	 Training Loss: 0.9988620281219482
Step: 252	 Data: torch.Size([10, 384])	 Training Loss: 0.9948486685752869
Step: 253	 Data: torch.Size([10, 384])	 Training Loss: 0.9715697169303894
Step: 254	 Data: torch.Size([10, 384])	 Training Loss: 0.9296624064445496
Step: 255	 Data: torch.Size([10, 384])	 Training Loss: 0.8535470366477966
Step: 256	 Data: torch.Size([10, 384])	 Training Loss: 0.9462276101112366
Step: 257	 Data: torch.Size([10, 384])	 Training Loss: 0.8980365991592407
Step: 258	 Data: torch.Size([10, 384])	 Training Loss: 0.8980841636657715
Step: 259	 Data: torch.Size([10, 384])	 Training Loss: 0.8396034836769104
Step: 260	 Data: torch.Size([10, 384])	 Training Loss: 0.8948933482170105
Step: 261	 Data: torch.Size([10, 384])	 Training Loss: 1.0286351442337036
Step: 262	 Data: torch.Size([10, 384])	 Training Loss: 0.9744834899902344
Step: 263	 Data: torch.Size([10, 384])	 Training Loss: 1.0487003326416016
Step: 264	 Data: torch.Size([10, 384])	 Training Loss: 1.0503557920455933
Step: 265	 Data: torch.Size([10, 384])	 Training Loss: 0.9416946172714233
Step: 266	 Data: torch.Size([10, 384])	 Training Loss: 0.8840376138687134
Step: 267	 Data: torch.Size([10, 384])	 Training Loss: 0.8796175122261047
Step: 268	 Data: torch.Size([10, 384])	 Training Loss: 0.8993414640426636
Step: 269	 Data: torch.Size([10, 384])	 Training Loss: 0.8836606740951538
Step: 270	 Data: torch.Size([10, 384])	 Training Loss: 0.9883546233177185
Step: 271	 Data: torch.Size([10, 384])	 Training Loss: 0.9529675841331482
Step: 272	 Data: torch.Size([10, 384])	 Training Loss: 0.9068162441253662
Step: 273	 Data: torch.Size([10, 384])	 Training Loss: 0.8203250765800476
Step: 274	 Data: torch.Size([10, 384])	 Training Loss: 0.9703591465950012
Step: 275	 Data: torch.Size([10, 384])	 Training Loss: 1.0077685117721558
Step: 276	 Data: torch.Size([10, 384])	 Training Loss: 0.941169261932373
Step: 277	 Data: torch.Size([10, 384])	 Training Loss: 0.9094823002815247
Step: 278	 Data: torch.Size([10, 384])	 Training Loss: 1.021850347518921
Step: 279	 Data: torch.Size([10, 384])	 Training Loss: 0.9727045297622681
Step: 280	 Data: torch.Size([10, 384])	 Training Loss: 0.9643517136573792
Step: 281	 Data: torch.Size([10, 384])	 Training Loss: 0.9932728409767151
Step: 282	 Data: torch.Size([10, 384])	 Training Loss: 0.9302711486816406
Step: 283	 Data: torch.Size([10, 384])	 Training Loss: 1.0488592386245728
Step: 284	 Data: torch.Size([10, 384])	 Training Loss: 1.2732375860214233
Step: 285	 Data: torch.Size([10, 384])	 Training Loss: 0.9253584742546082
Step: 286	 Data: torch.Size([10, 384])	 Training Loss: 1.0580700635910034
Step: 287	 Data: torch.Size([10, 384])	 Training Loss: 0.9078892469406128
Step: 288	 Data: torch.Size([10, 384])	 Training Loss: 0.7752503156661987
Step: 289	 Data: torch.Size([10, 384])	 Training Loss: 0.930819571018219
Step: 290	 Data: torch.Size([10, 384])	 Training Loss: 0.9152417182922363
Step: 291	 Data: torch.Size([10, 384])	 Training Loss: 0.9474441409111023
Step: 292	 Data: torch.Size([10, 384])	 Training Loss: 1.0278253555297852
Step: 293	 Data: torch.Size([10, 384])	 Training Loss: 0.8541001677513123
Step: 294	 Data: torch.Size([10, 384])	 Training Loss: 0.8531001210212708
Step: 295	 Data: torch.Size([10, 384])	 Training Loss: 0.9844814538955688
Step: 296	 Data: torch.Size([10, 384])	 Training Loss: 1.0073518753051758
Step: 297	 Data: torch.Size([10, 384])	 Training Loss: 0.940966784954071
Step: 298	 Data: torch.Size([10, 384])	 Training Loss: 0.9396074414253235
Step: 299	 Data: torch.Size([10, 384])	 Training Loss: 1.0080841779708862
Step: 300	 Data: torch.Size([10, 384])	 Training Loss: 1.0455985069274902
