[2024-05-07 05:10:54,052] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-05-07 05:10:54,052] torch.distributed.run: [WARNING] 
[2024-05-07 05:10:54,052] torch.distributed.run: [WARNING] *****************************************
[2024-05-07 05:10:54,052] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-07 05:10:54,052] torch.distributed.run: [WARNING] *****************************************
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56229 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56229 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56229 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56229 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56229 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56229 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56229 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56229 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56229 (errno: 22 - Invalid argument).
====================initialize the distributed env====================
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.20s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.71s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.90s/it]
====================get the model with lora====================
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.79s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.74s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.98s/it]
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
====================Use auto mixed precision training====================
====================Use gradient checkpoint====================
====================get the dataset====================
====================get the dataloader====================
====================start train====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Step: 0	 Data: torch.Size([10, 384])	 Training Loss: 1.0653773546218872
Step: 1	 Data: torch.Size([10, 384])	 Training Loss: 1.0276778936386108
Step: 2	 Data: torch.Size([10, 384])	 Training Loss: 0.9646230340003967
Step: 3	 Data: torch.Size([10, 384])	 Training Loss: 1.1950732469558716
Step: 4	 Data: torch.Size([10, 384])	 Training Loss: 1.2681667804718018
Step: 5	 Data: torch.Size([10, 302])	 Training Loss: 1.2406597137451172
Step: 6	 Data: torch.Size([10, 384])	 Training Loss: 1.2183763980865479
Step: 7	 Data: torch.Size([10, 384])	 Training Loss: 1.1052063703536987
Step: 8	 Data: torch.Size([10, 384])	 Training Loss: 1.1118923425674438
Step: 9	 Data: torch.Size([10, 384])	 Training Loss: 1.0326794385910034
Step: 10	 Data: torch.Size([10, 384])	 Training Loss: 1.3796390295028687
Step: 11	 Data: torch.Size([10, 319])	 Training Loss: 1.1889429092407227
Step: 12	 Data: torch.Size([10, 384])	 Training Loss: 1.188995361328125
Step: 13	 Data: torch.Size([10, 384])	 Training Loss: 0.9835812449455261
Step: 14	 Data: torch.Size([10, 384])	 Training Loss: 0.9871845841407776
Step: 15	 Data: torch.Size([10, 384])	 Training Loss: 1.2157665491104126
Step: 16	 Data: torch.Size([10, 384])	 Training Loss: 1.13834810256958
Step: 17	 Data: torch.Size([10, 384])	 Training Loss: 1.1938031911849976
Step: 18	 Data: torch.Size([10, 384])	 Training Loss: 1.1203304529190063
Step: 19	 Data: torch.Size([10, 384])	 Training Loss: 1.1211481094360352
Step: 20	 Data: torch.Size([10, 384])	 Training Loss: 1.2381073236465454
Step: 21	 Data: torch.Size([10, 384])	 Training Loss: 1.0429198741912842
Step: 22	 Data: torch.Size([10, 384])	 Training Loss: 1.145245909690857
Step: 23	 Data: torch.Size([10, 384])	 Training Loss: 1.070249319076538
Step: 24	 Data: torch.Size([10, 384])	 Training Loss: 1.1489049196243286
Step: 25	 Data: torch.Size([10, 384])	 Training Loss: 1.0754433870315552
Step: 26	 Data: torch.Size([10, 384])	 Training Loss: 1.353530764579773
Step: 27	 Data: torch.Size([10, 384])	 Training Loss: 1.1392371654510498
Step: 28	 Data: torch.Size([10, 384])	 Training Loss: 1.1083064079284668
Step: 29	 Data: torch.Size([10, 384])	 Training Loss: 1.148331880569458
Step: 30	 Data: torch.Size([10, 384])	 Training Loss: 0.9738193154335022
Step: 31	 Data: torch.Size([10, 384])	 Training Loss: 1.047343373298645
Step: 32	 Data: torch.Size([10, 384])	 Training Loss: 1.0157138109207153
Step: 33	 Data: torch.Size([10, 384])	 Training Loss: 1.1279053688049316
Step: 34	 Data: torch.Size([10, 384])	 Training Loss: 1.1651337146759033
Step: 35	 Data: torch.Size([10, 384])	 Training Loss: 0.9591991305351257
Step: 36	 Data: torch.Size([10, 384])	 Training Loss: 1.1566628217697144
Step: 37	 Data: torch.Size([10, 384])	 Training Loss: 1.448120355606079
Step: 38	 Data: torch.Size([10, 384])	 Training Loss: 1.2806404829025269
Step: 39	 Data: torch.Size([10, 384])	 Training Loss: 1.1215245723724365
Step: 40	 Data: torch.Size([10, 384])	 Training Loss: 1.1390750408172607
Step: 41	 Data: torch.Size([10, 384])	 Training Loss: 1.0311788320541382
Step: 42	 Data: torch.Size([10, 384])	 Training Loss: 1.1319983005523682
Step: 43	 Data: torch.Size([10, 384])	 Training Loss: 0.9792229533195496
Step: 44	 Data: torch.Size([10, 384])	 Training Loss: 0.93525630235672
Step: 45	 Data: torch.Size([10, 384])	 Training Loss: 1.154323697090149
Step: 46	 Data: torch.Size([10, 384])	 Training Loss: 1.2617888450622559
Step: 47	 Data: torch.Size([10, 384])	 Training Loss: 0.9958676099777222
Step: 48	 Data: torch.Size([10, 384])	 Training Loss: 1.0208252668380737
Step: 49	 Data: torch.Size([10, 384])	 Training Loss: 1.0400705337524414
Step: 50	 Data: torch.Size([10, 384])	 Training Loss: 0.9515330791473389
Step: 51	 Data: torch.Size([10, 384])	 Training Loss: 0.9491533041000366
Step: 52	 Data: torch.Size([10, 384])	 Training Loss: 1.0061596632003784
Step: 53	 Data: torch.Size([10, 384])	 Training Loss: 1.0731518268585205
Step: 54	 Data: torch.Size([10, 384])	 Training Loss: 1.3036551475524902
Step: 55	 Data: torch.Size([10, 384])	 Training Loss: 1.2115459442138672
Step: 56	 Data: torch.Size([10, 384])	 Training Loss: 1.0325783491134644
Step: 57	 Data: torch.Size([10, 384])	 Training Loss: 1.2163368463516235
Step: 58	 Data: torch.Size([10, 384])	 Training Loss: 1.0514034032821655
Step: 59	 Data: torch.Size([10, 384])	 Training Loss: 1.0872652530670166
Step: 60	 Data: torch.Size([10, 384])	 Training Loss: 0.9798094630241394
Step: 61	 Data: torch.Size([10, 384])	 Training Loss: 0.974850058555603
Step: 62	 Data: torch.Size([10, 384])	 Training Loss: 0.9658692479133606
Step: 63	 Data: torch.Size([10, 384])	 Training Loss: 1.0456410646438599
Step: 64	 Data: torch.Size([10, 384])	 Training Loss: 1.0248955488204956
Step: 65	 Data: torch.Size([10, 384])	 Training Loss: 1.1350946426391602
Step: 66	 Data: torch.Size([10, 384])	 Training Loss: 0.9620658755302429
Step: 67	 Data: torch.Size([10, 384])	 Training Loss: 1.0230436325073242
Step: 68	 Data: torch.Size([10, 384])	 Training Loss: 1.1093177795410156
Step: 69	 Data: torch.Size([10, 384])	 Training Loss: 1.0387994050979614
Step: 70	 Data: torch.Size([10, 384])	 Training Loss: 1.0132232904434204
Step: 71	 Data: torch.Size([10, 384])	 Training Loss: 0.9310457110404968
Step: 72	 Data: torch.Size([10, 384])	 Training Loss: 0.9240641593933105
Step: 73	 Data: torch.Size([10, 384])	 Training Loss: 0.9447798132896423
Step: 74	 Data: torch.Size([10, 384])	 Training Loss: 1.1128246784210205
Step: 75	 Data: torch.Size([10, 384])	 Training Loss: 0.9102978110313416
Step: 76	 Data: torch.Size([10, 384])	 Training Loss: 1.0512789487838745
Step: 77	 Data: torch.Size([10, 384])	 Training Loss: 1.0531635284423828
Step: 78	 Data: torch.Size([10, 384])	 Training Loss: 1.2053450345993042
Step: 79	 Data: torch.Size([10, 384])	 Training Loss: 1.0079632997512817
Step: 80	 Data: torch.Size([10, 384])	 Training Loss: 1.0361088514328003
Step: 81	 Data: torch.Size([10, 384])	 Training Loss: 1.047516942024231
Step: 82	 Data: torch.Size([10, 384])	 Training Loss: 1.1282732486724854
Step: 83	 Data: torch.Size([10, 384])	 Training Loss: 1.0893586874008179
Step: 84	 Data: torch.Size([10, 384])	 Training Loss: 1.0549811124801636
Step: 85	 Data: torch.Size([10, 384])	 Training Loss: 1.18760085105896
Step: 86	 Data: torch.Size([10, 384])	 Training Loss: 1.0311814546585083
Step: 87	 Data: torch.Size([10, 384])	 Training Loss: 1.1314687728881836
Step: 88	 Data: torch.Size([10, 384])	 Training Loss: 0.9621677398681641
Step: 89	 Data: torch.Size([10, 384])	 Training Loss: 1.1380053758621216
Step: 90	 Data: torch.Size([10, 384])	 Training Loss: 0.8934256434440613
Step: 91	 Data: torch.Size([10, 384])	 Training Loss: 0.9167749285697937
Step: 92	 Data: torch.Size([10, 384])	 Training Loss: 0.9162425994873047
Step: 93	 Data: torch.Size([10, 384])	 Training Loss: 0.8532403707504272
Step: 94	 Data: torch.Size([10, 384])	 Training Loss: 0.9146984219551086
Step: 95	 Data: torch.Size([10, 384])	 Training Loss: 0.9822961091995239
Step: 96	 Data: torch.Size([10, 384])	 Training Loss: 0.9997846484184265
Step: 97	 Data: torch.Size([10, 384])	 Training Loss: 1.1261844635009766
Step: 98	 Data: torch.Size([10, 384])	 Training Loss: 0.9410070180892944
Step: 99	 Data: torch.Size([10, 384])	 Training Loss: 0.9711102843284607
Step: 100	 Data: torch.Size([10, 384])	 Training Loss: 1.0601508617401123
Step: 101	 Data: torch.Size([10, 384])	 Training Loss: 1.0378845930099487
Step: 102	 Data: torch.Size([10, 384])	 Training Loss: 0.993851363658905
Step: 103	 Data: torch.Size([10, 384])	 Training Loss: 1.1150238513946533
Step: 104	 Data: torch.Size([10, 384])	 Training Loss: 1.0307731628417969
Step: 105	 Data: torch.Size([10, 384])	 Training Loss: 0.9658095836639404
Step: 106	 Data: torch.Size([10, 384])	 Training Loss: 1.0224553346633911
Step: 107	 Data: torch.Size([10, 384])	 Training Loss: 0.8742431998252869
Step: 108	 Data: torch.Size([10, 384])	 Training Loss: 1.0664517879486084
Step: 109	 Data: torch.Size([10, 384])	 Training Loss: 1.048052191734314
Step: 110	 Data: torch.Size([10, 384])	 Training Loss: 0.849540114402771
Step: 111	 Data: torch.Size([10, 384])	 Training Loss: 1.0268110036849976
Step: 112	 Data: torch.Size([10, 384])	 Training Loss: 0.9649516344070435
Step: 113	 Data: torch.Size([10, 349])	 Training Loss: 0.9731482267379761
Step: 114	 Data: torch.Size([10, 384])	 Training Loss: 0.8153473138809204
Step: 115	 Data: torch.Size([10, 384])	 Training Loss: 0.9810846447944641
Step: 116	 Data: torch.Size([10, 384])	 Training Loss: 1.2582520246505737
Step: 117	 Data: torch.Size([10, 384])	 Training Loss: 0.8863874077796936
Step: 118	 Data: torch.Size([10, 384])	 Training Loss: 0.9065855145454407
Step: 119	 Data: torch.Size([10, 384])	 Training Loss: 0.9277010560035706
Step: 120	 Data: torch.Size([10, 384])	 Training Loss: 0.8989402055740356
Step: 121	 Data: torch.Size([10, 384])	 Training Loss: 0.992785632610321
Step: 122	 Data: torch.Size([10, 384])	 Training Loss: 0.9744173288345337
Step: 123	 Data: torch.Size([10, 384])	 Training Loss: 1.0357877016067505
Step: 124	 Data: torch.Size([10, 384])	 Training Loss: 1.0022454261779785
Step: 125	 Data: torch.Size([10, 384])	 Training Loss: 1.0912600755691528
Step: 126	 Data: torch.Size([10, 384])	 Training Loss: 0.8942880630493164
Step: 127	 Data: torch.Size([10, 384])	 Training Loss: 0.8782904744148254
Step: 128	 Data: torch.Size([10, 384])	 Training Loss: 0.9606270790100098
Step: 129	 Data: torch.Size([10, 384])	 Training Loss: 0.8630425333976746
Step: 130	 Data: torch.Size([10, 384])	 Training Loss: 1.0240604877471924
Step: 131	 Data: torch.Size([10, 384])	 Training Loss: 0.9892832636833191
Step: 132	 Data: torch.Size([10, 384])	 Training Loss: 0.9531569480895996
Step: 133	 Data: torch.Size([10, 384])	 Training Loss: 0.8398780226707458
Step: 134	 Data: torch.Size([10, 384])	 Training Loss: 1.0157335996627808
Step: 135	 Data: torch.Size([10, 384])	 Training Loss: 0.90667724609375
Step: 136	 Data: torch.Size([10, 384])	 Training Loss: 1.0165293216705322
Step: 137	 Data: torch.Size([10, 384])	 Training Loss: 0.9257292747497559
Step: 138	 Data: torch.Size([10, 384])	 Training Loss: 0.9876359701156616
Step: 139	 Data: torch.Size([10, 384])	 Training Loss: 0.9641085267066956
Step: 140	 Data: torch.Size([10, 384])	 Training Loss: 1.0434798002243042
Step: 141	 Data: torch.Size([10, 384])	 Training Loss: 1.00489342212677
Step: 142	 Data: torch.Size([10, 384])	 Training Loss: 1.0305358171463013
Step: 143	 Data: torch.Size([10, 384])	 Training Loss: 1.034995436668396
Step: 144	 Data: torch.Size([10, 384])	 Training Loss: 0.8759705424308777
Step: 145	 Data: torch.Size([10, 384])	 Training Loss: 0.8326160311698914
Step: 146	 Data: torch.Size([10, 384])	 Training Loss: 0.9339631199836731
Step: 147	 Data: torch.Size([10, 384])	 Training Loss: 0.8835275769233704
Step: 148	 Data: torch.Size([10, 384])	 Training Loss: 1.087225079536438
Step: 149	 Data: torch.Size([10, 384])	 Training Loss: 0.8762760162353516
Step: 150	 Data: torch.Size([10, 384])	 Training Loss: 0.8206897377967834
Step: 151	 Data: torch.Size([10, 384])	 Training Loss: 0.9461883306503296
Step: 152	 Data: torch.Size([10, 384])	 Training Loss: 1.14574134349823
Step: 153	 Data: torch.Size([10, 384])	 Training Loss: 0.8778679966926575
Step: 154	 Data: torch.Size([10, 384])	 Training Loss: 0.9859617948532104
Step: 155	 Data: torch.Size([10, 384])	 Training Loss: 0.9988235831260681
Step: 156	 Data: torch.Size([10, 384])	 Training Loss: 0.9316598773002625
Step: 157	 Data: torch.Size([10, 384])	 Training Loss: 0.8509221076965332
Step: 158	 Data: torch.Size([10, 384])	 Training Loss: 1.0732910633087158
Step: 159	 Data: torch.Size([10, 384])	 Training Loss: 1.0127893686294556
Step: 160	 Data: torch.Size([10, 384])	 Training Loss: 0.8911148905754089
Step: 161	 Data: torch.Size([10, 384])	 Training Loss: 0.9091411828994751
Step: 162	 Data: torch.Size([10, 384])	 Training Loss: 0.9517053961753845
Step: 163	 Data: torch.Size([10, 384])	 Training Loss: 0.8571749329566956
Step: 164	 Data: torch.Size([10, 384])	 Training Loss: 0.9304922223091125
Step: 165	 Data: torch.Size([10, 384])	 Training Loss: 1.0349836349487305
Step: 166	 Data: torch.Size([10, 384])	 Training Loss: 0.7822664976119995
Step: 167	 Data: torch.Size([10, 384])	 Training Loss: 0.9900509715080261
Step: 168	 Data: torch.Size([10, 384])	 Training Loss: 0.9223551750183105
Step: 169	 Data: torch.Size([10, 384])	 Training Loss: 0.9173145294189453
Step: 170	 Data: torch.Size([10, 384])	 Training Loss: 0.9411091208457947
Step: 171	 Data: torch.Size([10, 384])	 Training Loss: 0.8872674703598022
Step: 172	 Data: torch.Size([10, 384])	 Training Loss: 1.1030901670455933
Step: 173	 Data: torch.Size([10, 384])	 Training Loss: 0.9311771392822266
Step: 174	 Data: torch.Size([10, 384])	 Training Loss: 1.07823646068573
Step: 175	 Data: torch.Size([10, 384])	 Training Loss: 0.8224729895591736
Step: 176	 Data: torch.Size([10, 346])	 Training Loss: 0.9454072713851929
Step: 177	 Data: torch.Size([10, 384])	 Training Loss: 0.8128191828727722
Step: 178	 Data: torch.Size([10, 384])	 Training Loss: 0.8716236352920532
Step: 179	 Data: torch.Size([10, 384])	 Training Loss: 0.9258114099502563
Step: 180	 Data: torch.Size([10, 384])	 Training Loss: 0.9288426637649536
Step: 181	 Data: torch.Size([10, 384])	 Training Loss: 0.9620426893234253
Step: 182	 Data: torch.Size([10, 384])	 Training Loss: 0.8936945199966431
Step: 183	 Data: torch.Size([10, 384])	 Training Loss: 1.1168930530548096
Step: 184	 Data: torch.Size([10, 384])	 Training Loss: 1.0638506412506104
Step: 185	 Data: torch.Size([10, 384])	 Training Loss: 0.9467072486877441
Step: 186	 Data: torch.Size([10, 384])	 Training Loss: 1.0576345920562744
Step: 187	 Data: torch.Size([10, 384])	 Training Loss: 0.9427455067634583
Step: 188	 Data: torch.Size([10, 384])	 Training Loss: 0.9985729455947876
Step: 189	 Data: torch.Size([10, 384])	 Training Loss: 0.9907345175743103
Step: 190	 Data: torch.Size([10, 384])	 Training Loss: 1.0214691162109375
Step: 191	 Data: torch.Size([10, 384])	 Training Loss: 0.8396097421646118
Step: 192	 Data: torch.Size([10, 384])	 Training Loss: 0.891356348991394
Step: 193	 Data: torch.Size([10, 384])	 Training Loss: 1.04071843624115
Step: 194	 Data: torch.Size([10, 384])	 Training Loss: 0.9491980671882629
Step: 195	 Data: torch.Size([10, 384])	 Training Loss: 0.9836220741271973
Step: 196	 Data: torch.Size([10, 384])	 Training Loss: 0.9825736880302429
Step: 197	 Data: torch.Size([10, 384])	 Training Loss: 0.8560531735420227
Step: 198	 Data: torch.Size([10, 384])	 Training Loss: 0.8772179484367371
Step: 199	 Data: torch.Size([10, 384])	 Training Loss: 0.831254780292511
Step: 200	 Data: torch.Size([10, 384])	 Training Loss: 0.9763966798782349
Step: 201	 Data: torch.Size([10, 277])	 Training Loss: 1.1297293901443481
Step: 202	 Data: torch.Size([10, 384])	 Training Loss: 0.9606162309646606
Step: 203	 Data: torch.Size([10, 384])	 Training Loss: 0.9414561986923218
Step: 204	 Data: torch.Size([10, 384])	 Training Loss: 1.0849283933639526
Step: 205	 Data: torch.Size([10, 356])	 Training Loss: 0.9475482702255249
Step: 206	 Data: torch.Size([10, 384])	 Training Loss: 0.9367542266845703
Step: 207	 Data: torch.Size([10, 384])	 Training Loss: 0.7938433289527893
Step: 208	 Data: torch.Size([10, 384])	 Training Loss: 0.8753859400749207
Step: 209	 Data: torch.Size([10, 384])	 Training Loss: 1.0307261943817139
Step: 210	 Data: torch.Size([10, 355])	 Training Loss: 0.9209075570106506
Step: 211	 Data: torch.Size([10, 384])	 Training Loss: 0.893146276473999
Step: 212	 Data: torch.Size([10, 384])	 Training Loss: 1.1095280647277832
Step: 213	 Data: torch.Size([10, 384])	 Training Loss: 0.9216259121894836
Step: 214	 Data: torch.Size([10, 384])	 Training Loss: 0.8631871342658997
Step: 215	 Data: torch.Size([10, 384])	 Training Loss: 0.8260050415992737
Step: 216	 Data: torch.Size([10, 384])	 Training Loss: 0.891537606716156
Step: 217	 Data: torch.Size([10, 384])	 Training Loss: 0.9168327450752258
Step: 218	 Data: torch.Size([10, 384])	 Training Loss: 0.9204652905464172
Step: 219	 Data: torch.Size([10, 384])	 Training Loss: 0.8593215942382812
Step: 220	 Data: torch.Size([10, 384])	 Training Loss: 0.9751883149147034
Step: 221	 Data: torch.Size([10, 384])	 Training Loss: 0.9197856187820435
Step: 222	 Data: torch.Size([10, 384])	 Training Loss: 0.9636409282684326
Step: 223	 Data: torch.Size([10, 384])	 Training Loss: 0.8940069079399109
Step: 224	 Data: torch.Size([10, 384])	 Training Loss: 0.9099674224853516
Step: 225	 Data: torch.Size([10, 384])	 Training Loss: 1.0796865224838257
Step: 226	 Data: torch.Size([10, 384])	 Training Loss: 0.9774333238601685
Step: 227	 Data: torch.Size([10, 384])	 Training Loss: 0.7755967378616333
Step: 228	 Data: torch.Size([10, 384])	 Training Loss: 0.9360216856002808
Step: 229	 Data: torch.Size([10, 384])	 Training Loss: 0.9516618847846985
Step: 230	 Data: torch.Size([10, 384])	 Training Loss: 0.7667211294174194
Step: 231	 Data: torch.Size([10, 384])	 Training Loss: 0.9103456735610962
Step: 232	 Data: torch.Size([10, 384])	 Training Loss: 0.8843767046928406
Step: 233	 Data: torch.Size([10, 384])	 Training Loss: 1.1626774072647095
Step: 234	 Data: torch.Size([10, 384])	 Training Loss: 0.9693931937217712
Step: 235	 Data: torch.Size([10, 384])	 Training Loss: 1.0218294858932495
Step: 236	 Data: torch.Size([10, 384])	 Training Loss: 0.9545045495033264
Step: 237	 Data: torch.Size([10, 384])	 Training Loss: 1.003520131111145
Step: 238	 Data: torch.Size([10, 384])	 Training Loss: 1.0280866622924805
Step: 239	 Data: torch.Size([10, 384])	 Training Loss: 0.9816295504570007
Step: 240	 Data: torch.Size([10, 384])	 Training Loss: 1.0671945810317993
Step: 241	 Data: torch.Size([10, 384])	 Training Loss: 0.9773513674736023
Step: 242	 Data: torch.Size([10, 384])	 Training Loss: 0.9848693609237671
Step: 243	 Data: torch.Size([10, 384])	 Training Loss: 0.8931615352630615
Step: 244	 Data: torch.Size([10, 384])	 Training Loss: 0.9627997279167175
Step: 245	 Data: torch.Size([10, 384])	 Training Loss: 1.1023575067520142
Step: 246	 Data: torch.Size([10, 384])	 Training Loss: 0.9592261910438538
Step: 247	 Data: torch.Size([10, 384])	 Training Loss: 1.01991868019104
Step: 248	 Data: torch.Size([10, 384])	 Training Loss: 1.0824553966522217
Step: 249	 Data: torch.Size([10, 340])	 Training Loss: 1.144053339958191
Step: 250	 Data: torch.Size([10, 384])	 Training Loss: 0.9840342402458191
Step: 251	 Data: torch.Size([10, 384])	 Training Loss: 0.852190375328064
Step: 252	 Data: torch.Size([10, 384])	 Training Loss: 1.0056843757629395
Step: 253	 Data: torch.Size([10, 384])	 Training Loss: 0.8635415434837341
Step: 254	 Data: torch.Size([10, 384])	 Training Loss: 0.9508841633796692
Step: 255	 Data: torch.Size([10, 384])	 Training Loss: 0.9412335753440857
Step: 256	 Data: torch.Size([10, 384])	 Training Loss: 0.9320817589759827
Step: 257	 Data: torch.Size([10, 384])	 Training Loss: 0.8914322257041931
Step: 258	 Data: torch.Size([10, 384])	 Training Loss: 0.9071047306060791
Step: 259	 Data: torch.Size([10, 384])	 Training Loss: 0.8930895924568176
Step: 260	 Data: torch.Size([10, 384])	 Training Loss: 0.8318667411804199
Step: 261	 Data: torch.Size([10, 384])	 Training Loss: 0.924026608467102
Step: 262	 Data: torch.Size([10, 384])	 Training Loss: 0.9256178140640259
Step: 263	 Data: torch.Size([10, 384])	 Training Loss: 0.8289827704429626
Step: 264	 Data: torch.Size([10, 384])	 Training Loss: 0.8503729104995728
Step: 265	 Data: torch.Size([10, 384])	 Training Loss: 0.9963988065719604
Step: 266	 Data: torch.Size([10, 384])	 Training Loss: 0.8743240833282471
Step: 267	 Data: torch.Size([10, 384])	 Training Loss: 0.9103641510009766
Step: 268	 Data: torch.Size([10, 384])	 Training Loss: 0.9843281507492065
Step: 269	 Data: torch.Size([10, 384])	 Training Loss: 0.9387442469596863
Step: 270	 Data: torch.Size([10, 384])	 Training Loss: 0.9065626859664917
Step: 271	 Data: torch.Size([10, 384])	 Training Loss: 1.0120761394500732
Step: 272	 Data: torch.Size([10, 384])	 Training Loss: 0.922561764717102
Step: 273	 Data: torch.Size([10, 384])	 Training Loss: 1.0146604776382446
Step: 274	 Data: torch.Size([10, 384])	 Training Loss: 0.9308866858482361
Step: 275	 Data: torch.Size([10, 384])	 Training Loss: 0.9750008583068848
Step: 276	 Data: torch.Size([10, 384])	 Training Loss: 0.9106271862983704
Step: 277	 Data: torch.Size([10, 384])	 Training Loss: 0.9469543099403381
Step: 278	 Data: torch.Size([10, 384])	 Training Loss: 0.9137581586837769
Step: 279	 Data: torch.Size([10, 384])	 Training Loss: 0.7967438101768494
Step: 280	 Data: torch.Size([10, 384])	 Training Loss: 1.0885581970214844
Step: 281	 Data: torch.Size([10, 384])	 Training Loss: 0.9276896715164185
Step: 282	 Data: torch.Size([10, 384])	 Training Loss: 0.8520937561988831
Step: 283	 Data: torch.Size([10, 384])	 Training Loss: 1.0459935665130615
Step: 284	 Data: torch.Size([10, 384])	 Training Loss: 0.8462852239608765
Step: 285	 Data: torch.Size([10, 384])	 Training Loss: 0.9902008771896362
Step: 286	 Data: torch.Size([10, 384])	 Training Loss: 0.9722994565963745
Step: 287	 Data: torch.Size([10, 384])	 Training Loss: 1.0083491802215576
Step: 288	 Data: torch.Size([10, 384])	 Training Loss: 0.9396430850028992
Step: 289	 Data: torch.Size([10, 384])	 Training Loss: 0.9110828042030334
Step: 290	 Data: torch.Size([10, 384])	 Training Loss: 0.9311222434043884
Step: 291	 Data: torch.Size([10, 384])	 Training Loss: 0.8033996224403381
Step: 292	 Data: torch.Size([10, 372])	 Training Loss: 0.8412756323814392
Step: 293	 Data: torch.Size([10, 384])	 Training Loss: 1.0392496585845947
Step: 294	 Data: torch.Size([10, 384])	 Training Loss: 0.8583235740661621
Step: 295	 Data: torch.Size([10, 384])	 Training Loss: 0.9271854162216187
Step: 296	 Data: torch.Size([10, 213])	 Training Loss: 1.0764539241790771
Step: 297	 Data: torch.Size([10, 384])	 Training Loss: 1.0107487440109253
Step: 298	 Data: torch.Size([10, 384])	 Training Loss: 0.8695833086967468
Step: 299	 Data: torch.Size([10, 384])	 Training Loss: 1.0358679294586182
Step: 300	 Data: torch.Size([10, 384])	 Training Loss: 1.078951120376587
Step: 301	 Data: torch.Size([10, 384])	 Training Loss: 0.8973910212516785
Step: 302	 Data: torch.Size([10, 384])	 Training Loss: 0.9344015121459961
Step: 303	 Data: torch.Size([10, 384])	 Training Loss: 0.8847843408584595
Step: 304	 Data: torch.Size([10, 384])	 Training Loss: 0.8789295554161072
Step: 305	 Data: torch.Size([10, 384])	 Training Loss: 1.078298807144165
Step: 306	 Data: torch.Size([10, 384])	 Training Loss: 0.9590928554534912
Step: 307	 Data: torch.Size([10, 384])	 Training Loss: 1.108092188835144
Step: 308	 Data: torch.Size([10, 384])	 Training Loss: 0.9785184860229492
Step: 309	 Data: torch.Size([10, 384])	 Training Loss: 0.9974116086959839
Step: 310	 Data: torch.Size([10, 384])	 Training Loss: 0.9824351668357849
Step: 311	 Data: torch.Size([10, 384])	 Training Loss: 0.8581722378730774
Step: 312	 Data: torch.Size([10, 384])	 Training Loss: 0.9259462356567383
Step: 313	 Data: torch.Size([10, 384])	 Training Loss: 0.9616811275482178
Step: 314	 Data: torch.Size([10, 384])	 Training Loss: 1.000535249710083
Step: 315	 Data: torch.Size([10, 384])	 Training Loss: 0.8275958895683289
Step: 316	 Data: torch.Size([10, 384])	 Training Loss: 0.8984296917915344
Step: 317	 Data: torch.Size([10, 384])	 Training Loss: 1.1403042078018188
Step: 318	 Data: torch.Size([10, 384])	 Training Loss: 0.9644725918769836
Step: 319	 Data: torch.Size([10, 384])	 Training Loss: 1.233066439628601
Step: 320	 Data: torch.Size([10, 384])	 Training Loss: 0.9917863607406616
Step: 321	 Data: torch.Size([10, 384])	 Training Loss: 1.148396372795105
Step: 322	 Data: torch.Size([10, 384])	 Training Loss: 0.9453877806663513
Step: 323	 Data: torch.Size([10, 384])	 Training Loss: 0.9002474546432495
Step: 324	 Data: torch.Size([10, 384])	 Training Loss: 0.8286827802658081
Step: 325	 Data: torch.Size([10, 384])	 Training Loss: 0.815655529499054
Step: 326	 Data: torch.Size([10, 384])	 Training Loss: 0.7997331619262695
Step: 327	 Data: torch.Size([10, 384])	 Training Loss: 1.128549337387085
Step: 328	 Data: torch.Size([10, 384])	 Training Loss: 1.1180229187011719
Step: 329	 Data: torch.Size([10, 384])	 Training Loss: 0.9480150938034058
Step: 330	 Data: torch.Size([10, 384])	 Training Loss: 0.7869499921798706
Step: 331	 Data: torch.Size([10, 384])	 Training Loss: 0.9991322159767151
Step: 332	 Data: torch.Size([10, 384])	 Training Loss: 0.9569903016090393
Step: 333	 Data: torch.Size([10, 384])	 Training Loss: 0.9717012643814087
Step: 334	 Data: torch.Size([10, 384])	 Training Loss: 0.828536331653595
Step: 335	 Data: torch.Size([10, 384])	 Training Loss: 0.8227951526641846
Step: 336	 Data: torch.Size([10, 384])	 Training Loss: 1.0915889739990234
Step: 337	 Data: torch.Size([10, 384])	 Training Loss: 1.046539545059204
Step: 338	 Data: torch.Size([10, 384])	 Training Loss: 0.9302242398262024
Step: 339	 Data: torch.Size([10, 384])	 Training Loss: 0.8141723275184631
Step: 340	 Data: torch.Size([10, 384])	 Training Loss: 0.8227822184562683
Step: 341	 Data: torch.Size([10, 384])	 Training Loss: 0.9723719358444214
Step: 342	 Data: torch.Size([10, 384])	 Training Loss: 1.0521401166915894
Step: 343	 Data: torch.Size([10, 384])	 Training Loss: 1.084359884262085
Step: 344	 Data: torch.Size([10, 384])	 Training Loss: 0.9884546399116516
Step: 345	 Data: torch.Size([10, 384])	 Training Loss: 0.9345885515213013
Step: 346	 Data: torch.Size([10, 384])	 Training Loss: 1.062584638595581
Step: 347	 Data: torch.Size([10, 384])	 Training Loss: 0.9536566734313965
Step: 348	 Data: torch.Size([10, 384])	 Training Loss: 0.8771710395812988
Step: 349	 Data: torch.Size([10, 384])	 Training Loss: 0.9037272334098816
Step: 350	 Data: torch.Size([10, 384])	 Training Loss: 0.8704416751861572
Step: 351	 Data: torch.Size([10, 384])	 Training Loss: 0.906373918056488
Step: 352	 Data: torch.Size([10, 384])	 Training Loss: 0.9692355990409851
Step: 353	 Data: torch.Size([10, 384])	 Training Loss: 0.9588748812675476
Step: 354	 Data: torch.Size([10, 384])	 Training Loss: 0.8671292066574097
Step: 355	 Data: torch.Size([10, 384])	 Training Loss: 1.0903736352920532
Step: 356	 Data: torch.Size([10, 384])	 Training Loss: 0.9807257056236267
Step: 357	 Data: torch.Size([10, 384])	 Training Loss: 1.0349154472351074
Step: 358	 Data: torch.Size([10, 384])	 Training Loss: 0.9651600122451782
Step: 359	 Data: torch.Size([10, 384])	 Training Loss: 0.9730122089385986
Step: 360	 Data: torch.Size([10, 384])	 Training Loss: 0.8223255276679993
Step: 361	 Data: torch.Size([10, 384])	 Training Loss: 0.8176840543746948
Step: 362	 Data: torch.Size([10, 384])	 Training Loss: 0.9324694871902466
Step: 363	 Data: torch.Size([10, 384])	 Training Loss: 0.9870285987854004
Step: 364	 Data: torch.Size([10, 384])	 Training Loss: 0.819661021232605
Step: 365	 Data: torch.Size([10, 384])	 Training Loss: 0.7797303199768066
Step: 366	 Data: torch.Size([10, 384])	 Training Loss: 0.8964068293571472
Step: 367	 Data: torch.Size([10, 384])	 Training Loss: 1.02255117893219
Step: 368	 Data: torch.Size([10, 384])	 Training Loss: 0.989096462726593
Step: 369	 Data: torch.Size([10, 384])	 Training Loss: 0.9125432372093201
Step: 370	 Data: torch.Size([10, 384])	 Training Loss: 0.8426428437232971
Step: 371	 Data: torch.Size([10, 384])	 Training Loss: 1.0044745206832886
Step: 372	 Data: torch.Size([10, 384])	 Training Loss: 0.958853006362915
Step: 373	 Data: torch.Size([10, 384])	 Training Loss: 0.872352659702301
Step: 374	 Data: torch.Size([10, 384])	 Training Loss: 0.8426092267036438
Step: 375	 Data: torch.Size([10, 384])	 Training Loss: 0.8774397969245911
Step: 376	 Data: torch.Size([10, 384])	 Training Loss: 0.9774901270866394
Step: 377	 Data: torch.Size([10, 384])	 Training Loss: 0.9096361994743347
Step: 378	 Data: torch.Size([10, 384])	 Training Loss: 0.8465248942375183
Step: 379	 Data: torch.Size([10, 384])	 Training Loss: 1.00783371925354
Step: 380	 Data: torch.Size([10, 384])	 Training Loss: 0.8712360858917236
Step: 381	 Data: torch.Size([10, 384])	 Training Loss: 0.8917855620384216
Step: 382	 Data: torch.Size([10, 384])	 Training Loss: 0.9321061968803406
Step: 383	 Data: torch.Size([10, 384])	 Training Loss: 0.8161385655403137
Step: 384	 Data: torch.Size([10, 384])	 Training Loss: 0.8365514278411865
Step: 385	 Data: torch.Size([10, 384])	 Training Loss: 0.9869844913482666
Step: 386	 Data: torch.Size([10, 384])	 Training Loss: 0.8547673225402832
Step: 387	 Data: torch.Size([10, 384])	 Training Loss: 0.9388895034790039
Step: 388	 Data: torch.Size([10, 384])	 Training Loss: 1.144456148147583
Step: 389	 Data: torch.Size([10, 384])	 Training Loss: 0.889348566532135
Step: 390	 Data: torch.Size([10, 384])	 Training Loss: 1.0975921154022217
Step: 391	 Data: torch.Size([10, 384])	 Training Loss: 0.9530195593833923
Step: 392	 Data: torch.Size([10, 384])	 Training Loss: 0.9144538640975952
Step: 393	 Data: torch.Size([10, 270])	 Training Loss: 0.8542576432228088
Step: 394	 Data: torch.Size([10, 384])	 Training Loss: 0.9416822195053101
Step: 395	 Data: torch.Size([10, 384])	 Training Loss: 0.888879120349884
Step: 396	 Data: torch.Size([10, 384])	 Training Loss: 0.8954590559005737
Step: 397	 Data: torch.Size([10, 384])	 Training Loss: 0.9466972351074219
Step: 398	 Data: torch.Size([10, 384])	 Training Loss: 0.9958630204200745
Step: 399	 Data: torch.Size([10, 384])	 Training Loss: 0.9771831035614014
Step: 400	 Data: torch.Size([10, 384])	 Training Loss: 0.9833171963691711
Step: 401	 Data: torch.Size([10, 384])	 Training Loss: 0.8322675228118896
Step: 402	 Data: torch.Size([10, 384])	 Training Loss: 0.9896504282951355
Step: 403	 Data: torch.Size([10, 384])	 Training Loss: 0.967257559299469
Step: 404	 Data: torch.Size([10, 384])	 Training Loss: 1.107696533203125
Step: 405	 Data: torch.Size([10, 384])	 Training Loss: 1.0069433450698853
Step: 406	 Data: torch.Size([10, 384])	 Training Loss: 0.8664833903312683
Step: 407	 Data: torch.Size([10, 384])	 Training Loss: 0.913231372833252
Step: 408	 Data: torch.Size([10, 384])	 Training Loss: 0.8203634023666382
Step: 409	 Data: torch.Size([10, 384])	 Training Loss: 0.8866264224052429
Step: 410	 Data: torch.Size([10, 384])	 Training Loss: 0.9028297066688538
Step: 411	 Data: torch.Size([10, 384])	 Training Loss: 1.0071947574615479
Step: 412	 Data: torch.Size([10, 384])	 Training Loss: 0.9381452202796936
Step: 413	 Data: torch.Size([10, 384])	 Training Loss: 0.963832676410675
Step: 414	 Data: torch.Size([10, 384])	 Training Loss: 0.8974223732948303
Step: 415	 Data: torch.Size([10, 384])	 Training Loss: 1.0369149446487427
Step: 416	 Data: torch.Size([10, 384])	 Training Loss: 0.9220028519630432
Step: 417	 Data: torch.Size([10, 384])	 Training Loss: 1.0181442499160767
Step: 418	 Data: torch.Size([10, 384])	 Training Loss: 0.9348297119140625
Step: 419	 Data: torch.Size([10, 384])	 Training Loss: 0.7982970476150513
Step: 420	 Data: torch.Size([10, 384])	 Training Loss: 0.8227263689041138
Step: 421	 Data: torch.Size([10, 384])	 Training Loss: 0.9080929160118103
Step: 422	 Data: torch.Size([10, 384])	 Training Loss: 0.8276367783546448
Step: 423	 Data: torch.Size([10, 384])	 Training Loss: 0.8360766768455505
Step: 424	 Data: torch.Size([10, 384])	 Training Loss: 0.897753119468689
Step: 425	 Data: torch.Size([10, 384])	 Training Loss: 0.8498252630233765
Step: 426	 Data: torch.Size([10, 384])	 Training Loss: 0.9852302670478821
Step: 427	 Data: torch.Size([10, 384])	 Training Loss: 0.881761908531189
Step: 428	 Data: torch.Size([10, 384])	 Training Loss: 0.866780161857605
Step: 429	 Data: torch.Size([10, 384])	 Training Loss: 0.9562034606933594
Step: 430	 Data: torch.Size([10, 384])	 Training Loss: 0.8383582830429077
Step: 431	 Data: torch.Size([10, 384])	 Training Loss: 0.9675958156585693
Step: 432	 Data: torch.Size([10, 384])	 Training Loss: 0.8648850917816162
Step: 433	 Data: torch.Size([10, 384])	 Training Loss: 0.9789555668830872
Step: 434	 Data: torch.Size([10, 384])	 Training Loss: 0.7613824009895325
Step: 435	 Data: torch.Size([10, 384])	 Training Loss: 0.8375505805015564
Step: 436	 Data: torch.Size([10, 384])	 Training Loss: 0.9912779927253723
Step: 437	 Data: torch.Size([10, 384])	 Training Loss: 0.9917897582054138
Step: 438	 Data: torch.Size([10, 384])	 Training Loss: 1.120551347732544
Step: 439	 Data: torch.Size([10, 384])	 Training Loss: 0.873129665851593
Step: 440	 Data: torch.Size([10, 384])	 Training Loss: 0.9254783987998962
Step: 441	 Data: torch.Size([10, 384])	 Training Loss: 1.0042698383331299
Step: 442	 Data: torch.Size([10, 384])	 Training Loss: 0.858328640460968
Step: 443	 Data: torch.Size([10, 384])	 Training Loss: 0.9251758456230164
Step: 444	 Data: torch.Size([10, 384])	 Training Loss: 1.0103546380996704
Step: 445	 Data: torch.Size([10, 384])	 Training Loss: 0.9755182862281799
Step: 446	 Data: torch.Size([10, 384])	 Training Loss: 0.978753387928009
Step: 447	 Data: torch.Size([10, 384])	 Training Loss: 0.8004284501075745
Step: 448	 Data: torch.Size([10, 384])	 Training Loss: 1.0809462070465088
Step: 449	 Data: torch.Size([10, 384])	 Training Loss: 0.8801289796829224
Step: 450	 Data: torch.Size([10, 384])	 Training Loss: 0.9326804876327515
Step: 451	 Data: torch.Size([10, 384])	 Training Loss: 0.8652388453483582
Step: 452	 Data: torch.Size([10, 384])	 Training Loss: 0.9279170036315918
Step: 453	 Data: torch.Size([10, 384])	 Training Loss: 1.0969475507736206
Step: 454	 Data: torch.Size([10, 384])	 Training Loss: 0.9776362180709839
Step: 455	 Data: torch.Size([10, 384])	 Training Loss: 0.8828660845756531
Step: 456	 Data: torch.Size([10, 384])	 Training Loss: 0.9548500180244446
Step: 457	 Data: torch.Size([10, 384])	 Training Loss: 0.9235143065452576
Step: 458	 Data: torch.Size([10, 384])	 Training Loss: 1.0363272428512573
Step: 459	 Data: torch.Size([10, 384])	 Training Loss: 0.9215764999389648
Step: 460	 Data: torch.Size([10, 384])	 Training Loss: 0.968567967414856
Step: 461	 Data: torch.Size([10, 384])	 Training Loss: 1.0786529779434204
Step: 462	 Data: torch.Size([10, 384])	 Training Loss: 0.8870071768760681
Step: 463	 Data: torch.Size([10, 306])	 Training Loss: 1.057765007019043
Step: 464	 Data: torch.Size([10, 249])	 Training Loss: 0.969355583190918
Step: 465	 Data: torch.Size([10, 384])	 Training Loss: 0.9494059681892395
Step: 466	 Data: torch.Size([10, 384])	 Training Loss: 0.9658960103988647
Step: 467	 Data: torch.Size([10, 384])	 Training Loss: 1.0552785396575928
Step: 468	 Data: torch.Size([10, 384])	 Training Loss: 0.9940080642700195
Step: 469	 Data: torch.Size([10, 384])	 Training Loss: 0.9994833469390869
Step: 470	 Data: torch.Size([10, 384])	 Training Loss: 0.8878084421157837
Step: 471	 Data: torch.Size([10, 384])	 Training Loss: 0.8756673336029053
Step: 472	 Data: torch.Size([10, 384])	 Training Loss: 1.0712834596633911
Step: 473	 Data: torch.Size([10, 384])	 Training Loss: 1.012648344039917
Step: 474	 Data: torch.Size([10, 384])	 Training Loss: 0.9412614703178406
Step: 475	 Data: torch.Size([10, 384])	 Training Loss: 1.1220802068710327
Step: 476	 Data: torch.Size([10, 384])	 Training Loss: 0.8396620750427246
Step: 477	 Data: torch.Size([10, 384])	 Training Loss: 0.9603275656700134
Step: 478	 Data: torch.Size([10, 384])	 Training Loss: 0.9693496227264404
Step: 479	 Data: torch.Size([10, 384])	 Training Loss: 0.9811939001083374
Step: 480	 Data: torch.Size([10, 384])	 Training Loss: 0.7902292013168335
Step: 481	 Data: torch.Size([10, 384])	 Training Loss: 1.016545057296753
Step: 482	 Data: torch.Size([10, 384])	 Training Loss: 1.035290002822876
Step: 483	 Data: torch.Size([10, 384])	 Training Loss: 0.8292611241340637
Step: 484	 Data: torch.Size([10, 384])	 Training Loss: 0.8399533629417419
Step: 485	 Data: torch.Size([10, 384])	 Training Loss: 0.9866479635238647
Step: 486	 Data: torch.Size([10, 384])	 Training Loss: 0.8097655177116394
Step: 487	 Data: torch.Size([10, 384])	 Training Loss: 0.9795506596565247
Step: 488	 Data: torch.Size([10, 384])	 Training Loss: 0.893669068813324
Step: 489	 Data: torch.Size([10, 384])	 Training Loss: 0.8366379141807556
Step: 490	 Data: torch.Size([10, 384])	 Training Loss: 0.7665703296661377
Step: 491	 Data: torch.Size([10, 384])	 Training Loss: 0.8484086990356445
Step: 492	 Data: torch.Size([10, 384])	 Training Loss: 0.8956118226051331
Step: 493	 Data: torch.Size([10, 384])	 Training Loss: 0.8129963278770447
Step: 494	 Data: torch.Size([10, 384])	 Training Loss: 1.0573458671569824
Step: 495	 Data: torch.Size([10, 384])	 Training Loss: 0.9458156228065491
Step: 496	 Data: torch.Size([10, 384])	 Training Loss: 1.0217574834823608
Step: 497	 Data: torch.Size([10, 384])	 Training Loss: 1.0077404975891113
Step: 498	 Data: torch.Size([10, 384])	 Training Loss: 0.8977356553077698
Step: 499	 Data: torch.Size([10, 384])	 Training Loss: 0.8675763607025146
Step: 500	 Data: torch.Size([10, 384])	 Training Loss: 0.867466151714325
Step: 501	 Data: torch.Size([10, 384])	 Training Loss: 0.9437245726585388
Step: 502	 Data: torch.Size([10, 384])	 Training Loss: 0.8299342393875122
Step: 503	 Data: torch.Size([10, 384])	 Training Loss: 0.8561453223228455
Step: 504	 Data: torch.Size([10, 384])	 Training Loss: 1.0321635007858276
Step: 505	 Data: torch.Size([10, 384])	 Training Loss: 0.7973440885543823
Step: 506	 Data: torch.Size([10, 384])	 Training Loss: 0.8164517283439636
Step: 507	 Data: torch.Size([10, 384])	 Training Loss: 0.9536519646644592
Step: 508	 Data: torch.Size([10, 384])	 Training Loss: 0.8721225261688232
Step: 509	 Data: torch.Size([10, 384])	 Training Loss: 0.9626244902610779
Step: 510	 Data: torch.Size([10, 384])	 Training Loss: 0.7629615664482117
Step: 511	 Data: torch.Size([10, 384])	 Training Loss: 1.1724401712417603
Step: 512	 Data: torch.Size([10, 384])	 Training Loss: 1.181750774383545
Step: 513	 Data: torch.Size([10, 384])	 Training Loss: 0.871141791343689
Step: 514	 Data: torch.Size([10, 302])	 Training Loss: 0.8422176241874695
Step: 515	 Data: torch.Size([10, 384])	 Training Loss: 1.0644032955169678
Step: 516	 Data: torch.Size([10, 384])	 Training Loss: 0.912446916103363
Step: 517	 Data: torch.Size([10, 384])	 Training Loss: 0.892058253288269
Step: 518	 Data: torch.Size([10, 384])	 Training Loss: 1.0261731147766113
Step: 519	 Data: torch.Size([10, 384])	 Training Loss: 0.7840471863746643
Step: 520	 Data: torch.Size([10, 384])	 Training Loss: 0.9576780796051025
Step: 521	 Data: torch.Size([10, 384])	 Training Loss: 1.1103769540786743
Step: 522	 Data: torch.Size([10, 384])	 Training Loss: 0.921789824962616
Step: 523	 Data: torch.Size([10, 384])	 Training Loss: 1.0008465051651
Step: 524	 Data: torch.Size([10, 384])	 Training Loss: 0.9691056609153748
Step: 525	 Data: torch.Size([10, 384])	 Training Loss: 0.967216968536377
Step: 526	 Data: torch.Size([10, 384])	 Training Loss: 0.8381000757217407
Step: 527	 Data: torch.Size([10, 384])	 Training Loss: 0.859462320804596
Step: 528	 Data: torch.Size([10, 384])	 Training Loss: 0.896133542060852
Step: 529	 Data: torch.Size([10, 384])	 Training Loss: 0.9806922078132629
Step: 530	 Data: torch.Size([10, 384])	 Training Loss: 0.9969549179077148
Step: 531	 Data: torch.Size([10, 384])	 Training Loss: 0.8055644631385803
Step: 532	 Data: torch.Size([10, 384])	 Training Loss: 1.068142294883728
Step: 533	 Data: torch.Size([10, 384])	 Training Loss: 0.9551088809967041
Step: 534	 Data: torch.Size([10, 384])	 Training Loss: 0.87920743227005
Step: 535	 Data: torch.Size([10, 384])	 Training Loss: 0.8920320272445679
Step: 536	 Data: torch.Size([10, 384])	 Training Loss: 0.904862642288208
Step: 537	 Data: torch.Size([10, 384])	 Training Loss: 1.0266063213348389
Step: 538	 Data: torch.Size([10, 384])	 Training Loss: 0.7981400489807129
Step: 539	 Data: torch.Size([10, 384])	 Training Loss: 0.9406665563583374
Step: 540	 Data: torch.Size([10, 384])	 Training Loss: 0.9475961923599243
Step: 541	 Data: torch.Size([10, 384])	 Training Loss: 0.8760805130004883
Step: 542	 Data: torch.Size([10, 384])	 Training Loss: 0.8775372505187988
Step: 543	 Data: torch.Size([10, 384])	 Training Loss: 1.0132994651794434
Step: 544	 Data: torch.Size([10, 384])	 Training Loss: 0.8689221739768982
Step: 545	 Data: torch.Size([10, 384])	 Training Loss: 0.8649895787239075
Step: 546	 Data: torch.Size([10, 384])	 Training Loss: 0.8425110578536987
Step: 547	 Data: torch.Size([10, 384])	 Training Loss: 0.9503932595252991
Step: 548	 Data: torch.Size([10, 384])	 Training Loss: 0.9207993745803833
Step: 549	 Data: torch.Size([10, 384])	 Training Loss: 0.9757429957389832
Step: 550	 Data: torch.Size([10, 384])	 Training Loss: 0.9495164752006531
Step: 551	 Data: torch.Size([10, 384])	 Training Loss: 1.1615257263183594
Step: 552	 Data: torch.Size([10, 384])	 Training Loss: 0.8471314907073975
Step: 553	 Data: torch.Size([10, 384])	 Training Loss: 0.8881575465202332
Step: 554	 Data: torch.Size([10, 384])	 Training Loss: 0.9054583311080933
Step: 555	 Data: torch.Size([10, 384])	 Training Loss: 0.960588812828064
Step: 556	 Data: torch.Size([10, 384])	 Training Loss: 1.0488137006759644
Step: 557	 Data: torch.Size([10, 384])	 Training Loss: 0.9193212985992432
Step: 558	 Data: torch.Size([10, 384])	 Training Loss: 1.0096145868301392
Step: 559	 Data: torch.Size([10, 384])	 Training Loss: 1.136055588722229
Step: 560	 Data: torch.Size([10, 384])	 Training Loss: 0.9161662459373474
Step: 561	 Data: torch.Size([10, 384])	 Training Loss: 0.9772803783416748
Step: 562	 Data: torch.Size([10, 384])	 Training Loss: 0.8736284971237183
Step: 563	 Data: torch.Size([10, 384])	 Training Loss: 1.0757777690887451
Step: 564	 Data: torch.Size([10, 384])	 Training Loss: 0.8687345385551453
Step: 565	 Data: torch.Size([10, 384])	 Training Loss: 1.0639125108718872
Step: 566	 Data: torch.Size([10, 374])	 Training Loss: 0.7376851439476013
Step: 567	 Data: torch.Size([10, 384])	 Training Loss: 1.0407406091690063
Step: 568	 Data: torch.Size([10, 384])	 Training Loss: 1.0012474060058594
Step: 569	 Data: torch.Size([10, 384])	 Training Loss: 0.8211162686347961
Step: 570	 Data: torch.Size([10, 384])	 Training Loss: 0.8837867975234985
Step: 571	 Data: torch.Size([10, 384])	 Training Loss: 0.7770750522613525
Step: 572	 Data: torch.Size([10, 384])	 Training Loss: 0.8375404477119446
Step: 573	 Data: torch.Size([10, 384])	 Training Loss: 0.7783061861991882
Step: 574	 Data: torch.Size([10, 384])	 Training Loss: 0.9679237008094788
Step: 575	 Data: torch.Size([10, 384])	 Training Loss: 0.8006536364555359
Step: 576	 Data: torch.Size([10, 384])	 Training Loss: 1.1152677536010742
Step: 577	 Data: torch.Size([10, 384])	 Training Loss: 0.8529267311096191
Step: 578	 Data: torch.Size([10, 384])	 Training Loss: 0.7350051999092102
Step: 579	 Data: torch.Size([10, 384])	 Training Loss: 1.0801068544387817
Step: 580	 Data: torch.Size([10, 384])	 Training Loss: 0.9879289865493774
Step: 581	 Data: torch.Size([10, 384])	 Training Loss: 0.865005373954773
Step: 582	 Data: torch.Size([10, 359])	 Training Loss: 1.0301867723464966
Step: 583	 Data: torch.Size([10, 287])	 Training Loss: 1.0169636011123657
Step: 584	 Data: torch.Size([10, 384])	 Training Loss: 0.8422993421554565
Step: 585	 Data: torch.Size([10, 384])	 Training Loss: 0.7814998626708984
Step: 586	 Data: torch.Size([10, 384])	 Training Loss: 0.9446751475334167
Step: 587	 Data: torch.Size([10, 384])	 Training Loss: 0.863735556602478
Step: 588	 Data: torch.Size([10, 384])	 Training Loss: 0.8837221264839172
Step: 589	 Data: torch.Size([10, 384])	 Training Loss: 0.8583282828330994
Step: 590	 Data: torch.Size([10, 384])	 Training Loss: 0.9527510404586792
Step: 591	 Data: torch.Size([10, 384])	 Training Loss: 0.7956514358520508
Step: 592	 Data: torch.Size([10, 384])	 Training Loss: 0.9693264961242676
Step: 593	 Data: torch.Size([10, 384])	 Training Loss: 0.8538991212844849
Step: 594	 Data: torch.Size([10, 384])	 Training Loss: 1.0463725328445435
Step: 595	 Data: torch.Size([10, 384])	 Training Loss: 0.8821424245834351
Step: 596	 Data: torch.Size([10, 384])	 Training Loss: 0.8471594452857971
Step: 597	 Data: torch.Size([10, 384])	 Training Loss: 0.8675746321678162
Step: 598	 Data: torch.Size([10, 384])	 Training Loss: 0.9083884358406067
Step: 599	 Data: torch.Size([10, 384])	 Training Loss: 0.957537829875946
