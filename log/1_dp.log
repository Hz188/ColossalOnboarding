[2024-05-07 09:30:50,287] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-05-07 09:30:50,288] torch.distributed.run: [WARNING] 
[2024-05-07 09:30:50,288] torch.distributed.run: [WARNING] *****************************************
[2024-05-07 09:30:50,288] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-07 09:30:50,288] torch.distributed.run: [WARNING] *****************************************
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:36031 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:36031 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:36031 (errno: 22 - Invalid argument).
====================initialize the distributed env====================
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.18s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:12<00:12, 12.49s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.64s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  8.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.20s/it]
====================get the model with lora====================
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.95s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.62s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.64s/it]
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
====================Use distributed data parallel====================
====================get the dataset====================
====================get the dataloader====================
====================start train====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Step: 1	 Data: torch.Size([10, 384])	 Training Loss: 1.0071995258331299
Step: 2	 Data: torch.Size([10, 384])	 Training Loss: 1.045508861541748
Step: 3	 Data: torch.Size([10, 384])	 Training Loss: 1.1251661777496338
Step: 4	 Data: torch.Size([10, 384])	 Training Loss: 1.07790207862854
Step: 5	 Data: torch.Size([10, 384])	 Training Loss: 1.0075218677520752
Step: 6	 Data: torch.Size([10, 384])	 Training Loss: 1.14442777633667
Step: 7	 Data: torch.Size([10, 384])	 Training Loss: 1.0274392366409302
Step: 8	 Data: torch.Size([10, 384])	 Training Loss: 1.220910668373108
Step: 9	 Data: torch.Size([10, 384])	 Training Loss: 1.0824288129806519
Step: 10	 Data: torch.Size([10, 384])	 Training Loss: 1.086726427078247
Step: 11	 Data: torch.Size([10, 384])	 Training Loss: 1.0137814283370972
Step: 12	 Data: torch.Size([10, 384])	 Training Loss: 1.0502893924713135
Step: 13	 Data: torch.Size([10, 384])	 Training Loss: 1.0890092849731445
Step: 14	 Data: torch.Size([10, 384])	 Training Loss: 1.2321075201034546
Step: 15	 Data: torch.Size([10, 384])	 Training Loss: 1.0377426147460938
Step: 16	 Data: torch.Size([10, 384])	 Training Loss: 1.124925136566162
Step: 17	 Data: torch.Size([10, 384])	 Training Loss: 1.1544510126113892
Step: 18	 Data: torch.Size([10, 384])	 Training Loss: 1.0534026622772217
Step: 19	 Data: torch.Size([10, 384])	 Training Loss: 1.2128088474273682
Step: 20	 Data: torch.Size([10, 384])	 Training Loss: 1.0158534049987793
Step: 21	 Data: torch.Size([10, 384])	 Training Loss: 1.0227386951446533
Step: 22	 Data: torch.Size([10, 384])	 Training Loss: 1.0416268110275269
Step: 23	 Data: torch.Size([10, 384])	 Training Loss: 1.1335524320602417
Step: 24	 Data: torch.Size([10, 384])	 Training Loss: 1.1642253398895264
Step: 25	 Data: torch.Size([10, 384])	 Training Loss: 0.9762818813323975
Step: 26	 Data: torch.Size([10, 384])	 Training Loss: 0.9520187377929688
Step: 27	 Data: torch.Size([10, 384])	 Training Loss: 1.2121622562408447
Step: 28	 Data: torch.Size([10, 384])	 Training Loss: 1.104995608329773
Step: 29	 Data: torch.Size([10, 384])	 Training Loss: 1.1103719472885132
Step: 30	 Data: torch.Size([10, 384])	 Training Loss: 0.9710512757301331
Step: 31	 Data: torch.Size([10, 384])	 Training Loss: 1.1122163534164429
Step: 32	 Data: torch.Size([10, 384])	 Training Loss: 1.110839605331421
Step: 33	 Data: torch.Size([10, 384])	 Training Loss: 1.0161017179489136
Step: 34	 Data: torch.Size([10, 384])	 Training Loss: 0.8907955288887024
Step: 35	 Data: torch.Size([10, 384])	 Training Loss: 1.0209875106811523
Step: 36	 Data: torch.Size([10, 384])	 Training Loss: 1.0483225584030151
Step: 37	 Data: torch.Size([10, 384])	 Training Loss: 1.0969021320343018
Step: 38	 Data: torch.Size([10, 384])	 Training Loss: 0.9490005373954773
Step: 39	 Data: torch.Size([10, 384])	 Training Loss: 0.9956648945808411
Step: 40	 Data: torch.Size([10, 384])	 Training Loss: 1.0217444896697998
Step: 41	 Data: torch.Size([10, 384])	 Training Loss: 1.1545448303222656
Step: 42	 Data: torch.Size([10, 384])	 Training Loss: 0.9956126809120178
Step: 43	 Data: torch.Size([10, 384])	 Training Loss: 1.0812994241714478
Step: 44	 Data: torch.Size([10, 384])	 Training Loss: 1.2309112548828125
Step: 45	 Data: torch.Size([10, 384])	 Training Loss: 1.0820317268371582
Step: 46	 Data: torch.Size([10, 384])	 Training Loss: 0.9615752100944519
Step: 47	 Data: torch.Size([10, 384])	 Training Loss: 0.9651999473571777
Step: 48	 Data: torch.Size([10, 384])	 Training Loss: 1.1911842823028564
Step: 49	 Data: torch.Size([10, 384])	 Training Loss: 1.1346439123153687
Step: 50	 Data: torch.Size([10, 384])	 Training Loss: 1.1865955591201782
Step: 51	 Data: torch.Size([10, 384])	 Training Loss: 0.9997447729110718
Step: 52	 Data: torch.Size([10, 384])	 Training Loss: 1.005481243133545
Step: 53	 Data: torch.Size([10, 384])	 Training Loss: 1.0804810523986816
Step: 54	 Data: torch.Size([10, 384])	 Training Loss: 1.0613621473312378
Step: 55	 Data: torch.Size([10, 384])	 Training Loss: 0.9652822613716125
Step: 56	 Data: torch.Size([10, 384])	 Training Loss: 1.1041927337646484
Step: 57	 Data: torch.Size([10, 384])	 Training Loss: 0.9603452682495117
Step: 58	 Data: torch.Size([10, 384])	 Training Loss: 0.8884717226028442
Step: 59	 Data: torch.Size([10, 384])	 Training Loss: 1.1158868074417114
Step: 60	 Data: torch.Size([10, 384])	 Training Loss: 1.1066004037857056
Step: 61	 Data: torch.Size([10, 384])	 Training Loss: 0.9414944052696228
Step: 62	 Data: torch.Size([10, 384])	 Training Loss: 1.17756986618042
Step: 63	 Data: torch.Size([10, 384])	 Training Loss: 1.0586652755737305
Step: 64	 Data: torch.Size([10, 384])	 Training Loss: 0.9930362701416016
Step: 65	 Data: torch.Size([10, 384])	 Training Loss: 0.9822348356246948
Step: 66	 Data: torch.Size([10, 384])	 Training Loss: 1.0086681842803955
Step: 67	 Data: torch.Size([10, 384])	 Training Loss: 1.013890266418457
Step: 68	 Data: torch.Size([10, 384])	 Training Loss: 1.1459226608276367
Step: 69	 Data: torch.Size([10, 384])	 Training Loss: 1.1719658374786377
Step: 70	 Data: torch.Size([10, 384])	 Training Loss: 0.9293272495269775
Step: 71	 Data: torch.Size([10, 384])	 Training Loss: 0.94538813829422
Step: 72	 Data: torch.Size([10, 350])	 Training Loss: 1.4283896684646606
Step: 73	 Data: torch.Size([10, 384])	 Training Loss: 0.9293969869613647
Step: 74	 Data: torch.Size([10, 384])	 Training Loss: 1.0660558938980103
Step: 75	 Data: torch.Size([10, 384])	 Training Loss: 0.9784712195396423
Step: 76	 Data: torch.Size([10, 384])	 Training Loss: 0.862473726272583
Step: 77	 Data: torch.Size([10, 384])	 Training Loss: 1.1111279726028442
Step: 78	 Data: torch.Size([10, 384])	 Training Loss: 1.0234298706054688
Step: 79	 Data: torch.Size([10, 384])	 Training Loss: 1.23151695728302
Step: 80	 Data: torch.Size([10, 384])	 Training Loss: 1.0607752799987793
Step: 81	 Data: torch.Size([10, 384])	 Training Loss: 1.0325701236724854
Step: 82	 Data: torch.Size([10, 384])	 Training Loss: 1.0638527870178223
Step: 83	 Data: torch.Size([10, 384])	 Training Loss: 1.039678692817688
Step: 84	 Data: torch.Size([10, 384])	 Training Loss: 0.861434817314148
Step: 85	 Data: torch.Size([10, 384])	 Training Loss: 0.9647151231765747
Step: 86	 Data: torch.Size([10, 384])	 Training Loss: 1.1019680500030518
Step: 87	 Data: torch.Size([10, 384])	 Training Loss: 1.0229805707931519
Step: 88	 Data: torch.Size([10, 384])	 Training Loss: 0.879732072353363
Step: 89	 Data: torch.Size([10, 384])	 Training Loss: 1.0758826732635498
Step: 90	 Data: torch.Size([10, 384])	 Training Loss: 1.0474382638931274
Step: 91	 Data: torch.Size([10, 384])	 Training Loss: 0.899707555770874
Step: 92	 Data: torch.Size([10, 384])	 Training Loss: 0.8839997053146362
Step: 93	 Data: torch.Size([10, 384])	 Training Loss: 0.9972538948059082
Step: 94	 Data: torch.Size([10, 384])	 Training Loss: 1.0963164567947388
Step: 95	 Data: torch.Size([10, 384])	 Training Loss: 0.9556711912155151
Step: 96	 Data: torch.Size([10, 384])	 Training Loss: 0.8927141427993774
Step: 97	 Data: torch.Size([10, 384])	 Training Loss: 1.0490269660949707
Step: 98	 Data: torch.Size([10, 384])	 Training Loss: 0.9106037616729736
Step: 99	 Data: torch.Size([10, 384])	 Training Loss: 0.9788323640823364
Step: 100	 Data: torch.Size([10, 384])	 Training Loss: 1.1384520530700684
Step: 101	 Data: torch.Size([10, 384])	 Training Loss: 0.960747480392456
Step: 102	 Data: torch.Size([10, 384])	 Training Loss: 0.9694739580154419
Step: 103	 Data: torch.Size([10, 384])	 Training Loss: 0.995771586894989
Step: 104	 Data: torch.Size([10, 384])	 Training Loss: 0.9369766712188721
Step: 105	 Data: torch.Size([10, 384])	 Training Loss: 0.9819363355636597
Step: 106	 Data: torch.Size([10, 384])	 Training Loss: 1.1110788583755493
Step: 107	 Data: torch.Size([10, 384])	 Training Loss: 0.9311632513999939
Step: 108	 Data: torch.Size([10, 384])	 Training Loss: 0.9040194153785706
Step: 109	 Data: torch.Size([10, 384])	 Training Loss: 0.9984275102615356
Step: 110	 Data: torch.Size([10, 384])	 Training Loss: 0.9107109308242798
Step: 111	 Data: torch.Size([10, 384])	 Training Loss: 1.1960170269012451
Step: 112	 Data: torch.Size([10, 384])	 Training Loss: 1.1897246837615967
Step: 113	 Data: torch.Size([10, 384])	 Training Loss: 1.0595823526382446
Step: 114	 Data: torch.Size([10, 384])	 Training Loss: 0.9701452851295471
Step: 115	 Data: torch.Size([10, 384])	 Training Loss: 0.8887633085250854
Step: 116	 Data: torch.Size([10, 384])	 Training Loss: 0.9124947786331177
Step: 117	 Data: torch.Size([10, 384])	 Training Loss: 0.8908146619796753
Step: 118	 Data: torch.Size([10, 384])	 Training Loss: 0.9348012208938599
Step: 119	 Data: torch.Size([10, 384])	 Training Loss: 1.314069151878357
Step: 120	 Data: torch.Size([10, 384])	 Training Loss: 0.8677892684936523
Step: 121	 Data: torch.Size([10, 307])	 Training Loss: 1.071420669555664
Step: 122	 Data: torch.Size([10, 384])	 Training Loss: 1.1275774240493774
Step: 123	 Data: torch.Size([10, 384])	 Training Loss: 0.9706246256828308
Step: 124	 Data: torch.Size([10, 384])	 Training Loss: 0.8592559099197388
Step: 125	 Data: torch.Size([10, 384])	 Training Loss: 0.8798366785049438
Step: 126	 Data: torch.Size([10, 384])	 Training Loss: 0.9084166884422302
Step: 127	 Data: torch.Size([10, 384])	 Training Loss: 1.0370794534683228
Step: 128	 Data: torch.Size([10, 384])	 Training Loss: 0.8317905068397522
Step: 129	 Data: torch.Size([10, 384])	 Training Loss: 1.0767956972122192
Step: 130	 Data: torch.Size([10, 384])	 Training Loss: 0.9651537537574768
Step: 131	 Data: torch.Size([10, 384])	 Training Loss: 0.962736189365387
Step: 132	 Data: torch.Size([10, 384])	 Training Loss: 0.9525055885314941
Step: 133	 Data: torch.Size([10, 384])	 Training Loss: 0.9916165471076965
Step: 134	 Data: torch.Size([10, 384])	 Training Loss: 1.0576916933059692
Step: 135	 Data: torch.Size([10, 384])	 Training Loss: 0.9748116135597229
Step: 136	 Data: torch.Size([10, 384])	 Training Loss: 0.9292078018188477
Step: 137	 Data: torch.Size([10, 384])	 Training Loss: 1.0534383058547974
Step: 138	 Data: torch.Size([10, 384])	 Training Loss: 0.9157047271728516
Step: 139	 Data: torch.Size([10, 384])	 Training Loss: 0.9990760087966919
Step: 140	 Data: torch.Size([10, 384])	 Training Loss: 0.9569662809371948
Step: 141	 Data: torch.Size([10, 384])	 Training Loss: 0.9837955832481384
Step: 142	 Data: torch.Size([10, 384])	 Training Loss: 0.9663692116737366
Step: 143	 Data: torch.Size([10, 384])	 Training Loss: 1.0068904161453247
Step: 144	 Data: torch.Size([10, 384])	 Training Loss: 1.0077455043792725
Step: 145	 Data: torch.Size([10, 384])	 Training Loss: 0.9457079172134399
Step: 146	 Data: torch.Size([10, 384])	 Training Loss: 1.0033042430877686
Step: 147	 Data: torch.Size([10, 384])	 Training Loss: 0.9821085929870605
Step: 148	 Data: torch.Size([10, 384])	 Training Loss: 0.9317935109138489
Step: 149	 Data: torch.Size([10, 384])	 Training Loss: 0.8985684514045715
Step: 150	 Data: torch.Size([10, 384])	 Training Loss: 0.9670923948287964
Step: 151	 Data: torch.Size([10, 384])	 Training Loss: 1.0521862506866455
Step: 152	 Data: torch.Size([10, 384])	 Training Loss: 0.8936581611633301
Step: 153	 Data: torch.Size([10, 384])	 Training Loss: 1.1085566282272339
Step: 154	 Data: torch.Size([10, 384])	 Training Loss: 1.0236488580703735
Step: 155	 Data: torch.Size([10, 384])	 Training Loss: 0.9304463267326355
Step: 156	 Data: torch.Size([10, 384])	 Training Loss: 0.8396143913269043
Step: 157	 Data: torch.Size([10, 384])	 Training Loss: 0.8584147691726685
Step: 158	 Data: torch.Size([10, 384])	 Training Loss: 0.978503942489624
Step: 159	 Data: torch.Size([10, 384])	 Training Loss: 1.0543290376663208
Step: 160	 Data: torch.Size([10, 384])	 Training Loss: 0.8692168593406677
Step: 161	 Data: torch.Size([10, 384])	 Training Loss: 1.0348396301269531
Step: 162	 Data: torch.Size([10, 384])	 Training Loss: 0.9997417330741882
Step: 163	 Data: torch.Size([10, 384])	 Training Loss: 0.9821663498878479
Step: 164	 Data: torch.Size([10, 384])	 Training Loss: 0.9494694471359253
Step: 165	 Data: torch.Size([10, 384])	 Training Loss: 0.905706524848938
Step: 166	 Data: torch.Size([10, 384])	 Training Loss: 1.0800834894180298
Step: 167	 Data: torch.Size([10, 384])	 Training Loss: 0.9235252141952515
Step: 168	 Data: torch.Size([10, 384])	 Training Loss: 1.0212751626968384
Step: 169	 Data: torch.Size([10, 384])	 Training Loss: 0.9639043807983398
Step: 170	 Data: torch.Size([10, 384])	 Training Loss: 1.0718674659729004
Step: 171	 Data: torch.Size([10, 384])	 Training Loss: 0.9120437502861023
Step: 172	 Data: torch.Size([10, 384])	 Training Loss: 0.8478811979293823
Step: 173	 Data: torch.Size([10, 384])	 Training Loss: 0.9151408672332764
Step: 174	 Data: torch.Size([10, 384])	 Training Loss: 0.9018621444702148
Step: 175	 Data: torch.Size([10, 384])	 Training Loss: 1.0375304222106934
Step: 176	 Data: torch.Size([10, 384])	 Training Loss: 0.9510921239852905
Step: 177	 Data: torch.Size([10, 384])	 Training Loss: 0.9917939901351929
Step: 178	 Data: torch.Size([10, 384])	 Training Loss: 0.9013274908065796
Step: 179	 Data: torch.Size([10, 384])	 Training Loss: 0.8358438611030579
Step: 180	 Data: torch.Size([10, 384])	 Training Loss: 1.0480470657348633
Step: 181	 Data: torch.Size([10, 384])	 Training Loss: 0.7367936372756958
Step: 182	 Data: torch.Size([10, 384])	 Training Loss: 1.0799978971481323
Step: 183	 Data: torch.Size([10, 384])	 Training Loss: 0.8633543848991394
Step: 184	 Data: torch.Size([10, 384])	 Training Loss: 0.9484636783599854
Step: 185	 Data: torch.Size([10, 384])	 Training Loss: 0.8499243259429932
Step: 186	 Data: torch.Size([10, 384])	 Training Loss: 0.9861167669296265
Step: 187	 Data: torch.Size([10, 384])	 Training Loss: 0.8676280379295349
Step: 188	 Data: torch.Size([10, 384])	 Training Loss: 0.9685808420181274
Step: 189	 Data: torch.Size([10, 384])	 Training Loss: 0.928760290145874
Step: 190	 Data: torch.Size([10, 384])	 Training Loss: 1.0979572534561157
Step: 191	 Data: torch.Size([10, 384])	 Training Loss: 0.8905272483825684
Step: 192	 Data: torch.Size([10, 384])	 Training Loss: 1.0066708326339722
Step: 193	 Data: torch.Size([10, 384])	 Training Loss: 0.9362062215805054
Step: 194	 Data: torch.Size([10, 384])	 Training Loss: 0.8796104192733765
Step: 195	 Data: torch.Size([10, 384])	 Training Loss: 0.9395251870155334
Step: 196	 Data: torch.Size([10, 384])	 Training Loss: 0.9152512550354004
Step: 197	 Data: torch.Size([10, 384])	 Training Loss: 0.8397629857063293
Step: 198	 Data: torch.Size([10, 384])	 Training Loss: 1.0155586004257202
Step: 199	 Data: torch.Size([10, 384])	 Training Loss: 1.0064177513122559
Step: 200	 Data: torch.Size([10, 384])	 Training Loss: 0.9034661650657654
Step: 201	 Data: torch.Size([10, 384])	 Training Loss: 0.9711538553237915
Step: 202	 Data: torch.Size([10, 384])	 Training Loss: 0.899389386177063
Step: 203	 Data: torch.Size([10, 384])	 Training Loss: 1.00657320022583
Step: 204	 Data: torch.Size([10, 384])	 Training Loss: 0.9764725565910339
Step: 205	 Data: torch.Size([10, 384])	 Training Loss: 0.9954811930656433
Step: 206	 Data: torch.Size([10, 384])	 Training Loss: 0.9001752138137817
Step: 207	 Data: torch.Size([10, 384])	 Training Loss: 0.8751891255378723
Step: 208	 Data: torch.Size([10, 384])	 Training Loss: 0.9837973117828369
Step: 209	 Data: torch.Size([10, 384])	 Training Loss: 0.9526844024658203
Step: 210	 Data: torch.Size([10, 384])	 Training Loss: 0.9876948595046997
Step: 211	 Data: torch.Size([10, 384])	 Training Loss: 0.894787609577179
Step: 212	 Data: torch.Size([10, 384])	 Training Loss: 0.8841076493263245
Step: 213	 Data: torch.Size([10, 384])	 Training Loss: 0.9283568859100342
Step: 214	 Data: torch.Size([10, 384])	 Training Loss: 1.0801312923431396
Step: 215	 Data: torch.Size([10, 384])	 Training Loss: 0.9043158292770386
Step: 216	 Data: torch.Size([10, 384])	 Training Loss: 0.9145375490188599
Step: 217	 Data: torch.Size([10, 384])	 Training Loss: 1.0365467071533203
Step: 218	 Data: torch.Size([10, 384])	 Training Loss: 0.9826278686523438
Step: 219	 Data: torch.Size([10, 384])	 Training Loss: 1.0442209243774414
Step: 220	 Data: torch.Size([10, 384])	 Training Loss: 0.8749560117721558
Step: 221	 Data: torch.Size([10, 384])	 Training Loss: 1.0105953216552734
Step: 222	 Data: torch.Size([10, 384])	 Training Loss: 0.8536264896392822
Step: 223	 Data: torch.Size([10, 384])	 Training Loss: 0.9294971823692322
Step: 224	 Data: torch.Size([10, 384])	 Training Loss: 0.9319344162940979
Step: 225	 Data: torch.Size([10, 384])	 Training Loss: 0.8135094046592712
Step: 226	 Data: torch.Size([10, 384])	 Training Loss: 0.8575952649116516
Step: 227	 Data: torch.Size([10, 384])	 Training Loss: 0.983232319355011
Step: 228	 Data: torch.Size([10, 384])	 Training Loss: 0.9075590968132019
Step: 229	 Data: torch.Size([10, 384])	 Training Loss: 0.8971570730209351
Step: 230	 Data: torch.Size([10, 384])	 Training Loss: 0.8229304552078247
Step: 231	 Data: torch.Size([10, 384])	 Training Loss: 0.9442773461341858
Step: 232	 Data: torch.Size([10, 384])	 Training Loss: 0.9850004315376282
Step: 233	 Data: torch.Size([10, 384])	 Training Loss: 0.972903311252594
Step: 234	 Data: torch.Size([10, 384])	 Training Loss: 0.8218855857849121
Step: 235	 Data: torch.Size([10, 384])	 Training Loss: 0.8209941983222961
Step: 236	 Data: torch.Size([10, 384])	 Training Loss: 0.9466850161552429
Step: 237	 Data: torch.Size([10, 384])	 Training Loss: 1.0224944353103638
Step: 238	 Data: torch.Size([10, 384])	 Training Loss: 1.0352681875228882
Step: 239	 Data: torch.Size([10, 384])	 Training Loss: 0.9324142932891846
Step: 240	 Data: torch.Size([10, 384])	 Training Loss: 0.9454010725021362
Step: 241	 Data: torch.Size([10, 384])	 Training Loss: 1.0208735466003418
Step: 242	 Data: torch.Size([10, 384])	 Training Loss: 0.9062385559082031
Step: 243	 Data: torch.Size([10, 384])	 Training Loss: 1.0613421201705933
Step: 244	 Data: torch.Size([10, 384])	 Training Loss: 1.0026400089263916
Step: 245	 Data: torch.Size([10, 384])	 Training Loss: 0.9566355347633362
Step: 246	 Data: torch.Size([10, 384])	 Training Loss: 1.0230412483215332
Step: 247	 Data: torch.Size([10, 384])	 Training Loss: 0.8973273038864136
Step: 248	 Data: torch.Size([10, 384])	 Training Loss: 0.8272247910499573
Step: 249	 Data: torch.Size([10, 384])	 Training Loss: 0.8979740738868713
Step: 250	 Data: torch.Size([10, 384])	 Training Loss: 1.033599853515625
Step: 251	 Data: torch.Size([10, 384])	 Training Loss: 0.9987475872039795
Step: 252	 Data: torch.Size([10, 384])	 Training Loss: 0.9948710203170776
Step: 253	 Data: torch.Size([10, 384])	 Training Loss: 0.9720035791397095
Step: 254	 Data: torch.Size([10, 384])	 Training Loss: 0.9304990172386169
Step: 255	 Data: torch.Size([10, 384])	 Training Loss: 0.8538028001785278
Step: 256	 Data: torch.Size([10, 384])	 Training Loss: 0.9455825686454773
Step: 257	 Data: torch.Size([10, 384])	 Training Loss: 0.897922158241272
Step: 258	 Data: torch.Size([10, 384])	 Training Loss: 0.8982715606689453
Step: 259	 Data: torch.Size([10, 384])	 Training Loss: 0.8398907780647278
Step: 260	 Data: torch.Size([10, 384])	 Training Loss: 0.894741952419281
Step: 261	 Data: torch.Size([10, 384])	 Training Loss: 1.0291409492492676
Step: 262	 Data: torch.Size([10, 384])	 Training Loss: 0.9749137759208679
Step: 263	 Data: torch.Size([10, 384])	 Training Loss: 1.0489470958709717
Step: 264	 Data: torch.Size([10, 384])	 Training Loss: 1.04997980594635
Step: 265	 Data: torch.Size([10, 384])	 Training Loss: 0.9408249258995056
Step: 266	 Data: torch.Size([10, 384])	 Training Loss: 0.8842591643333435
Step: 267	 Data: torch.Size([10, 384])	 Training Loss: 0.8800563216209412
Step: 268	 Data: torch.Size([10, 384])	 Training Loss: 0.9005193710327148
Step: 269	 Data: torch.Size([10, 384])	 Training Loss: 0.8834903240203857
Step: 270	 Data: torch.Size([10, 384])	 Training Loss: 0.9884517192840576
Step: 271	 Data: torch.Size([10, 384])	 Training Loss: 0.9529860615730286
Step: 272	 Data: torch.Size([10, 384])	 Training Loss: 0.9065195322036743
Step: 273	 Data: torch.Size([10, 384])	 Training Loss: 0.8204905986785889
Step: 274	 Data: torch.Size([10, 384])	 Training Loss: 0.9709229469299316
Step: 275	 Data: torch.Size([10, 384])	 Training Loss: 1.0076926946640015
Step: 276	 Data: torch.Size([10, 384])	 Training Loss: 0.9407683610916138
Step: 277	 Data: torch.Size([10, 384])	 Training Loss: 0.9087539911270142
Step: 278	 Data: torch.Size([10, 384])	 Training Loss: 1.0217475891113281
Step: 279	 Data: torch.Size([10, 384])	 Training Loss: 0.9730623364448547
Step: 280	 Data: torch.Size([10, 384])	 Training Loss: 0.9653668403625488
Step: 281	 Data: torch.Size([10, 384])	 Training Loss: 0.9938400387763977
Step: 282	 Data: torch.Size([10, 384])	 Training Loss: 0.9301042556762695
Step: 283	 Data: torch.Size([10, 384])	 Training Loss: 1.0493659973144531
Step: 284	 Data: torch.Size([10, 384])	 Training Loss: 1.272471308708191
Step: 285	 Data: torch.Size([10, 384])	 Training Loss: 0.9256532788276672
Step: 286	 Data: torch.Size([10, 384])	 Training Loss: 1.05820631980896
Step: 287	 Data: torch.Size([10, 384])	 Training Loss: 0.9078099727630615
Step: 288	 Data: torch.Size([10, 384])	 Training Loss: 0.7748815417289734
Step: 289	 Data: torch.Size([10, 384])	 Training Loss: 0.9309742450714111
Step: 290	 Data: torch.Size([10, 384])	 Training Loss: 0.9153067469596863
Step: 291	 Data: torch.Size([10, 384])	 Training Loss: 0.9470959901809692
Step: 292	 Data: torch.Size([10, 384])	 Training Loss: 1.0280097723007202
Step: 293	 Data: torch.Size([10, 384])	 Training Loss: 0.8548176288604736
Step: 294	 Data: torch.Size([10, 384])	 Training Loss: 0.8528139591217041
Step: 295	 Data: torch.Size([10, 384])	 Training Loss: 0.984619677066803
Step: 296	 Data: torch.Size([10, 384])	 Training Loss: 1.0068846940994263
Step: 297	 Data: torch.Size([10, 384])	 Training Loss: 0.9401965737342834
Step: 298	 Data: torch.Size([10, 384])	 Training Loss: 0.9395833015441895
Step: 299	 Data: torch.Size([10, 384])	 Training Loss: 1.0076686143875122
Step: 300	 Data: torch.Size([10, 384])	 Training Loss: 1.0449353456497192
