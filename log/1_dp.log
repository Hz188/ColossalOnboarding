[2024-05-07 05:50:31,122] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-05-07 05:50:31,123] torch.distributed.run: [WARNING] 
[2024-05-07 05:50:31,123] torch.distributed.run: [WARNING] *****************************************
[2024-05-07 05:50:31,123] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-07 05:50:31,123] torch.distributed.run: [WARNING] *****************************************
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:34745 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:34745 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:34745 (errno: 22 - Invalid argument).
====================initialize the distributed env====================
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.30s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.56s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.67s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.69s/it]
====================get the model with lora====================
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.78s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.71s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  8.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.03s/it]
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
====================Use distributed data parallel====================
====================get the dataset====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
====================get the dataloader====================
====================start train====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Step: 1	 Data: torch.Size([10, 384])	 Training Loss: 1.0071995258331299
Step: 2	 Data: torch.Size([10, 384])	 Training Loss: 1.0460771322250366
Step: 3	 Data: torch.Size([10, 384])	 Training Loss: 1.1262587308883667
Step: 4	 Data: torch.Size([10, 384])	 Training Loss: 1.0790140628814697
Step: 5	 Data: torch.Size([10, 384])	 Training Loss: 1.0097352266311646
Step: 6	 Data: torch.Size([10, 384])	 Training Loss: 1.1461296081542969
Step: 7	 Data: torch.Size([10, 384])	 Training Loss: 1.0300661325454712
Step: 8	 Data: torch.Size([10, 384])	 Training Loss: 1.223107933998108
Step: 9	 Data: torch.Size([10, 384])	 Training Loss: 1.0862387418746948
Step: 10	 Data: torch.Size([10, 384])	 Training Loss: 1.091552972793579
Step: 11	 Data: torch.Size([10, 384])	 Training Loss: 1.0178446769714355
Step: 12	 Data: torch.Size([10, 384])	 Training Loss: 1.0547127723693848
Step: 13	 Data: torch.Size([10, 384])	 Training Loss: 1.0950225591659546
Step: 14	 Data: torch.Size([10, 384])	 Training Loss: 1.2376806735992432
Step: 15	 Data: torch.Size([10, 384])	 Training Loss: 1.0422126054763794
Step: 16	 Data: torch.Size([10, 384])	 Training Loss: 1.1324433088302612
Step: 17	 Data: torch.Size([10, 384])	 Training Loss: 1.1617273092269897
Step: 18	 Data: torch.Size([10, 384])	 Training Loss: 1.0621955394744873
Step: 19	 Data: torch.Size([10, 384])	 Training Loss: 1.2256053686141968
Step: 20	 Data: torch.Size([10, 384])	 Training Loss: 1.0245825052261353
Step: 21	 Data: torch.Size([10, 384])	 Training Loss: 1.0358264446258545
Step: 22	 Data: torch.Size([10, 384])	 Training Loss: 1.0504083633422852
Step: 23	 Data: torch.Size([10, 384])	 Training Loss: 1.147881031036377
Step: 24	 Data: torch.Size([10, 384])	 Training Loss: 1.1765931844711304
Step: 25	 Data: torch.Size([10, 384])	 Training Loss: 0.9873887300491333
Step: 26	 Data: torch.Size([10, 384])	 Training Loss: 0.9650401473045349
Step: 27	 Data: torch.Size([10, 384])	 Training Loss: 1.2214447259902954
Step: 28	 Data: torch.Size([10, 384])	 Training Loss: 1.1181190013885498
Step: 29	 Data: torch.Size([10, 384])	 Training Loss: 1.1185879707336426
Step: 30	 Data: torch.Size([10, 384])	 Training Loss: 0.9864501357078552
Step: 31	 Data: torch.Size([10, 384])	 Training Loss: 1.1280585527420044
Step: 32	 Data: torch.Size([10, 384])	 Training Loss: 1.1259583234786987
Step: 33	 Data: torch.Size([10, 384])	 Training Loss: 1.034044861793518
Step: 34	 Data: torch.Size([10, 384])	 Training Loss: 0.90399569272995
Step: 35	 Data: torch.Size([10, 384])	 Training Loss: 1.0442756414413452
Step: 36	 Data: torch.Size([10, 384])	 Training Loss: 1.0723414421081543
Step: 37	 Data: torch.Size([10, 384])	 Training Loss: 1.122551679611206
Step: 38	 Data: torch.Size([10, 384])	 Training Loss: 0.9697989225387573
Step: 39	 Data: torch.Size([10, 384])	 Training Loss: 1.0176798105239868
Step: 40	 Data: torch.Size([10, 384])	 Training Loss: 1.0419971942901611
Step: 41	 Data: torch.Size([10, 384])	 Training Loss: 1.1760376691818237
Step: 42	 Data: torch.Size([10, 384])	 Training Loss: 1.0235744714736938
Step: 43	 Data: torch.Size([10, 384])	 Training Loss: 1.1060105562210083
Step: 44	 Data: torch.Size([10, 384])	 Training Loss: 1.2645487785339355
Step: 45	 Data: torch.Size([10, 384])	 Training Loss: 1.1048557758331299
Step: 46	 Data: torch.Size([10, 384])	 Training Loss: 0.988190770149231
Step: 47	 Data: torch.Size([10, 384])	 Training Loss: 0.9909616708755493
Step: 48	 Data: torch.Size([10, 384])	 Training Loss: 1.2241592407226562
Step: 49	 Data: torch.Size([10, 384])	 Training Loss: 1.162651538848877
Step: 50	 Data: torch.Size([10, 384])	 Training Loss: 1.2310411930084229
Step: 51	 Data: torch.Size([10, 384])	 Training Loss: 1.0427154302597046
Step: 52	 Data: torch.Size([10, 384])	 Training Loss: 1.0424370765686035
Step: 53	 Data: torch.Size([10, 384])	 Training Loss: 1.1122982501983643
Step: 54	 Data: torch.Size([10, 384])	 Training Loss: 1.093013882637024
Step: 55	 Data: torch.Size([10, 384])	 Training Loss: 1.0033683776855469
Step: 56	 Data: torch.Size([10, 384])	 Training Loss: 1.1531760692596436
Step: 57	 Data: torch.Size([10, 384])	 Training Loss: 0.9982693195343018
Step: 58	 Data: torch.Size([10, 384])	 Training Loss: 0.9433753490447998
Step: 59	 Data: torch.Size([10, 384])	 Training Loss: 1.1785372495651245
Step: 60	 Data: torch.Size([10, 384])	 Training Loss: 1.1614649295806885
Step: 61	 Data: torch.Size([10, 384])	 Training Loss: 1.0003268718719482
Step: 62	 Data: torch.Size([10, 384])	 Training Loss: 1.2405325174331665
Step: 63	 Data: torch.Size([10, 384])	 Training Loss: 1.110751986503601
Step: 64	 Data: torch.Size([10, 384])	 Training Loss: 1.046836256980896
Step: 65	 Data: torch.Size([10, 384])	 Training Loss: 1.0752571821212769
Step: 66	 Data: torch.Size([10, 384])	 Training Loss: 1.0690298080444336
Step: 67	 Data: torch.Size([10, 384])	 Training Loss: 1.0643863677978516
Step: 68	 Data: torch.Size([10, 384])	 Training Loss: 1.201994776725769
Step: 69	 Data: torch.Size([10, 384])	 Training Loss: 1.2500113248825073
Step: 70	 Data: torch.Size([10, 384])	 Training Loss: 0.9863158464431763
Step: 71	 Data: torch.Size([10, 384])	 Training Loss: 1.015045166015625
Step: 72	 Data: torch.Size([10, 350])	 Training Loss: 1.4833375215530396
Step: 73	 Data: torch.Size([10, 384])	 Training Loss: 1.0048002004623413
Step: 74	 Data: torch.Size([10, 384])	 Training Loss: 1.1335455179214478
Step: 75	 Data: torch.Size([10, 384])	 Training Loss: 1.0682058334350586
Step: 76	 Data: torch.Size([10, 384])	 Training Loss: 0.9431754350662231
Step: 77	 Data: torch.Size([10, 384])	 Training Loss: 1.1962859630584717
Step: 78	 Data: torch.Size([10, 384])	 Training Loss: 1.106613039970398
Step: 79	 Data: torch.Size([10, 384])	 Training Loss: 1.3082541227340698
Step: 80	 Data: torch.Size([10, 384])	 Training Loss: 1.1267510652542114
Step: 81	 Data: torch.Size([10, 384])	 Training Loss: 1.1283479928970337
Step: 82	 Data: torch.Size([10, 384])	 Training Loss: 1.1348865032196045
Step: 83	 Data: torch.Size([10, 384])	 Training Loss: 1.0930545330047607
Step: 84	 Data: torch.Size([10, 384])	 Training Loss: 0.9548999667167664
Step: 85	 Data: torch.Size([10, 384])	 Training Loss: 1.069955825805664
Step: 86	 Data: torch.Size([10, 384])	 Training Loss: 1.1740024089813232
Step: 87	 Data: torch.Size([10, 384])	 Training Loss: 1.0837754011154175
Step: 88	 Data: torch.Size([10, 384])	 Training Loss: 0.9512908458709717
Step: 89	 Data: torch.Size([10, 384])	 Training Loss: 1.148756504058838
Step: 90	 Data: torch.Size([10, 384])	 Training Loss: 1.1486836671829224
Step: 91	 Data: torch.Size([10, 384])	 Training Loss: 0.9869294166564941
Step: 92	 Data: torch.Size([10, 384])	 Training Loss: 0.9608757495880127
Step: 93	 Data: torch.Size([10, 384])	 Training Loss: 1.0756382942199707
Step: 94	 Data: torch.Size([10, 384])	 Training Loss: 1.211857795715332
Step: 95	 Data: torch.Size([10, 384])	 Training Loss: 1.0697777271270752
Step: 96	 Data: torch.Size([10, 384])	 Training Loss: 0.9737400412559509
Step: 97	 Data: torch.Size([10, 384])	 Training Loss: 1.1344455480575562
Step: 98	 Data: torch.Size([10, 384])	 Training Loss: 1.0104726552963257
Step: 99	 Data: torch.Size([10, 384])	 Training Loss: 1.0708215236663818
Step: 100	 Data: torch.Size([10, 384])	 Training Loss: 1.243984580039978
Step: 101	 Data: torch.Size([10, 384])	 Training Loss: 1.0457818508148193
Step: 102	 Data: torch.Size([10, 384])	 Training Loss: 1.0836430788040161
Step: 103	 Data: torch.Size([10, 384])	 Training Loss: 1.0963397026062012
Step: 104	 Data: torch.Size([10, 384])	 Training Loss: 1.0274255275726318
Step: 105	 Data: torch.Size([10, 384])	 Training Loss: 1.0709415674209595
Step: 106	 Data: torch.Size([10, 384])	 Training Loss: 1.2139779329299927
Step: 107	 Data: torch.Size([10, 384])	 Training Loss: 1.0273979902267456
Step: 108	 Data: torch.Size([10, 384])	 Training Loss: 1.039620280265808
Step: 109	 Data: torch.Size([10, 384])	 Training Loss: 1.0912439823150635
Step: 110	 Data: torch.Size([10, 384])	 Training Loss: 1.008082628250122
Step: 111	 Data: torch.Size([10, 384])	 Training Loss: 1.3037678003311157
Step: 112	 Data: torch.Size([10, 384])	 Training Loss: 1.3230525255203247
Step: 113	 Data: torch.Size([10, 384])	 Training Loss: 1.1849881410598755
Step: 114	 Data: torch.Size([10, 384])	 Training Loss: 1.0646531581878662
Step: 115	 Data: torch.Size([10, 384])	 Training Loss: 0.9951626062393188
Step: 116	 Data: torch.Size([10, 384])	 Training Loss: 1.0103254318237305
Step: 117	 Data: torch.Size([10, 384])	 Training Loss: 0.992533266544342
Step: 118	 Data: torch.Size([10, 384])	 Training Loss: 1.0436358451843262
Step: 119	 Data: torch.Size([10, 384])	 Training Loss: 1.461987018585205
Step: 120	 Data: torch.Size([10, 384])	 Training Loss: 0.9712415933609009
Step: 121	 Data: torch.Size([10, 307])	 Training Loss: 1.209991693496704
Step: 122	 Data: torch.Size([10, 384])	 Training Loss: 1.2451821565628052
Step: 123	 Data: torch.Size([10, 384])	 Training Loss: 1.0882441997528076
Step: 124	 Data: torch.Size([10, 384])	 Training Loss: 1.0484378337860107
Step: 125	 Data: torch.Size([10, 384])	 Training Loss: 0.9774298071861267
Step: 126	 Data: torch.Size([10, 384])	 Training Loss: 1.0457274913787842
Step: 127	 Data: torch.Size([10, 384])	 Training Loss: 1.1700929403305054
Step: 128	 Data: torch.Size([10, 384])	 Training Loss: 0.951673686504364
Step: 129	 Data: torch.Size([10, 384])	 Training Loss: 1.1808024644851685
Step: 130	 Data: torch.Size([10, 384])	 Training Loss: 1.0893176794052124
Step: 131	 Data: torch.Size([10, 384])	 Training Loss: 1.1019405126571655
Step: 132	 Data: torch.Size([10, 384])	 Training Loss: 1.107947826385498
Step: 133	 Data: torch.Size([10, 384])	 Training Loss: 1.1080787181854248
Step: 134	 Data: torch.Size([10, 384])	 Training Loss: 1.1977373361587524
Step: 135	 Data: torch.Size([10, 384])	 Training Loss: 1.1399173736572266
Step: 136	 Data: torch.Size([10, 384])	 Training Loss: 1.0426470041275024
Step: 137	 Data: torch.Size([10, 384])	 Training Loss: 1.2074841260910034
Step: 138	 Data: torch.Size([10, 384])	 Training Loss: 1.0506987571716309
Step: 139	 Data: torch.Size([10, 384])	 Training Loss: 1.1552904844284058
Step: 140	 Data: torch.Size([10, 384])	 Training Loss: 1.0757691860198975
Step: 141	 Data: torch.Size([10, 384])	 Training Loss: 1.0963845252990723
Step: 142	 Data: torch.Size([10, 384])	 Training Loss: 1.0994532108306885
Step: 143	 Data: torch.Size([10, 384])	 Training Loss: 1.1567412614822388
Step: 144	 Data: torch.Size([10, 384])	 Training Loss: 1.1361873149871826
Step: 145	 Data: torch.Size([10, 384])	 Training Loss: 1.1162441968917847
Step: 146	 Data: torch.Size([10, 384])	 Training Loss: 1.1200581789016724
Step: 147	 Data: torch.Size([10, 384])	 Training Loss: 1.1663321256637573
Step: 148	 Data: torch.Size([10, 384])	 Training Loss: 1.1017787456512451
Step: 149	 Data: torch.Size([10, 384])	 Training Loss: 1.0580902099609375
Step: 150	 Data: torch.Size([10, 384])	 Training Loss: 1.073050856590271
Step: 151	 Data: torch.Size([10, 384])	 Training Loss: 1.2218979597091675
Step: 152	 Data: torch.Size([10, 384])	 Training Loss: 1.0392214059829712
Step: 153	 Data: torch.Size([10, 384])	 Training Loss: 1.2583481073379517
Step: 154	 Data: torch.Size([10, 384])	 Training Loss: 1.160644292831421
Step: 155	 Data: torch.Size([10, 384])	 Training Loss: 1.0613141059875488
Step: 156	 Data: torch.Size([10, 384])	 Training Loss: 0.9675544500350952
Step: 157	 Data: torch.Size([10, 384])	 Training Loss: 1.0234110355377197
Step: 158	 Data: torch.Size([10, 384])	 Training Loss: 1.1395628452301025
Step: 159	 Data: torch.Size([10, 384])	 Training Loss: 1.2163968086242676
Step: 160	 Data: torch.Size([10, 384])	 Training Loss: 1.0132339000701904
Step: 161	 Data: torch.Size([10, 384])	 Training Loss: 1.1416507959365845
Step: 162	 Data: torch.Size([10, 384])	 Training Loss: 1.2020587921142578
Step: 163	 Data: torch.Size([10, 384])	 Training Loss: 1.1432232856750488
Step: 164	 Data: torch.Size([10, 384])	 Training Loss: 1.1203913688659668
Step: 165	 Data: torch.Size([10, 384])	 Training Loss: 1.0382479429244995
Step: 166	 Data: torch.Size([10, 384])	 Training Loss: 1.2543771266937256
Step: 167	 Data: torch.Size([10, 384])	 Training Loss: 1.0560988187789917
Step: 168	 Data: torch.Size([10, 384])	 Training Loss: 1.1262052059173584
Step: 169	 Data: torch.Size([10, 384])	 Training Loss: 1.0936146974563599
Step: 170	 Data: torch.Size([10, 384])	 Training Loss: 1.2154607772827148
Step: 171	 Data: torch.Size([10, 384])	 Training Loss: 1.0485767126083374
Step: 172	 Data: torch.Size([10, 384])	 Training Loss: 0.9896163940429688
Step: 173	 Data: torch.Size([10, 384])	 Training Loss: 1.0623234510421753
Step: 174	 Data: torch.Size([10, 384])	 Training Loss: 1.0269105434417725
Step: 175	 Data: torch.Size([10, 384])	 Training Loss: 1.1623384952545166
Step: 176	 Data: torch.Size([10, 384])	 Training Loss: 1.089264988899231
Step: 177	 Data: torch.Size([10, 384])	 Training Loss: 1.1498223543167114
Step: 178	 Data: torch.Size([10, 384])	 Training Loss: 1.0514976978302002
Step: 179	 Data: torch.Size([10, 384])	 Training Loss: 1.0404843091964722
Step: 180	 Data: torch.Size([10, 384])	 Training Loss: 1.252539873123169
Step: 181	 Data: torch.Size([10, 384])	 Training Loss: 0.8862356543540955
Step: 182	 Data: torch.Size([10, 384])	 Training Loss: 1.2553097009658813
Step: 183	 Data: torch.Size([10, 384])	 Training Loss: 1.0744444131851196
Step: 184	 Data: torch.Size([10, 384])	 Training Loss: 1.1622368097305298
Step: 185	 Data: torch.Size([10, 384])	 Training Loss: 1.0232417583465576
Step: 186	 Data: torch.Size([10, 384])	 Training Loss: 1.141223430633545
Step: 187	 Data: torch.Size([10, 384])	 Training Loss: 1.0040191411972046
Step: 188	 Data: torch.Size([10, 384])	 Training Loss: 1.0990124940872192
Step: 189	 Data: torch.Size([10, 384])	 Training Loss: 1.0778253078460693
Step: 190	 Data: torch.Size([10, 384])	 Training Loss: 1.2429343461990356
Step: 191	 Data: torch.Size([10, 384])	 Training Loss: 1.0493361949920654
Step: 192	 Data: torch.Size([10, 384])	 Training Loss: 1.166059136390686
Step: 193	 Data: torch.Size([10, 384])	 Training Loss: 1.0783498287200928
Step: 194	 Data: torch.Size([10, 384])	 Training Loss: 1.08210027217865
Step: 195	 Data: torch.Size([10, 384])	 Training Loss: 1.094038486480713
Step: 196	 Data: torch.Size([10, 384])	 Training Loss: 1.0589767694473267
Step: 197	 Data: torch.Size([10, 384])	 Training Loss: 0.9647483825683594
Step: 198	 Data: torch.Size([10, 384])	 Training Loss: 1.1759445667266846
Step: 199	 Data: torch.Size([10, 384])	 Training Loss: 1.197390079498291
Step: 200	 Data: torch.Size([10, 384])	 Training Loss: 1.0809664726257324
Step: 201	 Data: torch.Size([10, 384])	 Training Loss: 1.1187463998794556
Step: 202	 Data: torch.Size([10, 384])	 Training Loss: 1.0570906400680542
Step: 203	 Data: torch.Size([10, 384])	 Training Loss: 1.1911379098892212
Step: 204	 Data: torch.Size([10, 384])	 Training Loss: 1.1185609102249146
Step: 205	 Data: torch.Size([10, 384])	 Training Loss: 1.1478749513626099
Step: 206	 Data: torch.Size([10, 384])	 Training Loss: 1.0527206659317017
Step: 207	 Data: torch.Size([10, 384])	 Training Loss: 1.040809154510498
Step: 208	 Data: torch.Size([10, 384])	 Training Loss: 1.1146005392074585
Step: 209	 Data: torch.Size([10, 384])	 Training Loss: 1.1059787273406982
Step: 210	 Data: torch.Size([10, 384])	 Training Loss: 1.1411261558532715
Step: 211	 Data: torch.Size([10, 384])	 Training Loss: 1.0717695951461792
Step: 212	 Data: torch.Size([10, 384])	 Training Loss: 1.0098178386688232
Step: 213	 Data: torch.Size([10, 384])	 Training Loss: 1.090266227722168
Step: 214	 Data: torch.Size([10, 384])	 Training Loss: 1.2275978326797485
Step: 215	 Data: torch.Size([10, 384])	 Training Loss: 1.1000851392745972
Step: 216	 Data: torch.Size([10, 384])	 Training Loss: 1.1002076864242554
Step: 217	 Data: torch.Size([10, 384])	 Training Loss: 1.2294780015945435
Step: 218	 Data: torch.Size([10, 384])	 Training Loss: 1.165967583656311
Step: 219	 Data: torch.Size([10, 384])	 Training Loss: 1.1980425119400024
Step: 220	 Data: torch.Size([10, 384])	 Training Loss: 1.0590684413909912
Step: 221	 Data: torch.Size([10, 384])	 Training Loss: 1.1670125722885132
Step: 222	 Data: torch.Size([10, 384])	 Training Loss: 1.001536250114441
Step: 223	 Data: torch.Size([10, 384])	 Training Loss: 1.0914366245269775
Step: 224	 Data: torch.Size([10, 384])	 Training Loss: 1.0828129053115845
Step: 225	 Data: torch.Size([10, 384])	 Training Loss: 0.9529889822006226
Step: 226	 Data: torch.Size([10, 384])	 Training Loss: 0.9943557381629944
Step: 227	 Data: torch.Size([10, 384])	 Training Loss: 1.1247611045837402
Step: 228	 Data: torch.Size([10, 384])	 Training Loss: 1.0412864685058594
Step: 229	 Data: torch.Size([10, 384])	 Training Loss: 1.0417085886001587
Step: 230	 Data: torch.Size([10, 384])	 Training Loss: 1.026512622833252
Step: 231	 Data: torch.Size([10, 384])	 Training Loss: 1.1168426275253296
Step: 232	 Data: torch.Size([10, 384])	 Training Loss: 1.0997995138168335
Step: 233	 Data: torch.Size([10, 384])	 Training Loss: 1.1884868144989014
Step: 234	 Data: torch.Size([10, 384])	 Training Loss: 0.9613088965415955
Step: 235	 Data: torch.Size([10, 384])	 Training Loss: 0.9752887487411499
Step: 236	 Data: torch.Size([10, 384])	 Training Loss: 1.1049913167953491
Step: 237	 Data: torch.Size([10, 384])	 Training Loss: 1.1913275718688965
Step: 238	 Data: torch.Size([10, 384])	 Training Loss: 1.1770968437194824
Step: 239	 Data: torch.Size([10, 384])	 Training Loss: 1.072962999343872
Step: 240	 Data: torch.Size([10, 384])	 Training Loss: 1.1335710287094116
Step: 241	 Data: torch.Size([10, 384])	 Training Loss: 1.205216646194458
Step: 242	 Data: torch.Size([10, 384])	 Training Loss: 1.0799307823181152
Step: 243	 Data: torch.Size([10, 384])	 Training Loss: 1.2169065475463867
Step: 244	 Data: torch.Size([10, 384])	 Training Loss: 1.1498478651046753
Step: 245	 Data: torch.Size([10, 384])	 Training Loss: 1.1733843088150024
Step: 246	 Data: torch.Size([10, 384])	 Training Loss: 1.1482272148132324
Step: 247	 Data: torch.Size([10, 384])	 Training Loss: 1.083104133605957
Step: 248	 Data: torch.Size([10, 384])	 Training Loss: 0.9999099373817444
Step: 249	 Data: torch.Size([10, 384])	 Training Loss: 1.046987771987915
Step: 250	 Data: torch.Size([10, 384])	 Training Loss: 1.2063745260238647
Step: 251	 Data: torch.Size([10, 384])	 Training Loss: 1.1724903583526611
Step: 252	 Data: torch.Size([10, 384])	 Training Loss: 1.1630204916000366
Step: 253	 Data: torch.Size([10, 384])	 Training Loss: 1.1205620765686035
Step: 254	 Data: torch.Size([10, 384])	 Training Loss: 1.1026147603988647
Step: 255	 Data: torch.Size([10, 384])	 Training Loss: 0.9892370700836182
Step: 256	 Data: torch.Size([10, 384])	 Training Loss: 1.1136233806610107
Step: 257	 Data: torch.Size([10, 384])	 Training Loss: 1.0682423114776611
Step: 258	 Data: torch.Size([10, 384])	 Training Loss: 1.0227198600769043
Step: 259	 Data: torch.Size([10, 384])	 Training Loss: 0.9982061982154846
Step: 260	 Data: torch.Size([10, 384])	 Training Loss: 1.1228573322296143
Step: 261	 Data: torch.Size([10, 384])	 Training Loss: 1.1734108924865723
Step: 262	 Data: torch.Size([10, 384])	 Training Loss: 1.156078815460205
Step: 263	 Data: torch.Size([10, 384])	 Training Loss: 1.206503987312317
Step: 264	 Data: torch.Size([10, 384])	 Training Loss: 1.2307366132736206
Step: 265	 Data: torch.Size([10, 384])	 Training Loss: 1.0819836854934692
Step: 266	 Data: torch.Size([10, 384])	 Training Loss: 1.0260348320007324
Step: 267	 Data: torch.Size([10, 384])	 Training Loss: 1.0171419382095337
Step: 268	 Data: torch.Size([10, 384])	 Training Loss: 1.07494056224823
Step: 269	 Data: torch.Size([10, 384])	 Training Loss: 1.038456678390503
Step: 270	 Data: torch.Size([10, 384])	 Training Loss: 1.1561496257781982
Step: 271	 Data: torch.Size([10, 384])	 Training Loss: 1.1226612329483032
Step: 272	 Data: torch.Size([10, 384])	 Training Loss: 1.0622469186782837
Step: 273	 Data: torch.Size([10, 384])	 Training Loss: 0.9571048021316528
Step: 274	 Data: torch.Size([10, 384])	 Training Loss: 1.1341580152511597
Step: 275	 Data: torch.Size([10, 384])	 Training Loss: 1.155113697052002
Step: 276	 Data: torch.Size([10, 384])	 Training Loss: 1.092247486114502
Step: 277	 Data: torch.Size([10, 384])	 Training Loss: 1.0693496465682983
Step: 278	 Data: torch.Size([10, 384])	 Training Loss: 1.1662096977233887
Step: 279	 Data: torch.Size([10, 384])	 Training Loss: 1.1295098066329956
Step: 280	 Data: torch.Size([10, 384])	 Training Loss: 1.1155965328216553
Step: 281	 Data: torch.Size([10, 384])	 Training Loss: 1.1482738256454468
Step: 282	 Data: torch.Size([10, 384])	 Training Loss: 1.1170905828475952
Step: 283	 Data: torch.Size([10, 384])	 Training Loss: 1.2302751541137695
Step: 284	 Data: torch.Size([10, 384])	 Training Loss: 1.4442604780197144
Step: 285	 Data: torch.Size([10, 384])	 Training Loss: 1.1041516065597534
Step: 286	 Data: torch.Size([10, 384])	 Training Loss: 1.2723345756530762
Step: 287	 Data: torch.Size([10, 384])	 Training Loss: 1.103968858718872
Step: 288	 Data: torch.Size([10, 384])	 Training Loss: 0.9288789629936218
Step: 289	 Data: torch.Size([10, 384])	 Training Loss: 1.0837653875350952
Step: 290	 Data: torch.Size([10, 384])	 Training Loss: 1.1300008296966553
Step: 291	 Data: torch.Size([10, 384])	 Training Loss: 1.1084686517715454
Step: 292	 Data: torch.Size([10, 384])	 Training Loss: 1.2006970643997192
Step: 293	 Data: torch.Size([10, 384])	 Training Loss: 1.031097650527954
Step: 294	 Data: torch.Size([10, 384])	 Training Loss: 1.0071080923080444
Step: 295	 Data: torch.Size([10, 384])	 Training Loss: 1.151637077331543
Step: 296	 Data: torch.Size([10, 384])	 Training Loss: 1.1147907972335815
Step: 297	 Data: torch.Size([10, 384])	 Training Loss: 1.1277247667312622
Step: 298	 Data: torch.Size([10, 384])	 Training Loss: 1.090926170349121
Step: 299	 Data: torch.Size([10, 384])	 Training Loss: 1.1494476795196533
Step: 300	 Data: torch.Size([10, 384])	 Training Loss: 1.2186042070388794
