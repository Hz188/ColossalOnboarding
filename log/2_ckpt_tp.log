[2024-05-07 14:26:39,540] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-05-07 14:26:39,541] torch.distributed.run: [WARNING] 
[2024-05-07 14:26:39,541] torch.distributed.run: [WARNING] *****************************************
[2024-05-07 14:26:39,541] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-07 14:26:39,541] torch.distributed.run: [WARNING] *****************************************
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-198]:49999 (errno: 22 - Invalid argument).
====================initialize the distributed env====================
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:20<00:20, 20.03s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.90s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:20<00:20, 20.24s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:20<00:20, 20.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 15.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 16.59s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 16.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 16.84s/it]
====================Use tensor parallel====================
====================convert origin mlp to parallel mlp====================
====================get the model with lora====================
trainable params: 4,194,304 || all params: 4,578,349,056 || trainable%: 0.09161171305851609
Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 16.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 16.84s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 16.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 16.87s/it]
====================Use gradient checkpoint====================
====================get the dataset====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
====================get the dataloader====================
====================start train====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Step: 1	 Data: torch.Size([10, 384])	 Training Loss: 1.0653094053268433
Step: 2	 Data: torch.Size([10, 384])	 Training Loss: 1.0275640487670898
Step: 3	 Data: torch.Size([10, 384])	 Training Loss: 0.9645192623138428
Step: 4	 Data: torch.Size([10, 384])	 Training Loss: 1.1948126554489136
Step: 5	 Data: torch.Size([10, 384])	 Training Loss: 1.2678747177124023
Step: 6	 Data: torch.Size([10, 302])	 Training Loss: 1.2405095100402832
Step: 7	 Data: torch.Size([10, 384])	 Training Loss: 1.218008279800415
Step: 8	 Data: torch.Size([10, 384])	 Training Loss: 1.104996919631958
Step: 9	 Data: torch.Size([10, 384])	 Training Loss: 1.1116503477096558
Step: 10	 Data: torch.Size([10, 384])	 Training Loss: 1.0323024988174438
Step: 11	 Data: torch.Size([10, 384])	 Training Loss: 1.3795616626739502
Step: 12	 Data: torch.Size([10, 319])	 Training Loss: 1.188642144203186
Step: 13	 Data: torch.Size([10, 384])	 Training Loss: 1.188737392425537
Step: 14	 Data: torch.Size([10, 384])	 Training Loss: 0.9832932353019714
Step: 15	 Data: torch.Size([10, 384])	 Training Loss: 0.9869405627250671
Step: 16	 Data: torch.Size([10, 384])	 Training Loss: 1.2154525518417358
Step: 17	 Data: torch.Size([10, 384])	 Training Loss: 1.138084888458252
Step: 18	 Data: torch.Size([10, 384])	 Training Loss: 1.1936246156692505
Step: 19	 Data: torch.Size([10, 384])	 Training Loss: 1.1201162338256836
Step: 20	 Data: torch.Size([10, 384])	 Training Loss: 1.1210169792175293
Step: 21	 Data: torch.Size([10, 384])	 Training Loss: 1.2380058765411377
Step: 22	 Data: torch.Size([10, 384])	 Training Loss: 1.0427429676055908
Step: 23	 Data: torch.Size([10, 384])	 Training Loss: 1.145168423652649
Step: 24	 Data: torch.Size([10, 384])	 Training Loss: 1.0701488256454468
Step: 25	 Data: torch.Size([10, 384])	 Training Loss: 1.14913010597229
Step: 26	 Data: torch.Size([10, 384])	 Training Loss: 1.075184941291809
Step: 27	 Data: torch.Size([10, 384])	 Training Loss: 1.3532497882843018
Step: 28	 Data: torch.Size([10, 384])	 Training Loss: 1.1387897729873657
Step: 29	 Data: torch.Size([10, 384])	 Training Loss: 1.1077145338058472
Step: 30	 Data: torch.Size([10, 384])	 Training Loss: 1.1480937004089355
Step: 31	 Data: torch.Size([10, 384])	 Training Loss: 0.9738308787345886
Step: 32	 Data: torch.Size([10, 384])	 Training Loss: 1.0468579530715942
Step: 33	 Data: torch.Size([10, 384])	 Training Loss: 1.015368103981018
Step: 34	 Data: torch.Size([10, 384])	 Training Loss: 1.127008318901062
Step: 35	 Data: torch.Size([10, 384])	 Training Loss: 1.1649785041809082
Step: 36	 Data: torch.Size([10, 384])	 Training Loss: 0.959113359451294
Step: 37	 Data: torch.Size([10, 384])	 Training Loss: 1.156293272972107
Step: 38	 Data: torch.Size([10, 384])	 Training Loss: 1.447973608970642
Step: 39	 Data: torch.Size([10, 384])	 Training Loss: 1.280094027519226
Step: 40	 Data: torch.Size([10, 384])	 Training Loss: 1.121447205543518
Step: 41	 Data: torch.Size([10, 384])	 Training Loss: 1.1389650106430054
Step: 42	 Data: torch.Size([10, 384])	 Training Loss: 1.0303425788879395
Step: 43	 Data: torch.Size([10, 384])	 Training Loss: 1.1316176652908325
Step: 44	 Data: torch.Size([10, 384])	 Training Loss: 0.9790228009223938
Step: 45	 Data: torch.Size([10, 384])	 Training Loss: 0.9346807599067688
Step: 46	 Data: torch.Size([10, 384])	 Training Loss: 1.1535050868988037
Step: 47	 Data: torch.Size([10, 384])	 Training Loss: 1.261455774307251
Step: 48	 Data: torch.Size([10, 384])	 Training Loss: 0.9951722025871277
Step: 49	 Data: torch.Size([10, 384])	 Training Loss: 1.0196045637130737
Step: 50	 Data: torch.Size([10, 384])	 Training Loss: 1.039812445640564
Step: 51	 Data: torch.Size([10, 384])	 Training Loss: 0.9512020349502563
Step: 52	 Data: torch.Size([10, 384])	 Training Loss: 0.9483094215393066
Step: 53	 Data: torch.Size([10, 384])	 Training Loss: 1.005553126335144
Step: 54	 Data: torch.Size([10, 384])	 Training Loss: 1.0721230506896973
Step: 55	 Data: torch.Size([10, 384])	 Training Loss: 1.3029197454452515
Step: 56	 Data: torch.Size([10, 384])	 Training Loss: 1.2104955911636353
Step: 57	 Data: torch.Size([10, 384])	 Training Loss: 1.031535029411316
Step: 58	 Data: torch.Size([10, 384])	 Training Loss: 1.2159583568572998
Step: 59	 Data: torch.Size([10, 384])	 Training Loss: 1.0502283573150635
Step: 60	 Data: torch.Size([10, 384])	 Training Loss: 1.086551308631897
Step: 61	 Data: torch.Size([10, 384])	 Training Loss: 0.9789131283760071
Step: 62	 Data: torch.Size([10, 384])	 Training Loss: 0.9741306304931641
Step: 63	 Data: torch.Size([10, 384])	 Training Loss: 0.9653540849685669
Step: 64	 Data: torch.Size([10, 384])	 Training Loss: 1.0446449518203735
Step: 65	 Data: torch.Size([10, 384])	 Training Loss: 1.024674892425537
Step: 66	 Data: torch.Size([10, 384])	 Training Loss: 1.1345287561416626
Step: 67	 Data: torch.Size([10, 384])	 Training Loss: 0.9617751836776733
Step: 68	 Data: torch.Size([10, 384])	 Training Loss: 1.02241849899292
Step: 69	 Data: torch.Size([10, 384])	 Training Loss: 1.1087961196899414
Step: 70	 Data: torch.Size([10, 384])	 Training Loss: 1.037885308265686
Step: 71	 Data: torch.Size([10, 384])	 Training Loss: 1.013095498085022
Step: 72	 Data: torch.Size([10, 384])	 Training Loss: 0.9305751919746399
Step: 73	 Data: torch.Size([10, 384])	 Training Loss: 0.923943281173706
Step: 74	 Data: torch.Size([10, 384])	 Training Loss: 0.9436558485031128
Step: 75	 Data: torch.Size([10, 384])	 Training Loss: 1.1118698120117188
Step: 76	 Data: torch.Size([10, 384])	 Training Loss: 0.9107888340950012
Step: 77	 Data: torch.Size([10, 384])	 Training Loss: 1.0513505935668945
Step: 78	 Data: torch.Size([10, 384])	 Training Loss: 1.052634596824646
Step: 79	 Data: torch.Size([10, 384])	 Training Loss: 1.205095648765564
Step: 80	 Data: torch.Size([10, 384])	 Training Loss: 1.0076619386672974
Step: 81	 Data: torch.Size([10, 384])	 Training Loss: 1.0358593463897705
Step: 82	 Data: torch.Size([10, 384])	 Training Loss: 1.0480684041976929
Step: 83	 Data: torch.Size([10, 384])	 Training Loss: 1.1268705129623413
Step: 84	 Data: torch.Size([10, 384])	 Training Loss: 1.0890995264053345
Step: 85	 Data: torch.Size([10, 384])	 Training Loss: 1.0543813705444336
Step: 86	 Data: torch.Size([10, 384])	 Training Loss: 1.1876051425933838
Step: 87	 Data: torch.Size([10, 384])	 Training Loss: 1.0315101146697998
Step: 88	 Data: torch.Size([10, 384])	 Training Loss: 1.131804347038269
Step: 89	 Data: torch.Size([10, 384])	 Training Loss: 0.9630077481269836
Step: 90	 Data: torch.Size([10, 384])	 Training Loss: 1.1382296085357666
Step: 91	 Data: torch.Size([10, 384])	 Training Loss: 0.8935635685920715
Step: 92	 Data: torch.Size([10, 384])	 Training Loss: 0.9168370962142944
Step: 93	 Data: torch.Size([10, 384])	 Training Loss: 0.917569637298584
Step: 94	 Data: torch.Size([10, 384])	 Training Loss: 0.8540570139884949
Step: 95	 Data: torch.Size([10, 384])	 Training Loss: 0.9137252569198608
Step: 96	 Data: torch.Size([10, 384])	 Training Loss: 0.9834169149398804
Step: 97	 Data: torch.Size([10, 384])	 Training Loss: 0.9999468922615051
Step: 98	 Data: torch.Size([10, 384])	 Training Loss: 1.1258323192596436
Step: 99	 Data: torch.Size([10, 384])	 Training Loss: 0.9421975612640381
Step: 100	 Data: torch.Size([10, 384])	 Training Loss: 0.9735056161880493
Step: 101	 Data: torch.Size([10, 384])	 Training Loss: 1.0611480474472046
Step: 102	 Data: torch.Size([10, 384])	 Training Loss: 1.0395280122756958
Step: 103	 Data: torch.Size([10, 384])	 Training Loss: 0.9939817786216736
Step: 104	 Data: torch.Size([10, 384])	 Training Loss: 1.1164512634277344
Step: 105	 Data: torch.Size([10, 384])	 Training Loss: 1.0329687595367432
Step: 106	 Data: torch.Size([10, 384])	 Training Loss: 0.9666138887405396
Step: 107	 Data: torch.Size([10, 384])	 Training Loss: 1.0236926078796387
Step: 108	 Data: torch.Size([10, 384])	 Training Loss: 0.8750693202018738
Step: 109	 Data: torch.Size([10, 384])	 Training Loss: 1.0683923959732056
Step: 110	 Data: torch.Size([10, 384])	 Training Loss: 1.0493083000183105
Step: 111	 Data: torch.Size([10, 384])	 Training Loss: 0.8505057096481323
Step: 112	 Data: torch.Size([10, 384])	 Training Loss: 1.0282152891159058
Step: 113	 Data: torch.Size([10, 384])	 Training Loss: 0.9675942063331604
Step: 114	 Data: torch.Size([10, 349])	 Training Loss: 0.9745476841926575
Step: 115	 Data: torch.Size([10, 384])	 Training Loss: 0.8168401718139648
Step: 116	 Data: torch.Size([10, 384])	 Training Loss: 0.9829175472259521
Step: 117	 Data: torch.Size([10, 384])	 Training Loss: 1.2595242261886597
Step: 118	 Data: torch.Size([10, 384])	 Training Loss: 0.8895251154899597
Step: 119	 Data: torch.Size([10, 384])	 Training Loss: 0.9098955392837524
Step: 120	 Data: torch.Size([10, 384])	 Training Loss: 0.9308357834815979
Step: 121	 Data: torch.Size([10, 384])	 Training Loss: 0.901337742805481
Step: 122	 Data: torch.Size([10, 384])	 Training Loss: 0.9953274726867676
Step: 123	 Data: torch.Size([10, 384])	 Training Loss: 0.9769686460494995
Step: 124	 Data: torch.Size([10, 384])	 Training Loss: 1.0392286777496338
Step: 125	 Data: torch.Size([10, 384])	 Training Loss: 1.0059040784835815
Step: 126	 Data: torch.Size([10, 384])	 Training Loss: 1.0960075855255127
Step: 127	 Data: torch.Size([10, 384])	 Training Loss: 0.8978244066238403
Step: 128	 Data: torch.Size([10, 384])	 Training Loss: 0.8821797966957092
Step: 129	 Data: torch.Size([10, 384])	 Training Loss: 0.9641423225402832
Step: 130	 Data: torch.Size([10, 384])	 Training Loss: 0.867464005947113
Step: 131	 Data: torch.Size([10, 384])	 Training Loss: 1.0287644863128662
Step: 132	 Data: torch.Size([10, 384])	 Training Loss: 0.9955224990844727
Step: 133	 Data: torch.Size([10, 384])	 Training Loss: 0.9589948654174805
Step: 134	 Data: torch.Size([10, 384])	 Training Loss: 0.8428400158882141
Step: 135	 Data: torch.Size([10, 384])	 Training Loss: 1.0235381126403809
Step: 136	 Data: torch.Size([10, 384])	 Training Loss: 0.9115175604820251
Step: 137	 Data: torch.Size([10, 384])	 Training Loss: 1.021392822265625
Step: 138	 Data: torch.Size([10, 384])	 Training Loss: 0.9314950704574585
Step: 139	 Data: torch.Size([10, 384])	 Training Loss: 0.9916830658912659
Step: 140	 Data: torch.Size([10, 384])	 Training Loss: 0.9679250717163086
Step: 141	 Data: torch.Size([10, 384])	 Training Loss: 1.0445747375488281
Step: 142	 Data: torch.Size([10, 384])	 Training Loss: 1.0087858438491821
Step: 143	 Data: torch.Size([10, 384])	 Training Loss: 1.0355356931686401
Step: 144	 Data: torch.Size([10, 384])	 Training Loss: 1.0372488498687744
Step: 145	 Data: torch.Size([10, 384])	 Training Loss: 0.8793100714683533
Step: 146	 Data: torch.Size([10, 384])	 Training Loss: 0.8354355096817017
Step: 147	 Data: torch.Size([10, 384])	 Training Loss: 0.9373486638069153
Step: 148	 Data: torch.Size([10, 384])	 Training Loss: 0.8860443830490112
Step: 149	 Data: torch.Size([10, 384])	 Training Loss: 1.0871440172195435
Step: 150	 Data: torch.Size([10, 384])	 Training Loss: 0.8780844807624817
Step: 151	 Data: torch.Size([10, 384])	 Training Loss: 0.8216745853424072
Step: 152	 Data: torch.Size([10, 384])	 Training Loss: 0.9489896297454834
Step: 153	 Data: torch.Size([10, 384])	 Training Loss: 1.149169921875
Step: 154	 Data: torch.Size([10, 384])	 Training Loss: 0.8782032132148743
Step: 155	 Data: torch.Size([10, 384])	 Training Loss: 0.9876144528388977
Step: 156	 Data: torch.Size([10, 384])	 Training Loss: 0.9994314312934875
Step: 157	 Data: torch.Size([10, 384])	 Training Loss: 0.933082640171051
Step: 158	 Data: torch.Size([10, 384])	 Training Loss: 0.8531062006950378
Step: 159	 Data: torch.Size([10, 384])	 Training Loss: 1.0752818584442139
Step: 160	 Data: torch.Size([10, 384])	 Training Loss: 1.0136024951934814
Step: 161	 Data: torch.Size([10, 384])	 Training Loss: 0.8932241797447205
Step: 162	 Data: torch.Size([10, 384])	 Training Loss: 0.9110031127929688
Step: 163	 Data: torch.Size([10, 384])	 Training Loss: 0.9533376097679138
Step: 164	 Data: torch.Size([10, 384])	 Training Loss: 0.8591558933258057
Step: 165	 Data: torch.Size([10, 384])	 Training Loss: 0.9331380724906921
Step: 166	 Data: torch.Size([10, 384])	 Training Loss: 1.034464716911316
Step: 167	 Data: torch.Size([10, 384])	 Training Loss: 0.7824376225471497
Step: 168	 Data: torch.Size([10, 384])	 Training Loss: 0.9916785359382629
Step: 169	 Data: torch.Size([10, 384])	 Training Loss: 0.9231582283973694
Step: 170	 Data: torch.Size([10, 384])	 Training Loss: 0.9176098704338074
Step: 171	 Data: torch.Size([10, 384])	 Training Loss: 0.9431413412094116
Step: 172	 Data: torch.Size([10, 384])	 Training Loss: 0.8877094388008118
Step: 173	 Data: torch.Size([10, 384])	 Training Loss: 1.1042821407318115
Step: 174	 Data: torch.Size([10, 384])	 Training Loss: 0.9327605366706848
Step: 175	 Data: torch.Size([10, 384])	 Training Loss: 1.0791326761245728
Step: 176	 Data: torch.Size([10, 384])	 Training Loss: 0.8236865401268005
Step: 177	 Data: torch.Size([10, 346])	 Training Loss: 0.9465743899345398
Step: 178	 Data: torch.Size([10, 384])	 Training Loss: 0.8140036463737488
Step: 179	 Data: torch.Size([10, 384])	 Training Loss: 0.8714385628700256
Step: 180	 Data: torch.Size([10, 384])	 Training Loss: 0.9275762438774109
Step: 181	 Data: torch.Size([10, 384])	 Training Loss: 0.9298260807991028
Step: 182	 Data: torch.Size([10, 384])	 Training Loss: 0.9627837538719177
Step: 183	 Data: torch.Size([10, 384])	 Training Loss: 0.8949428796768188
Step: 184	 Data: torch.Size([10, 384])	 Training Loss: 1.1181498765945435
Step: 185	 Data: torch.Size([10, 384])	 Training Loss: 1.0668689012527466
Step: 186	 Data: torch.Size([10, 384])	 Training Loss: 0.9476025104522705
Step: 187	 Data: torch.Size([10, 384])	 Training Loss: 1.0583124160766602
Step: 188	 Data: torch.Size([10, 384])	 Training Loss: 0.9433175325393677
Step: 189	 Data: torch.Size([10, 384])	 Training Loss: 0.9994378089904785
Step: 190	 Data: torch.Size([10, 384])	 Training Loss: 0.9918977618217468
Step: 191	 Data: torch.Size([10, 384])	 Training Loss: 1.0219045877456665
Step: 192	 Data: torch.Size([10, 384])	 Training Loss: 0.8402760624885559
Step: 193	 Data: torch.Size([10, 384])	 Training Loss: 0.8915233612060547
Step: 194	 Data: torch.Size([10, 384])	 Training Loss: 1.0415308475494385
Step: 195	 Data: torch.Size([10, 384])	 Training Loss: 0.9492788314819336
Step: 196	 Data: torch.Size([10, 384])	 Training Loss: 0.9839459657669067
Step: 197	 Data: torch.Size([10, 384])	 Training Loss: 0.9834364652633667
Step: 198	 Data: torch.Size([10, 384])	 Training Loss: 0.8559333086013794
Step: 199	 Data: torch.Size([10, 384])	 Training Loss: 0.8780770897865295
Step: 200	 Data: torch.Size([10, 384])	 Training Loss: 0.8319569826126099
Step: 201	 Data: torch.Size([10, 384])	 Training Loss: 0.9765976071357727
Step: 202	 Data: torch.Size([10, 277])	 Training Loss: 1.1313425302505493
Step: 203	 Data: torch.Size([10, 384])	 Training Loss: 0.9625287652015686
Step: 204	 Data: torch.Size([10, 384])	 Training Loss: 0.9421571493148804
Step: 205	 Data: torch.Size([10, 384])	 Training Loss: 1.0868737697601318
Step: 206	 Data: torch.Size([10, 356])	 Training Loss: 0.9516384601593018
Step: 207	 Data: torch.Size([10, 384])	 Training Loss: 0.9376548528671265
Step: 208	 Data: torch.Size([10, 384])	 Training Loss: 0.7965653538703918
Step: 209	 Data: torch.Size([10, 384])	 Training Loss: 0.8761728405952454
Step: 210	 Data: torch.Size([10, 384])	 Training Loss: 1.0324839353561401
Step: 211	 Data: torch.Size([10, 355])	 Training Loss: 0.9207972288131714
Step: 212	 Data: torch.Size([10, 384])	 Training Loss: 0.8932876586914062
Step: 213	 Data: torch.Size([10, 384])	 Training Loss: 1.109633207321167
Step: 214	 Data: torch.Size([10, 384])	 Training Loss: 0.9209802150726318
Step: 215	 Data: torch.Size([10, 384])	 Training Loss: 0.8630483746528625
Step: 216	 Data: torch.Size([10, 384])	 Training Loss: 0.8280240893363953
Step: 217	 Data: torch.Size([10, 384])	 Training Loss: 0.8915038704872131
Step: 218	 Data: torch.Size([10, 384])	 Training Loss: 0.9163194894790649
Step: 219	 Data: torch.Size([10, 384])	 Training Loss: 0.9211596846580505
Step: 220	 Data: torch.Size([10, 384])	 Training Loss: 0.8601547479629517
Step: 221	 Data: torch.Size([10, 384])	 Training Loss: 0.9756242632865906
Step: 222	 Data: torch.Size([10, 384])	 Training Loss: 0.9201510548591614
Step: 223	 Data: torch.Size([10, 384])	 Training Loss: 0.9637542963027954
Step: 224	 Data: torch.Size([10, 384])	 Training Loss: 0.893600583076477
Step: 225	 Data: torch.Size([10, 384])	 Training Loss: 0.9097142815589905
Step: 226	 Data: torch.Size([10, 384])	 Training Loss: 1.078502893447876
Step: 227	 Data: torch.Size([10, 384])	 Training Loss: 0.9780448079109192
Step: 228	 Data: torch.Size([10, 384])	 Training Loss: 0.7763211131095886
Step: 229	 Data: torch.Size([10, 384])	 Training Loss: 0.9362170696258545
Step: 230	 Data: torch.Size([10, 384])	 Training Loss: 0.9516851902008057
Step: 231	 Data: torch.Size([10, 384])	 Training Loss: 0.7673695087432861
Step: 232	 Data: torch.Size([10, 384])	 Training Loss: 0.9119582176208496
Step: 233	 Data: torch.Size([10, 384])	 Training Loss: 0.8852167129516602
Step: 234	 Data: torch.Size([10, 384])	 Training Loss: 1.162462830543518
Step: 235	 Data: torch.Size([10, 384])	 Training Loss: 0.9697198867797852
Step: 236	 Data: torch.Size([10, 384])	 Training Loss: 1.0215706825256348
Step: 237	 Data: torch.Size([10, 384])	 Training Loss: 0.9567714333534241
Step: 238	 Data: torch.Size([10, 384])	 Training Loss: 1.0065503120422363
Step: 239	 Data: torch.Size([10, 384])	 Training Loss: 1.0286189317703247
Step: 240	 Data: torch.Size([10, 384])	 Training Loss: 0.9820327162742615
Step: 241	 Data: torch.Size([10, 384])	 Training Loss: 1.0692126750946045
Step: 242	 Data: torch.Size([10, 384])	 Training Loss: 0.9778478145599365
Step: 243	 Data: torch.Size([10, 384])	 Training Loss: 0.9863665699958801
Step: 244	 Data: torch.Size([10, 384])	 Training Loss: 0.8935779929161072
Step: 245	 Data: torch.Size([10, 384])	 Training Loss: 0.9639030694961548
Step: 246	 Data: torch.Size([10, 384])	 Training Loss: 1.1034095287322998
Step: 247	 Data: torch.Size([10, 384])	 Training Loss: 0.9606103301048279
Step: 248	 Data: torch.Size([10, 384])	 Training Loss: 1.0219002962112427
Step: 249	 Data: torch.Size([10, 384])	 Training Loss: 1.0832033157348633
Step: 250	 Data: torch.Size([10, 340])	 Training Loss: 1.1452865600585938
Step: 251	 Data: torch.Size([10, 384])	 Training Loss: 0.9835337996482849
Step: 252	 Data: torch.Size([10, 384])	 Training Loss: 0.8531038761138916
Step: 253	 Data: torch.Size([10, 384])	 Training Loss: 1.0052505731582642
Step: 254	 Data: torch.Size([10, 384])	 Training Loss: 0.8626900911331177
Step: 255	 Data: torch.Size([10, 384])	 Training Loss: 0.9513528943061829
Step: 256	 Data: torch.Size([10, 384])	 Training Loss: 0.9416758418083191
Step: 257	 Data: torch.Size([10, 384])	 Training Loss: 0.9334842562675476
Step: 258	 Data: torch.Size([10, 384])	 Training Loss: 0.8912990093231201
Step: 259	 Data: torch.Size([10, 384])	 Training Loss: 0.9066716432571411
Step: 260	 Data: torch.Size([10, 384])	 Training Loss: 0.8941404819488525
Step: 261	 Data: torch.Size([10, 384])	 Training Loss: 0.8323216438293457
Step: 262	 Data: torch.Size([10, 384])	 Training Loss: 0.9254550933837891
Step: 263	 Data: torch.Size([10, 384])	 Training Loss: 0.9266517162322998
Step: 264	 Data: torch.Size([10, 384])	 Training Loss: 0.8300518989562988
Step: 265	 Data: torch.Size([10, 384])	 Training Loss: 0.851150393486023
Step: 266	 Data: torch.Size([10, 384])	 Training Loss: 0.9963143467903137
Step: 267	 Data: torch.Size([10, 384])	 Training Loss: 0.8756767511367798
Step: 268	 Data: torch.Size([10, 384])	 Training Loss: 0.9100965261459351
Step: 269	 Data: torch.Size([10, 384])	 Training Loss: 0.9853172302246094
Step: 270	 Data: torch.Size([10, 384])	 Training Loss: 0.9403368234634399
Step: 271	 Data: torch.Size([10, 384])	 Training Loss: 0.9066095352172852
Step: 272	 Data: torch.Size([10, 384])	 Training Loss: 1.0132246017456055
Step: 273	 Data: torch.Size([10, 384])	 Training Loss: 0.923127293586731
Step: 274	 Data: torch.Size([10, 384])	 Training Loss: 1.0140219926834106
Step: 275	 Data: torch.Size([10, 384])	 Training Loss: 0.9327890872955322
Step: 276	 Data: torch.Size([10, 384])	 Training Loss: 0.9754467010498047
Step: 277	 Data: torch.Size([10, 384])	 Training Loss: 0.9117979407310486
Step: 278	 Data: torch.Size([10, 384])	 Training Loss: 0.9473860859870911
Step: 279	 Data: torch.Size([10, 384])	 Training Loss: 0.9141126275062561
Step: 280	 Data: torch.Size([10, 384])	 Training Loss: 0.7979589700698853
Step: 281	 Data: torch.Size([10, 384])	 Training Loss: 1.0884238481521606
Step: 282	 Data: torch.Size([10, 384])	 Training Loss: 0.9278675317764282
Step: 283	 Data: torch.Size([10, 384])	 Training Loss: 0.8521627187728882
Step: 284	 Data: torch.Size([10, 384])	 Training Loss: 1.0471198558807373
Step: 285	 Data: torch.Size([10, 384])	 Training Loss: 0.8474650382995605
Step: 286	 Data: torch.Size([10, 384])	 Training Loss: 0.99152672290802
Step: 287	 Data: torch.Size([10, 384])	 Training Loss: 0.9730628132820129
Step: 288	 Data: torch.Size([10, 384])	 Training Loss: 1.0087424516677856
Step: 289	 Data: torch.Size([10, 384])	 Training Loss: 0.939710259437561
Step: 290	 Data: torch.Size([10, 384])	 Training Loss: 0.9115911722183228
Step: 291	 Data: torch.Size([10, 384])	 Training Loss: 0.9315254092216492
Step: 292	 Data: torch.Size([10, 384])	 Training Loss: 0.8039326071739197
Step: 293	 Data: torch.Size([10, 372])	 Training Loss: 0.8401485085487366
Step: 294	 Data: torch.Size([10, 384])	 Training Loss: 1.0404345989227295
Step: 295	 Data: torch.Size([10, 384])	 Training Loss: 0.8600425124168396
Step: 296	 Data: torch.Size([10, 384])	 Training Loss: 0.9271794557571411
Step: 297	 Data: torch.Size([10, 213])	 Training Loss: 1.0750300884246826
Step: 298	 Data: torch.Size([10, 384])	 Training Loss: 1.0120658874511719
Step: 299	 Data: torch.Size([10, 384])	 Training Loss: 0.8687546253204346
Step: 300	 Data: torch.Size([10, 384])	 Training Loss: 1.0360256433486938
Step: 301	 Data: torch.Size([10, 384])	 Training Loss: 1.0797314643859863
Step: 302	 Data: torch.Size([10, 384])	 Training Loss: 0.8976221084594727
Step: 303	 Data: torch.Size([10, 384])	 Training Loss: 0.9349043369293213
Step: 304	 Data: torch.Size([10, 384])	 Training Loss: 0.8851714730262756
Step: 305	 Data: torch.Size([10, 384])	 Training Loss: 0.8788472414016724
Step: 306	 Data: torch.Size([10, 384])	 Training Loss: 1.0780730247497559
Step: 307	 Data: torch.Size([10, 384])	 Training Loss: 0.9584076404571533
Step: 308	 Data: torch.Size([10, 384])	 Training Loss: 1.1076985597610474
Step: 309	 Data: torch.Size([10, 384])	 Training Loss: 0.9775431752204895
Step: 310	 Data: torch.Size([10, 384])	 Training Loss: 0.9965543150901794
Step: 311	 Data: torch.Size([10, 384])	 Training Loss: 0.9832859635353088
Step: 312	 Data: torch.Size([10, 384])	 Training Loss: 0.8574464321136475
Step: 313	 Data: torch.Size([10, 384])	 Training Loss: 0.9265463352203369
Step: 314	 Data: torch.Size([10, 384])	 Training Loss: 0.9623146653175354
Step: 315	 Data: torch.Size([10, 384])	 Training Loss: 1.000093936920166
Step: 316	 Data: torch.Size([10, 384])	 Training Loss: 0.8275824785232544
Step: 317	 Data: torch.Size([10, 384])	 Training Loss: 0.8990225791931152
Step: 318	 Data: torch.Size([10, 384])	 Training Loss: 1.1403825283050537
Step: 319	 Data: torch.Size([10, 384])	 Training Loss: 0.9636803865432739
Step: 320	 Data: torch.Size([10, 384])	 Training Loss: 1.2340542078018188
Step: 321	 Data: torch.Size([10, 384])	 Training Loss: 0.9931294918060303
Step: 322	 Data: torch.Size([10, 384])	 Training Loss: 1.150687575340271
Step: 323	 Data: torch.Size([10, 384])	 Training Loss: 0.9460711479187012
Step: 324	 Data: torch.Size([10, 384])	 Training Loss: 0.9011101722717285
Step: 325	 Data: torch.Size([10, 384])	 Training Loss: 0.8277735114097595
Step: 326	 Data: torch.Size([10, 384])	 Training Loss: 0.8155721426010132
Step: 327	 Data: torch.Size([10, 384])	 Training Loss: 0.8002416491508484
Step: 328	 Data: torch.Size([10, 384])	 Training Loss: 1.1288520097732544
Step: 329	 Data: torch.Size([10, 384])	 Training Loss: 1.1157110929489136
Step: 330	 Data: torch.Size([10, 384])	 Training Loss: 0.9490776658058167
Step: 331	 Data: torch.Size([10, 384])	 Training Loss: 0.7876155972480774
Step: 332	 Data: torch.Size([10, 384])	 Training Loss: 0.9997060298919678
Step: 333	 Data: torch.Size([10, 384])	 Training Loss: 0.9578779339790344
Step: 334	 Data: torch.Size([10, 384])	 Training Loss: 0.9709962606430054
Step: 335	 Data: torch.Size([10, 384])	 Training Loss: 0.8285603523254395
Step: 336	 Data: torch.Size([10, 384])	 Training Loss: 0.823128879070282
Step: 337	 Data: torch.Size([10, 384])	 Training Loss: 1.0925793647766113
Step: 338	 Data: torch.Size([10, 384])	 Training Loss: 1.0459675788879395
Step: 339	 Data: torch.Size([10, 384])	 Training Loss: 0.9309136271476746
Step: 340	 Data: torch.Size([10, 384])	 Training Loss: 0.8137066960334778
Step: 341	 Data: torch.Size([10, 384])	 Training Loss: 0.8240793347358704
Step: 342	 Data: torch.Size([10, 384])	 Training Loss: 0.97272789478302
Step: 343	 Data: torch.Size([10, 384])	 Training Loss: 1.053383231163025
Step: 344	 Data: torch.Size([10, 384])	 Training Loss: 1.085084319114685
Step: 345	 Data: torch.Size([10, 384])	 Training Loss: 0.9885976314544678
Step: 346	 Data: torch.Size([10, 384])	 Training Loss: 0.9349830746650696
Step: 347	 Data: torch.Size([10, 384])	 Training Loss: 1.063314437866211
Step: 348	 Data: torch.Size([10, 384])	 Training Loss: 0.9544282555580139
Step: 349	 Data: torch.Size([10, 384])	 Training Loss: 0.8778300881385803
Step: 350	 Data: torch.Size([10, 384])	 Training Loss: 0.9042010307312012
Step: 351	 Data: torch.Size([10, 384])	 Training Loss: 0.8712952136993408
Step: 352	 Data: torch.Size([10, 384])	 Training Loss: 0.9058584570884705
Step: 353	 Data: torch.Size([10, 384])	 Training Loss: 0.9711366295814514
Step: 354	 Data: torch.Size([10, 384])	 Training Loss: 0.9592649936676025
Step: 355	 Data: torch.Size([10, 384])	 Training Loss: 0.8674483299255371
Step: 356	 Data: torch.Size([10, 384])	 Training Loss: 1.0921897888183594
Step: 357	 Data: torch.Size([10, 384])	 Training Loss: 0.9811212420463562
Step: 358	 Data: torch.Size([10, 384])	 Training Loss: 1.0325934886932373
Step: 359	 Data: torch.Size([10, 384])	 Training Loss: 0.965400755405426
Step: 360	 Data: torch.Size([10, 384])	 Training Loss: 0.9732968211174011
Step: 361	 Data: torch.Size([10, 384])	 Training Loss: 0.8239045143127441
Step: 362	 Data: torch.Size([10, 384])	 Training Loss: 0.8186132311820984
Step: 363	 Data: torch.Size([10, 384])	 Training Loss: 0.9323843717575073
Step: 364	 Data: torch.Size([10, 384])	 Training Loss: 0.9882490634918213
Step: 365	 Data: torch.Size([10, 384])	 Training Loss: 0.8199194073677063
Step: 366	 Data: torch.Size([10, 384])	 Training Loss: 0.7797045111656189
Step: 367	 Data: torch.Size([10, 384])	 Training Loss: 0.8972555994987488
Step: 368	 Data: torch.Size([10, 384])	 Training Loss: 1.0227988958358765
Step: 369	 Data: torch.Size([10, 384])	 Training Loss: 0.9910823106765747
Step: 370	 Data: torch.Size([10, 384])	 Training Loss: 0.9128859043121338
Step: 371	 Data: torch.Size([10, 384])	 Training Loss: 0.8425738215446472
Step: 372	 Data: torch.Size([10, 384])	 Training Loss: 1.0045291185379028
Step: 373	 Data: torch.Size([10, 384])	 Training Loss: 0.959138810634613
Step: 374	 Data: torch.Size([10, 384])	 Training Loss: 0.8727229833602905
Step: 375	 Data: torch.Size([10, 384])	 Training Loss: 0.8436322808265686
Step: 376	 Data: torch.Size([10, 384])	 Training Loss: 0.8797215223312378
Step: 377	 Data: torch.Size([10, 384])	 Training Loss: 0.9774572253227234
Step: 378	 Data: torch.Size([10, 384])	 Training Loss: 0.9102684855461121
Step: 379	 Data: torch.Size([10, 384])	 Training Loss: 0.8475855588912964
Step: 380	 Data: torch.Size([10, 384])	 Training Loss: 1.0085556507110596
Step: 381	 Data: torch.Size([10, 384])	 Training Loss: 0.8720086812973022
Step: 382	 Data: torch.Size([10, 384])	 Training Loss: 0.892683744430542
Step: 383	 Data: torch.Size([10, 384])	 Training Loss: 0.9324672818183899
Step: 384	 Data: torch.Size([10, 384])	 Training Loss: 0.816452145576477
Step: 385	 Data: torch.Size([10, 384])	 Training Loss: 0.8380820155143738
Step: 386	 Data: torch.Size([10, 384])	 Training Loss: 0.9861562252044678
Step: 387	 Data: torch.Size([10, 384])	 Training Loss: 0.8550942540168762
Step: 388	 Data: torch.Size([10, 384])	 Training Loss: 0.9409106969833374
Step: 389	 Data: torch.Size([10, 384])	 Training Loss: 1.144716501235962
Step: 390	 Data: torch.Size([10, 384])	 Training Loss: 0.890284538269043
Step: 391	 Data: torch.Size([10, 384])	 Training Loss: 1.0968563556671143
Step: 392	 Data: torch.Size([10, 384])	 Training Loss: 0.9524180889129639
Step: 393	 Data: torch.Size([10, 384])	 Training Loss: 0.9152011275291443
Step: 394	 Data: torch.Size([10, 270])	 Training Loss: 0.8554267287254333
Step: 395	 Data: torch.Size([10, 384])	 Training Loss: 0.9423017501831055
Step: 396	 Data: torch.Size([10, 384])	 Training Loss: 0.8896671533584595
Step: 397	 Data: torch.Size([10, 384])	 Training Loss: 0.8960949182510376
Step: 398	 Data: torch.Size([10, 384])	 Training Loss: 0.945963978767395
Step: 399	 Data: torch.Size([10, 384])	 Training Loss: 0.9967989921569824
Step: 400	 Data: torch.Size([10, 384])	 Training Loss: 0.9766495227813721
Step: 401	 Data: torch.Size([10, 384])	 Training Loss: 0.9843645691871643
Step: 402	 Data: torch.Size([10, 384])	 Training Loss: 0.8334658741950989
Step: 403	 Data: torch.Size([10, 384])	 Training Loss: 0.9887488484382629
Step: 404	 Data: torch.Size([10, 384])	 Training Loss: 0.9658727049827576
Step: 405	 Data: torch.Size([10, 384])	 Training Loss: 1.109879970550537
Step: 406	 Data: torch.Size([10, 384])	 Training Loss: 1.007267713546753
Step: 407	 Data: torch.Size([10, 384])	 Training Loss: 0.8676435947418213
Step: 408	 Data: torch.Size([10, 384])	 Training Loss: 0.9126938581466675
Step: 409	 Data: torch.Size([10, 384])	 Training Loss: 0.8224080204963684
Step: 410	 Data: torch.Size([10, 384])	 Training Loss: 0.8869918584823608
Step: 411	 Data: torch.Size([10, 384])	 Training Loss: 0.9048280715942383
Step: 412	 Data: torch.Size([10, 384])	 Training Loss: 1.0076394081115723
Step: 413	 Data: torch.Size([10, 384])	 Training Loss: 0.9376088380813599
Step: 414	 Data: torch.Size([10, 384])	 Training Loss: 0.9644591808319092
Step: 415	 Data: torch.Size([10, 384])	 Training Loss: 0.8967506289482117
Step: 416	 Data: torch.Size([10, 384])	 Training Loss: 1.0372065305709839
Step: 417	 Data: torch.Size([10, 384])	 Training Loss: 0.9215286374092102
Step: 418	 Data: torch.Size([10, 384])	 Training Loss: 1.0199276208877563
Step: 419	 Data: torch.Size([10, 384])	 Training Loss: 0.9351944923400879
Step: 420	 Data: torch.Size([10, 384])	 Training Loss: 0.7979356050491333
Step: 421	 Data: torch.Size([10, 384])	 Training Loss: 0.8232255578041077
Step: 422	 Data: torch.Size([10, 384])	 Training Loss: 0.907455325126648
Step: 423	 Data: torch.Size([10, 384])	 Training Loss: 0.8283388018608093
Step: 424	 Data: torch.Size([10, 384])	 Training Loss: 0.8362343907356262
Step: 425	 Data: torch.Size([10, 384])	 Training Loss: 0.8989484310150146
Step: 426	 Data: torch.Size([10, 384])	 Training Loss: 0.8496455550193787
Step: 427	 Data: torch.Size([10, 384])	 Training Loss: 0.9854258298873901
Step: 428	 Data: torch.Size([10, 384])	 Training Loss: 0.8822040557861328
Step: 429	 Data: torch.Size([10, 384])	 Training Loss: 0.8662537336349487
Step: 430	 Data: torch.Size([10, 384])	 Training Loss: 0.9563471674919128
Step: 431	 Data: torch.Size([10, 384])	 Training Loss: 0.8389358520507812
Step: 432	 Data: torch.Size([10, 384])	 Training Loss: 0.9679023027420044
Step: 433	 Data: torch.Size([10, 384])	 Training Loss: 0.8648560047149658
Step: 434	 Data: torch.Size([10, 384])	 Training Loss: 0.9795558452606201
Step: 435	 Data: torch.Size([10, 384])	 Training Loss: 0.7610499262809753
Step: 436	 Data: torch.Size([10, 384])	 Training Loss: 0.8369001150131226
Step: 437	 Data: torch.Size([10, 384])	 Training Loss: 0.9909610152244568
Step: 438	 Data: torch.Size([10, 384])	 Training Loss: 0.9902975559234619
Step: 439	 Data: torch.Size([10, 384])	 Training Loss: 1.1211555004119873
Step: 440	 Data: torch.Size([10, 384])	 Training Loss: 0.872706949710846
Step: 441	 Data: torch.Size([10, 384])	 Training Loss: 0.927274227142334
Step: 442	 Data: torch.Size([10, 384])	 Training Loss: 1.0032274723052979
Step: 443	 Data: torch.Size([10, 384])	 Training Loss: 0.8593011498451233
Step: 444	 Data: torch.Size([10, 384])	 Training Loss: 0.9251856803894043
Step: 445	 Data: torch.Size([10, 384])	 Training Loss: 1.0103784799575806
Step: 446	 Data: torch.Size([10, 384])	 Training Loss: 0.9754419326782227
Step: 447	 Data: torch.Size([10, 384])	 Training Loss: 0.979804277420044
Step: 448	 Data: torch.Size([10, 384])	 Training Loss: 0.8011220097541809
Step: 449	 Data: torch.Size([10, 384])	 Training Loss: 1.0806620121002197
Step: 450	 Data: torch.Size([10, 384])	 Training Loss: 0.8795834183692932
Step: 451	 Data: torch.Size([10, 384])	 Training Loss: 0.9314282536506653
Step: 452	 Data: torch.Size([10, 384])	 Training Loss: 0.866569995880127
Step: 453	 Data: torch.Size([10, 384])	 Training Loss: 0.9289551377296448
Step: 454	 Data: torch.Size([10, 384])	 Training Loss: 1.0974721908569336
Step: 455	 Data: torch.Size([10, 384])	 Training Loss: 0.977202832698822
Step: 456	 Data: torch.Size([10, 384])	 Training Loss: 0.8831712007522583
Step: 457	 Data: torch.Size([10, 384])	 Training Loss: 0.9559749960899353
Step: 458	 Data: torch.Size([10, 384])	 Training Loss: 0.9220297336578369
Step: 459	 Data: torch.Size([10, 384])	 Training Loss: 1.0363105535507202
Step: 460	 Data: torch.Size([10, 384])	 Training Loss: 0.9223257303237915
Step: 461	 Data: torch.Size([10, 384])	 Training Loss: 0.9705410599708557
Step: 462	 Data: torch.Size([10, 384])	 Training Loss: 1.0789811611175537
Step: 463	 Data: torch.Size([10, 384])	 Training Loss: 0.8875707983970642
Step: 464	 Data: torch.Size([10, 306])	 Training Loss: 1.0570616722106934
Step: 465	 Data: torch.Size([10, 249])	 Training Loss: 0.9707251787185669
Step: 466	 Data: torch.Size([10, 384])	 Training Loss: 0.9504347443580627
Step: 467	 Data: torch.Size([10, 384])	 Training Loss: 0.9672595262527466
Step: 468	 Data: torch.Size([10, 384])	 Training Loss: 1.056476354598999
Step: 469	 Data: torch.Size([10, 384])	 Training Loss: 0.9940054416656494
Step: 470	 Data: torch.Size([10, 384])	 Training Loss: 0.99958336353302
Step: 471	 Data: torch.Size([10, 384])	 Training Loss: 0.888138473033905
Step: 472	 Data: torch.Size([10, 384])	 Training Loss: 0.8770489692687988
Step: 473	 Data: torch.Size([10, 384])	 Training Loss: 1.0694611072540283
Step: 474	 Data: torch.Size([10, 384])	 Training Loss: 1.0129448175430298
Step: 475	 Data: torch.Size([10, 384])	 Training Loss: 0.9431701302528381
Step: 476	 Data: torch.Size([10, 384])	 Training Loss: 1.1210341453552246
Step: 477	 Data: torch.Size([10, 384])	 Training Loss: 0.8409632444381714
Step: 478	 Data: torch.Size([10, 384])	 Training Loss: 0.9603918194770813
Step: 479	 Data: torch.Size([10, 384])	 Training Loss: 0.9695650935173035
Step: 480	 Data: torch.Size([10, 384])	 Training Loss: 0.9822254180908203
Step: 481	 Data: torch.Size([10, 384])	 Training Loss: 0.7913315892219543
Step: 482	 Data: torch.Size([10, 384])	 Training Loss: 1.0184932947158813
Step: 483	 Data: torch.Size([10, 384])	 Training Loss: 1.0347203016281128
Step: 484	 Data: torch.Size([10, 384])	 Training Loss: 0.8292751312255859
Step: 485	 Data: torch.Size([10, 384])	 Training Loss: 0.8397963643074036
Step: 486	 Data: torch.Size([10, 384])	 Training Loss: 0.9874066114425659
Step: 487	 Data: torch.Size([10, 384])	 Training Loss: 0.8107066750526428
Step: 488	 Data: torch.Size([10, 384])	 Training Loss: 0.9804945588111877
Step: 489	 Data: torch.Size([10, 384])	 Training Loss: 0.8944641947746277
Step: 490	 Data: torch.Size([10, 384])	 Training Loss: 0.8388309478759766
Step: 491	 Data: torch.Size([10, 384])	 Training Loss: 0.765561580657959
Step: 492	 Data: torch.Size([10, 384])	 Training Loss: 0.8487333655357361
Step: 493	 Data: torch.Size([10, 384])	 Training Loss: 0.8962829113006592
Step: 494	 Data: torch.Size([10, 384])	 Training Loss: 0.8145328760147095
Step: 495	 Data: torch.Size([10, 384])	 Training Loss: 1.057323932647705
Step: 496	 Data: torch.Size([10, 384])	 Training Loss: 0.9451760053634644
Step: 497	 Data: torch.Size([10, 384])	 Training Loss: 1.0218483209609985
Step: 498	 Data: torch.Size([10, 384])	 Training Loss: 1.0082727670669556
Step: 499	 Data: torch.Size([10, 384])	 Training Loss: 0.8994731903076172
Step: 500	 Data: torch.Size([10, 384])	 Training Loss: 0.8676232099533081
Step: 501	 Data: torch.Size([10, 384])	 Training Loss: 0.8681697845458984
Step: 502	 Data: torch.Size([10, 384])	 Training Loss: 0.9461170434951782
Step: 503	 Data: torch.Size([10, 384])	 Training Loss: 0.8297277688980103
Step: 504	 Data: torch.Size([10, 384])	 Training Loss: 0.8562038540840149
Step: 505	 Data: torch.Size([10, 384])	 Training Loss: 1.0339065790176392
Step: 506	 Data: torch.Size([10, 384])	 Training Loss: 0.7979835867881775
Step: 507	 Data: torch.Size([10, 384])	 Training Loss: 0.8166252970695496
Step: 508	 Data: torch.Size([10, 384])	 Training Loss: 0.9580916166305542
Step: 509	 Data: torch.Size([10, 384])	 Training Loss: 0.871739387512207
Step: 510	 Data: torch.Size([10, 384])	 Training Loss: 0.963259756565094
Step: 511	 Data: torch.Size([10, 384])	 Training Loss: 0.7628973722457886
Step: 512	 Data: torch.Size([10, 384])	 Training Loss: 1.1753133535385132
Step: 513	 Data: torch.Size([10, 384])	 Training Loss: 1.182345986366272
Step: 514	 Data: torch.Size([10, 384])	 Training Loss: 0.8724324703216553
Step: 515	 Data: torch.Size([10, 302])	 Training Loss: 0.8430947661399841
Step: 516	 Data: torch.Size([10, 384])	 Training Loss: 1.0661510229110718
Step: 517	 Data: torch.Size([10, 384])	 Training Loss: 0.9128244519233704
Step: 518	 Data: torch.Size([10, 384])	 Training Loss: 0.8932619094848633
Step: 519	 Data: torch.Size([10, 384])	 Training Loss: 1.0266345739364624
Step: 520	 Data: torch.Size([10, 384])	 Training Loss: 0.7851666212081909
Step: 521	 Data: torch.Size([10, 384])	 Training Loss: 0.957671046257019
Step: 522	 Data: torch.Size([10, 384])	 Training Loss: 1.1100986003875732
Step: 523	 Data: torch.Size([10, 384])	 Training Loss: 0.9224945902824402
Step: 524	 Data: torch.Size([10, 384])	 Training Loss: 1.0017979145050049
Step: 525	 Data: torch.Size([10, 384])	 Training Loss: 0.9708318710327148
Step: 526	 Data: torch.Size([10, 384])	 Training Loss: 0.968032717704773
Step: 527	 Data: torch.Size([10, 384])	 Training Loss: 0.838119626045227
Step: 528	 Data: torch.Size([10, 384])	 Training Loss: 0.8598321080207825
Step: 529	 Data: torch.Size([10, 384])	 Training Loss: 0.896442711353302
Step: 530	 Data: torch.Size([10, 384])	 Training Loss: 0.981877326965332
Step: 531	 Data: torch.Size([10, 384])	 Training Loss: 0.996012806892395
Step: 532	 Data: torch.Size([10, 384])	 Training Loss: 0.805803656578064
Step: 533	 Data: torch.Size([10, 384])	 Training Loss: 1.069281816482544
Step: 534	 Data: torch.Size([10, 384])	 Training Loss: 0.9561265110969543
Step: 535	 Data: torch.Size([10, 384])	 Training Loss: 0.8795590400695801
Step: 536	 Data: torch.Size([10, 384])	 Training Loss: 0.8922723531723022
Step: 537	 Data: torch.Size([10, 384])	 Training Loss: 0.905899167060852
Step: 538	 Data: torch.Size([10, 384])	 Training Loss: 1.0270575284957886
Step: 539	 Data: torch.Size([10, 384])	 Training Loss: 0.7993777990341187
Step: 540	 Data: torch.Size([10, 384])	 Training Loss: 0.941676139831543
Step: 541	 Data: torch.Size([10, 384])	 Training Loss: 0.9482268691062927
Step: 542	 Data: torch.Size([10, 384])	 Training Loss: 0.8765963912010193
Step: 543	 Data: torch.Size([10, 384])	 Training Loss: 0.8776536583900452
Step: 544	 Data: torch.Size([10, 384])	 Training Loss: 1.0138850212097168
Step: 545	 Data: torch.Size([10, 384])	 Training Loss: 0.8693209290504456
Step: 546	 Data: torch.Size([10, 384])	 Training Loss: 0.8652417063713074
Step: 547	 Data: torch.Size([10, 384])	 Training Loss: 0.8427411317825317
Step: 548	 Data: torch.Size([10, 384])	 Training Loss: 0.9501723051071167
Step: 549	 Data: torch.Size([10, 384])	 Training Loss: 0.921853244304657
Step: 550	 Data: torch.Size([10, 384])	 Training Loss: 0.9749777913093567
Step: 551	 Data: torch.Size([10, 384])	 Training Loss: 0.9500666856765747
Step: 552	 Data: torch.Size([10, 384])	 Training Loss: 1.1624937057495117
Step: 553	 Data: torch.Size([10, 384])	 Training Loss: 0.8475004434585571
Step: 554	 Data: torch.Size([10, 384])	 Training Loss: 0.8899577856063843
Step: 555	 Data: torch.Size([10, 384])	 Training Loss: 0.9050298929214478
Step: 556	 Data: torch.Size([10, 384])	 Training Loss: 0.9625467658042908
Step: 557	 Data: torch.Size([10, 384])	 Training Loss: 1.050767421722412
Step: 558	 Data: torch.Size([10, 384])	 Training Loss: 0.9197670817375183
Step: 559	 Data: torch.Size([10, 384])	 Training Loss: 1.010478138923645
Step: 560	 Data: torch.Size([10, 384])	 Training Loss: 1.1359351873397827
Step: 561	 Data: torch.Size([10, 384])	 Training Loss: 0.9181033372879028
Step: 562	 Data: torch.Size([10, 384])	 Training Loss: 0.9791005253791809
Step: 563	 Data: torch.Size([10, 384])	 Training Loss: 0.874159574508667
Step: 564	 Data: torch.Size([10, 384])	 Training Loss: 1.0758440494537354
Step: 565	 Data: torch.Size([10, 384])	 Training Loss: 0.8694740533828735
Step: 566	 Data: torch.Size([10, 384])	 Training Loss: 1.0642248392105103
Step: 567	 Data: torch.Size([10, 374])	 Training Loss: 0.7397961616516113
Step: 568	 Data: torch.Size([10, 384])	 Training Loss: 1.0404657125473022
Step: 569	 Data: torch.Size([10, 384])	 Training Loss: 1.003454327583313
Step: 570	 Data: torch.Size([10, 384])	 Training Loss: 0.821624755859375
Step: 571	 Data: torch.Size([10, 384])	 Training Loss: 0.8854952454566956
Step: 572	 Data: torch.Size([10, 384])	 Training Loss: 0.7795986533164978
Step: 573	 Data: torch.Size([10, 384])	 Training Loss: 0.8367125391960144
Step: 574	 Data: torch.Size([10, 384])	 Training Loss: 0.7790558934211731
Step: 575	 Data: torch.Size([10, 384])	 Training Loss: 0.9692573547363281
Step: 576	 Data: torch.Size([10, 384])	 Training Loss: 0.8027917146682739
Step: 577	 Data: torch.Size([10, 384])	 Training Loss: 1.115142822265625
Step: 578	 Data: torch.Size([10, 384])	 Training Loss: 0.8533897995948792
Step: 579	 Data: torch.Size([10, 384])	 Training Loss: 0.736122190952301
Step: 580	 Data: torch.Size([10, 384])	 Training Loss: 1.0806459188461304
Step: 581	 Data: torch.Size([10, 384])	 Training Loss: 0.9907225966453552
Step: 582	 Data: torch.Size([10, 384])	 Training Loss: 0.8662762641906738
Step: 583	 Data: torch.Size([10, 359])	 Training Loss: 1.0289580821990967
Step: 584	 Data: torch.Size([10, 287])	 Training Loss: 1.0178507566452026
Step: 585	 Data: torch.Size([10, 384])	 Training Loss: 0.8425108194351196
Step: 586	 Data: torch.Size([10, 384])	 Training Loss: 0.7828395962715149
Step: 587	 Data: torch.Size([10, 384])	 Training Loss: 0.9447499513626099
Step: 588	 Data: torch.Size([10, 384])	 Training Loss: 0.8639615178108215
Step: 589	 Data: torch.Size([10, 384])	 Training Loss: 0.8833863735198975
Step: 590	 Data: torch.Size([10, 384])	 Training Loss: 0.8588814735412598
Step: 591	 Data: torch.Size([10, 384])	 Training Loss: 0.9545257091522217
Step: 592	 Data: torch.Size([10, 384])	 Training Loss: 0.7968806624412537
Step: 593	 Data: torch.Size([10, 384])	 Training Loss: 0.9712365865707397
Step: 594	 Data: torch.Size([10, 384])	 Training Loss: 0.8534829616546631
Step: 595	 Data: torch.Size([10, 384])	 Training Loss: 1.0468358993530273
Step: 596	 Data: torch.Size([10, 384])	 Training Loss: 0.8848547339439392
Step: 597	 Data: torch.Size([10, 384])	 Training Loss: 0.8469613194465637
Step: 598	 Data: torch.Size([10, 384])	 Training Loss: 0.8677831888198853
Step: 599	 Data: torch.Size([10, 384])	 Training Loss: 0.9088158011436462
Step: 600	 Data: torch.Size([10, 384])	 Training Loss: 0.9577404856681824
