[2024-05-07 08:55:22,994] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-05-07 08:55:22,994] torch.distributed.run: [WARNING] 
[2024-05-07 08:55:22,994] torch.distributed.run: [WARNING] *****************************************
[2024-05-07 08:55:22,994] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-07 08:55:22,994] torch.distributed.run: [WARNING] *****************************************
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:34233 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:34233 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:34233 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:34233 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:34233 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:34233 (errno: 22 - Invalid argument).
====================initialize the distributed env====================
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.22s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.32s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.82s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  8.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.79s/it]
====================get the model with lora====================
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  8.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.99s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  8.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.59s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00,  9.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.47s/it]
====================Use gradient checkpoint====================
====================get the dataset====================
====================get the dataloader====================
====================start train====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Step: 1	 Data: torch.Size([10, 384])	 Training Loss: 1.0653092861175537
Step: 2	 Data: torch.Size([10, 384])	 Training Loss: 1.0275307893753052
Step: 3	 Data: torch.Size([10, 384])	 Training Loss: 0.9644657373428345
Step: 4	 Data: torch.Size([10, 384])	 Training Loss: 1.194652795791626
Step: 5	 Data: torch.Size([10, 384])	 Training Loss: 1.2677936553955078
Step: 6	 Data: torch.Size([10, 302])	 Training Loss: 1.2402234077453613
Step: 7	 Data: torch.Size([10, 384])	 Training Loss: 1.2178047895431519
Step: 8	 Data: torch.Size([10, 384])	 Training Loss: 1.1047031879425049
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Step: 9	 Data: torch.Size([10, 384])	 Training Loss: 1.1114025115966797
Step: 10	 Data: torch.Size([10, 384])	 Training Loss: 1.0319733619689941
Step: 11	 Data: torch.Size([10, 384])	 Training Loss: 1.3791403770446777
Step: 12	 Data: torch.Size([10, 319])	 Training Loss: 1.187793254852295
Step: 13	 Data: torch.Size([10, 384])	 Training Loss: 1.188172459602356
Step: 14	 Data: torch.Size([10, 384])	 Training Loss: 0.9831816554069519
Step: 15	 Data: torch.Size([10, 384])	 Training Loss: 0.9868123531341553
Step: 16	 Data: torch.Size([10, 384])	 Training Loss: 1.2150890827178955
Step: 17	 Data: torch.Size([10, 384])	 Training Loss: 1.1379033327102661
Step: 18	 Data: torch.Size([10, 384])	 Training Loss: 1.1932984590530396
Step: 19	 Data: torch.Size([10, 384])	 Training Loss: 1.1196459531784058
Step: 20	 Data: torch.Size([10, 384])	 Training Loss: 1.120406985282898
Step: 21	 Data: torch.Size([10, 384])	 Training Loss: 1.2370129823684692
Step: 22	 Data: torch.Size([10, 384])	 Training Loss: 1.0422308444976807
Step: 23	 Data: torch.Size([10, 384])	 Training Loss: 1.1443196535110474
Step: 24	 Data: torch.Size([10, 384])	 Training Loss: 1.069368600845337
Step: 25	 Data: torch.Size([10, 384])	 Training Loss: 1.148391842842102
Step: 26	 Data: torch.Size([10, 384])	 Training Loss: 1.0746625661849976
Step: 27	 Data: torch.Size([10, 384])	 Training Loss: 1.3524025678634644
Step: 28	 Data: torch.Size([10, 384])	 Training Loss: 1.1382713317871094
Step: 29	 Data: torch.Size([10, 384])	 Training Loss: 1.1074059009552002
Step: 30	 Data: torch.Size([10, 384])	 Training Loss: 1.1473032236099243
Step: 31	 Data: torch.Size([10, 384])	 Training Loss: 0.9727094173431396
Step: 32	 Data: torch.Size([10, 384])	 Training Loss: 1.0462586879730225
Step: 33	 Data: torch.Size([10, 384])	 Training Loss: 1.0146592855453491
Step: 34	 Data: torch.Size([10, 384])	 Training Loss: 1.1250112056732178
Step: 35	 Data: torch.Size([10, 384])	 Training Loss: 1.1633226871490479
Step: 36	 Data: torch.Size([10, 384])	 Training Loss: 0.9574575424194336
Step: 37	 Data: torch.Size([10, 384])	 Training Loss: 1.1551748514175415
Step: 38	 Data: torch.Size([10, 384])	 Training Loss: 1.446419358253479
Step: 39	 Data: torch.Size([10, 384])	 Training Loss: 1.2789174318313599
Step: 40	 Data: torch.Size([10, 384])	 Training Loss: 1.1206774711608887
Step: 41	 Data: torch.Size([10, 384])	 Training Loss: 1.1371504068374634
Step: 42	 Data: torch.Size([10, 384])	 Training Loss: 1.0290601253509521
Step: 43	 Data: torch.Size([10, 384])	 Training Loss: 1.1304763555526733
Step: 44	 Data: torch.Size([10, 384])	 Training Loss: 0.977817952632904
Step: 45	 Data: torch.Size([10, 384])	 Training Loss: 0.9336004257202148
Step: 46	 Data: torch.Size([10, 384])	 Training Loss: 1.1520811319351196
Step: 47	 Data: torch.Size([10, 384])	 Training Loss: 1.2598572969436646
Step: 48	 Data: torch.Size([10, 384])	 Training Loss: 0.9940590262413025
Step: 49	 Data: torch.Size([10, 384])	 Training Loss: 1.0185426473617554
Step: 50	 Data: torch.Size([10, 384])	 Training Loss: 1.0384758710861206
Step: 51	 Data: torch.Size([10, 384])	 Training Loss: 0.9498945474624634
Step: 52	 Data: torch.Size([10, 384])	 Training Loss: 0.9469925165176392
Step: 53	 Data: torch.Size([10, 384])	 Training Loss: 1.0041704177856445
Step: 54	 Data: torch.Size([10, 384])	 Training Loss: 1.0707355737686157
Step: 55	 Data: torch.Size([10, 384])	 Training Loss: 1.3002853393554688
Step: 56	 Data: torch.Size([10, 384])	 Training Loss: 1.208709478378296
Step: 57	 Data: torch.Size([10, 384])	 Training Loss: 1.0299142599105835
Step: 58	 Data: torch.Size([10, 384])	 Training Loss: 1.2121628522872925
Step: 59	 Data: torch.Size([10, 384])	 Training Loss: 1.0488576889038086
Step: 60	 Data: torch.Size([10, 384])	 Training Loss: 1.0847525596618652
Step: 61	 Data: torch.Size([10, 384])	 Training Loss: 0.9774827361106873
Step: 62	 Data: torch.Size([10, 384])	 Training Loss: 0.9726889729499817
Step: 63	 Data: torch.Size([10, 384])	 Training Loss: 0.9634379744529724
Step: 64	 Data: torch.Size([10, 384])	 Training Loss: 1.0426831245422363
Step: 65	 Data: torch.Size([10, 384])	 Training Loss: 1.022613763809204
Step: 66	 Data: torch.Size([10, 384])	 Training Loss: 1.1323504447937012
Step: 67	 Data: torch.Size([10, 384])	 Training Loss: 0.9592246413230896
Step: 68	 Data: torch.Size([10, 384])	 Training Loss: 1.0197087526321411
Step: 69	 Data: torch.Size([10, 384])	 Training Loss: 1.1066018342971802
Step: 70	 Data: torch.Size([10, 384])	 Training Loss: 1.037014365196228
Step: 71	 Data: torch.Size([10, 384])	 Training Loss: 1.0095564126968384
Step: 72	 Data: torch.Size([10, 384])	 Training Loss: 0.9285690784454346
Step: 73	 Data: torch.Size([10, 384])	 Training Loss: 0.9209765195846558
Step: 74	 Data: torch.Size([10, 384])	 Training Loss: 0.9409956932067871
Step: 75	 Data: torch.Size([10, 384])	 Training Loss: 1.1079996824264526
Step: 76	 Data: torch.Size([10, 384])	 Training Loss: 0.9089238047599792
Step: 77	 Data: torch.Size([10, 384])	 Training Loss: 1.0488152503967285
Step: 78	 Data: torch.Size([10, 384])	 Training Loss: 1.0506798028945923
Step: 79	 Data: torch.Size([10, 384])	 Training Loss: 1.2038908004760742
Step: 80	 Data: torch.Size([10, 384])	 Training Loss: 1.0059653520584106
Step: 81	 Data: torch.Size([10, 384])	 Training Loss: 1.0341743230819702
Step: 82	 Data: torch.Size([10, 384])	 Training Loss: 1.0459775924682617
Step: 83	 Data: torch.Size([10, 384])	 Training Loss: 1.1253111362457275
Step: 84	 Data: torch.Size([10, 384])	 Training Loss: 1.0869288444519043
Step: 85	 Data: torch.Size([10, 384])	 Training Loss: 1.050856351852417
Step: 86	 Data: torch.Size([10, 384])	 Training Loss: 1.183652400970459
Step: 87	 Data: torch.Size([10, 384])	 Training Loss: 1.0292696952819824
Step: 88	 Data: torch.Size([10, 384])	 Training Loss: 1.1290724277496338
Step: 89	 Data: torch.Size([10, 384])	 Training Loss: 0.960399329662323
Step: 90	 Data: torch.Size([10, 384])	 Training Loss: 1.135636329650879
Step: 91	 Data: torch.Size([10, 384])	 Training Loss: 0.8927549719810486
Step: 92	 Data: torch.Size([10, 384])	 Training Loss: 0.9152910709381104
Step: 93	 Data: torch.Size([10, 384])	 Training Loss: 0.915071427822113
Step: 94	 Data: torch.Size([10, 384])	 Training Loss: 0.8524837493896484
Step: 95	 Data: torch.Size([10, 384])	 Training Loss: 0.9138403534889221
Step: 96	 Data: torch.Size([10, 384])	 Training Loss: 0.9817517995834351
Step: 97	 Data: torch.Size([10, 384])	 Training Loss: 0.9986246824264526
Step: 98	 Data: torch.Size([10, 384])	 Training Loss: 1.1236428022384644
Step: 99	 Data: torch.Size([10, 384])	 Training Loss: 0.9407491683959961
Step: 100	 Data: torch.Size([10, 384])	 Training Loss: 0.9719648957252502
Step: 101	 Data: torch.Size([10, 384])	 Training Loss: 1.0588327646255493
Step: 102	 Data: torch.Size([10, 384])	 Training Loss: 1.0382412672042847
Step: 103	 Data: torch.Size([10, 384])	 Training Loss: 0.9929295182228088
Step: 104	 Data: torch.Size([10, 384])	 Training Loss: 1.1139075756072998
Step: 105	 Data: torch.Size([10, 384])	 Training Loss: 1.0313514471054077
Step: 106	 Data: torch.Size([10, 384])	 Training Loss: 0.9656870365142822
Step: 107	 Data: torch.Size([10, 384])	 Training Loss: 1.021982192993164
Step: 108	 Data: torch.Size([10, 384])	 Training Loss: 0.8742773532867432
Step: 109	 Data: torch.Size([10, 384])	 Training Loss: 1.0656412839889526
Step: 110	 Data: torch.Size([10, 384])	 Training Loss: 1.0466464757919312
Step: 111	 Data: torch.Size([10, 384])	 Training Loss: 0.8497613668441772
Step: 112	 Data: torch.Size([10, 384])	 Training Loss: 1.0259032249450684
Step: 113	 Data: torch.Size([10, 384])	 Training Loss: 0.9652924537658691
Step: 114	 Data: torch.Size([10, 349])	 Training Loss: 0.9729992151260376
Step: 115	 Data: torch.Size([10, 384])	 Training Loss: 0.8153395056724548
Step: 116	 Data: torch.Size([10, 384])	 Training Loss: 0.9805250763893127
Step: 117	 Data: torch.Size([10, 384])	 Training Loss: 1.2579973936080933
Step: 118	 Data: torch.Size([10, 384])	 Training Loss: 0.8870707750320435
Step: 119	 Data: torch.Size([10, 384])	 Training Loss: 0.9073668122291565
Step: 120	 Data: torch.Size([10, 384])	 Training Loss: 0.928641140460968
Step: 121	 Data: torch.Size([10, 384])	 Training Loss: 0.8987088799476624
Step: 122	 Data: torch.Size([10, 384])	 Training Loss: 0.9928914904594421
Step: 123	 Data: torch.Size([10, 384])	 Training Loss: 0.9745920896530151
Step: 124	 Data: torch.Size([10, 384])	 Training Loss: 1.0358844995498657
Step: 125	 Data: torch.Size([10, 384])	 Training Loss: 1.0019797086715698
Step: 126	 Data: torch.Size([10, 384])	 Training Loss: 1.0913721323013306
Step: 127	 Data: torch.Size([10, 384])	 Training Loss: 0.8951155543327332
Step: 128	 Data: torch.Size([10, 384])	 Training Loss: 0.878769040107727
Step: 129	 Data: torch.Size([10, 384])	 Training Loss: 0.9607189893722534
Step: 130	 Data: torch.Size([10, 384])	 Training Loss: 0.8627190589904785
Step: 131	 Data: torch.Size([10, 384])	 Training Loss: 1.0232832431793213
Step: 132	 Data: torch.Size([10, 384])	 Training Loss: 0.9899229407310486
Step: 133	 Data: torch.Size([10, 384])	 Training Loss: 0.9536705613136292
Step: 134	 Data: torch.Size([10, 384])	 Training Loss: 0.8398275971412659
Step: 135	 Data: torch.Size([10, 384])	 Training Loss: 1.0159910917282104
Step: 136	 Data: torch.Size([10, 384])	 Training Loss: 0.9072521924972534
Step: 137	 Data: torch.Size([10, 384])	 Training Loss: 1.017346978187561
Step: 138	 Data: torch.Size([10, 384])	 Training Loss: 0.9268888831138611
Step: 139	 Data: torch.Size([10, 384])	 Training Loss: 0.9886677861213684
Step: 140	 Data: torch.Size([10, 384])	 Training Loss: 0.9640663862228394
Step: 141	 Data: torch.Size([10, 384])	 Training Loss: 1.0437495708465576
Step: 142	 Data: torch.Size([10, 384])	 Training Loss: 1.0048434734344482
Step: 143	 Data: torch.Size([10, 384])	 Training Loss: 1.031332015991211
Step: 144	 Data: torch.Size([10, 384])	 Training Loss: 1.0357409715652466
Step: 145	 Data: torch.Size([10, 384])	 Training Loss: 0.8768250346183777
Step: 146	 Data: torch.Size([10, 384])	 Training Loss: 0.8332234621047974
Step: 147	 Data: torch.Size([10, 384])	 Training Loss: 0.9343342781066895
Step: 148	 Data: torch.Size([10, 384])	 Training Loss: 0.8844969868659973
Step: 149	 Data: torch.Size([10, 384])	 Training Loss: 1.087156057357788
Step: 150	 Data: torch.Size([10, 384])	 Training Loss: 0.8767958283424377
Step: 151	 Data: torch.Size([10, 384])	 Training Loss: 0.8218975067138672
Step: 152	 Data: torch.Size([10, 384])	 Training Loss: 0.9472748041152954
Step: 153	 Data: torch.Size([10, 384])	 Training Loss: 1.1459177732467651
Step: 154	 Data: torch.Size([10, 384])	 Training Loss: 0.8792741894721985
Step: 155	 Data: torch.Size([10, 384])	 Training Loss: 0.9865602254867554
Step: 156	 Data: torch.Size([10, 384])	 Training Loss: 0.999508261680603
Step: 157	 Data: torch.Size([10, 384])	 Training Loss: 0.9321274161338806
Step: 158	 Data: torch.Size([10, 384])	 Training Loss: 0.8521960973739624
Step: 159	 Data: torch.Size([10, 384])	 Training Loss: 1.0732253789901733
Step: 160	 Data: torch.Size([10, 384])	 Training Loss: 1.013729453086853
Step: 161	 Data: torch.Size([10, 384])	 Training Loss: 0.8920696377754211
Step: 162	 Data: torch.Size([10, 384])	 Training Loss: 0.9097135663032532
Step: 163	 Data: torch.Size([10, 384])	 Training Loss: 0.9509977698326111
Step: 164	 Data: torch.Size([10, 384])	 Training Loss: 0.8580644130706787
Step: 165	 Data: torch.Size([10, 384])	 Training Loss: 0.9321706891059875
Step: 166	 Data: torch.Size([10, 384])	 Training Loss: 1.0342755317687988
Step: 167	 Data: torch.Size([10, 384])	 Training Loss: 0.7821903824806213
Step: 168	 Data: torch.Size([10, 384])	 Training Loss: 0.9909682869911194
Step: 169	 Data: torch.Size([10, 384])	 Training Loss: 0.923866868019104
Step: 170	 Data: torch.Size([10, 384])	 Training Loss: 0.917698323726654
Step: 171	 Data: torch.Size([10, 384])	 Training Loss: 0.9423457980155945
Step: 172	 Data: torch.Size([10, 384])	 Training Loss: 0.8881918787956238
Step: 173	 Data: torch.Size([10, 384])	 Training Loss: 1.1039338111877441
Step: 174	 Data: torch.Size([10, 384])	 Training Loss: 0.932116687297821
Step: 175	 Data: torch.Size([10, 384])	 Training Loss: 1.0775361061096191
Step: 176	 Data: torch.Size([10, 384])	 Training Loss: 0.8225946426391602
Step: 177	 Data: torch.Size([10, 346])	 Training Loss: 0.9459445476531982
Step: 178	 Data: torch.Size([10, 384])	 Training Loss: 0.8133236169815063
Step: 179	 Data: torch.Size([10, 384])	 Training Loss: 0.8711347579956055
Step: 180	 Data: torch.Size([10, 384])	 Training Loss: 0.9261908531188965
Step: 181	 Data: torch.Size([10, 384])	 Training Loss: 0.9308215975761414
Step: 182	 Data: torch.Size([10, 384])	 Training Loss: 0.9626339077949524
Step: 183	 Data: torch.Size([10, 384])	 Training Loss: 0.8936071395874023
Step: 184	 Data: torch.Size([10, 384])	 Training Loss: 1.1169906854629517
Step: 185	 Data: torch.Size([10, 384])	 Training Loss: 1.0641666650772095
Step: 186	 Data: torch.Size([10, 384])	 Training Loss: 0.9458518624305725
Step: 187	 Data: torch.Size([10, 384])	 Training Loss: 1.058307409286499
Step: 188	 Data: torch.Size([10, 384])	 Training Loss: 0.9431737661361694
Step: 189	 Data: torch.Size([10, 384])	 Training Loss: 0.9989182353019714
Step: 190	 Data: torch.Size([10, 384])	 Training Loss: 0.9913723468780518
Step: 191	 Data: torch.Size([10, 384])	 Training Loss: 1.021276831626892
Step: 192	 Data: torch.Size([10, 384])	 Training Loss: 0.8393505215644836
Step: 193	 Data: torch.Size([10, 384])	 Training Loss: 0.8919227719306946
Step: 194	 Data: torch.Size([10, 384])	 Training Loss: 1.040132999420166
Step: 195	 Data: torch.Size([10, 384])	 Training Loss: 0.949443519115448
Step: 196	 Data: torch.Size([10, 384])	 Training Loss: 0.9837247729301453
Step: 197	 Data: torch.Size([10, 384])	 Training Loss: 0.9826441407203674
Step: 198	 Data: torch.Size([10, 384])	 Training Loss: 0.8569502830505371
Step: 199	 Data: torch.Size([10, 384])	 Training Loss: 0.8788500428199768
Step: 200	 Data: torch.Size([10, 384])	 Training Loss: 0.8317095041275024
Step: 201	 Data: torch.Size([10, 384])	 Training Loss: 0.9772043228149414
Step: 202	 Data: torch.Size([10, 277])	 Training Loss: 1.1308599710464478
Step: 203	 Data: torch.Size([10, 384])	 Training Loss: 0.9628620147705078
Step: 204	 Data: torch.Size([10, 384])	 Training Loss: 0.940483808517456
Step: 205	 Data: torch.Size([10, 384])	 Training Loss: 1.086121916770935
Step: 206	 Data: torch.Size([10, 356])	 Training Loss: 0.9472689032554626
Step: 207	 Data: torch.Size([10, 384])	 Training Loss: 0.9364882111549377
Step: 208	 Data: torch.Size([10, 384])	 Training Loss: 0.7947079539299011
Step: 209	 Data: torch.Size([10, 384])	 Training Loss: 0.875541627407074
Step: 210	 Data: torch.Size([10, 384])	 Training Loss: 1.0318176746368408
Step: 211	 Data: torch.Size([10, 355])	 Training Loss: 0.9204308986663818
Step: 212	 Data: torch.Size([10, 384])	 Training Loss: 0.8926621079444885
Step: 213	 Data: torch.Size([10, 384])	 Training Loss: 1.1099554300308228
Step: 214	 Data: torch.Size([10, 384])	 Training Loss: 0.9221627116203308
Step: 215	 Data: torch.Size([10, 384])	 Training Loss: 0.8634581565856934
Step: 216	 Data: torch.Size([10, 384])	 Training Loss: 0.8263427019119263
Step: 217	 Data: torch.Size([10, 384])	 Training Loss: 0.8917294144630432
Step: 218	 Data: torch.Size([10, 384])	 Training Loss: 0.9174500107765198
Step: 219	 Data: torch.Size([10, 384])	 Training Loss: 0.9196223616600037
Step: 220	 Data: torch.Size([10, 384])	 Training Loss: 0.8598303198814392
Step: 221	 Data: torch.Size([10, 384])	 Training Loss: 0.9760821461677551
Step: 222	 Data: torch.Size([10, 384])	 Training Loss: 0.9196754693984985
Step: 223	 Data: torch.Size([10, 384])	 Training Loss: 0.9635295867919922
Step: 224	 Data: torch.Size([10, 384])	 Training Loss: 0.8934663534164429
Step: 225	 Data: torch.Size([10, 384])	 Training Loss: 0.9092574119567871
Step: 226	 Data: torch.Size([10, 384])	 Training Loss: 1.079575538635254
Step: 227	 Data: torch.Size([10, 384])	 Training Loss: 0.9773204326629639
Step: 228	 Data: torch.Size([10, 384])	 Training Loss: 0.7760477662086487
Step: 229	 Data: torch.Size([10, 384])	 Training Loss: 0.9365552067756653
Step: 230	 Data: torch.Size([10, 384])	 Training Loss: 0.952208399772644
Step: 231	 Data: torch.Size([10, 384])	 Training Loss: 0.766934335231781
Step: 232	 Data: torch.Size([10, 384])	 Training Loss: 0.91092449426651
Step: 233	 Data: torch.Size([10, 384])	 Training Loss: 0.8843546509742737
Step: 234	 Data: torch.Size([10, 384])	 Training Loss: 1.1628544330596924
Step: 235	 Data: torch.Size([10, 384])	 Training Loss: 0.9690326452255249
Step: 236	 Data: torch.Size([10, 384])	 Training Loss: 1.0219238996505737
Step: 237	 Data: torch.Size([10, 384])	 Training Loss: 0.954593300819397
Step: 238	 Data: torch.Size([10, 384])	 Training Loss: 1.0056641101837158
Step: 239	 Data: torch.Size([10, 384])	 Training Loss: 1.0279608964920044
Step: 240	 Data: torch.Size([10, 384])	 Training Loss: 0.9824783205986023
Step: 241	 Data: torch.Size([10, 384])	 Training Loss: 1.0671800374984741
Step: 242	 Data: torch.Size([10, 384])	 Training Loss: 0.9772363305091858
Step: 243	 Data: torch.Size([10, 384])	 Training Loss: 0.9852496981620789
Step: 244	 Data: torch.Size([10, 384])	 Training Loss: 0.8929988741874695
Step: 245	 Data: torch.Size([10, 384])	 Training Loss: 0.9627915024757385
Step: 246	 Data: torch.Size([10, 384])	 Training Loss: 1.1029679775238037
Step: 247	 Data: torch.Size([10, 384])	 Training Loss: 0.9600731730461121
Step: 248	 Data: torch.Size([10, 384])	 Training Loss: 1.0210537910461426
Step: 249	 Data: torch.Size([10, 384])	 Training Loss: 1.082743525505066
Step: 250	 Data: torch.Size([10, 340])	 Training Loss: 1.1446884870529175
Step: 251	 Data: torch.Size([10, 384])	 Training Loss: 0.9840724468231201
Step: 252	 Data: torch.Size([10, 384])	 Training Loss: 0.852955162525177
Step: 253	 Data: torch.Size([10, 384])	 Training Loss: 1.0050910711288452
Step: 254	 Data: torch.Size([10, 384])	 Training Loss: 0.8636488318443298
Step: 255	 Data: torch.Size([10, 384])	 Training Loss: 0.9497966766357422
Step: 256	 Data: torch.Size([10, 384])	 Training Loss: 0.940925657749176
Step: 257	 Data: torch.Size([10, 384])	 Training Loss: 0.9317521452903748
Step: 258	 Data: torch.Size([10, 384])	 Training Loss: 0.8918299674987793
Step: 259	 Data: torch.Size([10, 384])	 Training Loss: 0.907991886138916
Step: 260	 Data: torch.Size([10, 384])	 Training Loss: 0.8932144045829773
Step: 261	 Data: torch.Size([10, 384])	 Training Loss: 0.8321654796600342
Step: 262	 Data: torch.Size([10, 384])	 Training Loss: 0.9236699342727661
Step: 263	 Data: torch.Size([10, 384])	 Training Loss: 0.9257023334503174
Step: 264	 Data: torch.Size([10, 384])	 Training Loss: 0.8285506963729858
Step: 265	 Data: torch.Size([10, 384])	 Training Loss: 0.8511546850204468
Step: 266	 Data: torch.Size([10, 384])	 Training Loss: 0.9956843256950378
Step: 267	 Data: torch.Size([10, 384])	 Training Loss: 0.8737931251525879
Step: 268	 Data: torch.Size([10, 384])	 Training Loss: 0.9104041457176208
Step: 269	 Data: torch.Size([10, 384])	 Training Loss: 0.9839760661125183
Step: 270	 Data: torch.Size([10, 384])	 Training Loss: 0.9391835927963257
Step: 271	 Data: torch.Size([10, 384])	 Training Loss: 0.90669184923172
Step: 272	 Data: torch.Size([10, 384])	 Training Loss: 1.0126398801803589
Step: 273	 Data: torch.Size([10, 384])	 Training Loss: 0.9234431982040405
Step: 274	 Data: torch.Size([10, 384])	 Training Loss: 1.0138344764709473
Step: 275	 Data: torch.Size([10, 384])	 Training Loss: 0.9303938746452332
Step: 276	 Data: torch.Size([10, 384])	 Training Loss: 0.9746953248977661
Step: 277	 Data: torch.Size([10, 384])	 Training Loss: 0.9106084704399109
Step: 278	 Data: torch.Size([10, 384])	 Training Loss: 0.9470546841621399
Step: 279	 Data: torch.Size([10, 384])	 Training Loss: 0.9145898222923279
Step: 280	 Data: torch.Size([10, 384])	 Training Loss: 0.7978034019470215
Step: 281	 Data: torch.Size([10, 384])	 Training Loss: 1.0876919031143188
Step: 282	 Data: torch.Size([10, 384])	 Training Loss: 0.9274299740791321
Step: 283	 Data: torch.Size([10, 384])	 Training Loss: 0.8520652055740356
Step: 284	 Data: torch.Size([10, 384])	 Training Loss: 1.0455232858657837
Step: 285	 Data: torch.Size([10, 384])	 Training Loss: 0.8469487428665161
Step: 286	 Data: torch.Size([10, 384])	 Training Loss: 0.9906118512153625
Step: 287	 Data: torch.Size([10, 384])	 Training Loss: 0.9729706645011902
Step: 288	 Data: torch.Size([10, 384])	 Training Loss: 1.0082522630691528
Step: 289	 Data: torch.Size([10, 384])	 Training Loss: 0.9385405778884888
Step: 290	 Data: torch.Size([10, 384])	 Training Loss: 0.9105350375175476
Step: 291	 Data: torch.Size([10, 384])	 Training Loss: 0.9305533170700073
Step: 292	 Data: torch.Size([10, 384])	 Training Loss: 0.803704559803009
Step: 293	 Data: torch.Size([10, 372])	 Training Loss: 0.8410723805427551
Step: 294	 Data: torch.Size([10, 384])	 Training Loss: 1.0395517349243164
Step: 295	 Data: torch.Size([10, 384])	 Training Loss: 0.8581947088241577
Step: 296	 Data: torch.Size([10, 384])	 Training Loss: 0.926780641078949
Step: 297	 Data: torch.Size([10, 213])	 Training Loss: 1.075880527496338
Step: 298	 Data: torch.Size([10, 384])	 Training Loss: 1.0115020275115967
Step: 299	 Data: torch.Size([10, 384])	 Training Loss: 0.869417130947113
Step: 300	 Data: torch.Size([10, 384])	 Training Loss: 1.0357087850570679
Step: 301	 Data: torch.Size([10, 384])	 Training Loss: 1.0794434547424316
Step: 302	 Data: torch.Size([10, 384])	 Training Loss: 0.8970850110054016
Step: 303	 Data: torch.Size([10, 384])	 Training Loss: 0.9348615407943726
Step: 304	 Data: torch.Size([10, 384])	 Training Loss: 0.8843620419502258
Step: 305	 Data: torch.Size([10, 384])	 Training Loss: 0.8797544240951538
Step: 306	 Data: torch.Size([10, 384])	 Training Loss: 1.0785691738128662
Step: 307	 Data: torch.Size([10, 384])	 Training Loss: 0.9581380486488342
Step: 308	 Data: torch.Size([10, 384])	 Training Loss: 1.107625961303711
Step: 309	 Data: torch.Size([10, 384])	 Training Loss: 0.9791096448898315
Step: 310	 Data: torch.Size([10, 384])	 Training Loss: 0.9970806837081909
Step: 311	 Data: torch.Size([10, 384])	 Training Loss: 0.9825114011764526
Step: 312	 Data: torch.Size([10, 384])	 Training Loss: 0.8582754135131836
Step: 313	 Data: torch.Size([10, 384])	 Training Loss: 0.9254565238952637
Step: 314	 Data: torch.Size([10, 384])	 Training Loss: 0.9623283743858337
Step: 315	 Data: torch.Size([10, 384])	 Training Loss: 0.9999020099639893
Step: 316	 Data: torch.Size([10, 384])	 Training Loss: 0.8278483152389526
Step: 317	 Data: torch.Size([10, 384])	 Training Loss: 0.8992253541946411
Step: 318	 Data: torch.Size([10, 384])	 Training Loss: 1.1404929161071777
Step: 319	 Data: torch.Size([10, 384])	 Training Loss: 0.9647917151451111
Step: 320	 Data: torch.Size([10, 384])	 Training Loss: 1.2334315776824951
Step: 321	 Data: torch.Size([10, 384])	 Training Loss: 0.9924858808517456
Step: 322	 Data: torch.Size([10, 384])	 Training Loss: 1.1487077474594116
Step: 323	 Data: torch.Size([10, 384])	 Training Loss: 0.9454554915428162
Step: 324	 Data: torch.Size([10, 384])	 Training Loss: 0.9006001949310303
Step: 325	 Data: torch.Size([10, 384])	 Training Loss: 0.8286460041999817
Step: 326	 Data: torch.Size([10, 384])	 Training Loss: 0.8153210282325745
Step: 327	 Data: torch.Size([10, 384])	 Training Loss: 0.7989431023597717
Step: 328	 Data: torch.Size([10, 384])	 Training Loss: 1.1285643577575684
Step: 329	 Data: torch.Size([10, 384])	 Training Loss: 1.1176178455352783
Step: 330	 Data: torch.Size([10, 384])	 Training Loss: 0.9488006830215454
Step: 331	 Data: torch.Size([10, 384])	 Training Loss: 0.7867071628570557
Step: 332	 Data: torch.Size([10, 384])	 Training Loss: 0.9984042048454285
Step: 333	 Data: torch.Size([10, 384])	 Training Loss: 0.9566409587860107
Step: 334	 Data: torch.Size([10, 384])	 Training Loss: 0.9705492258071899
Step: 335	 Data: torch.Size([10, 384])	 Training Loss: 0.8286439180374146
Step: 336	 Data: torch.Size([10, 384])	 Training Loss: 0.8232430219650269
Step: 337	 Data: torch.Size([10, 384])	 Training Loss: 1.0919057130813599
Step: 338	 Data: torch.Size([10, 384])	 Training Loss: 1.046854853630066
Step: 339	 Data: torch.Size([10, 384])	 Training Loss: 0.9297775626182556
Step: 340	 Data: torch.Size([10, 384])	 Training Loss: 0.8146776556968689
Step: 341	 Data: torch.Size([10, 384])	 Training Loss: 0.8230107426643372
Step: 342	 Data: torch.Size([10, 384])	 Training Loss: 0.9725048542022705
Step: 343	 Data: torch.Size([10, 384])	 Training Loss: 1.052480936050415
Step: 344	 Data: torch.Size([10, 384])	 Training Loss: 1.0840309858322144
Step: 345	 Data: torch.Size([10, 384])	 Training Loss: 0.9884028434753418
Step: 346	 Data: torch.Size([10, 384])	 Training Loss: 0.935411274433136
Step: 347	 Data: torch.Size([10, 384])	 Training Loss: 1.0628557205200195
Step: 348	 Data: torch.Size([10, 384])	 Training Loss: 0.9533020257949829
Step: 349	 Data: torch.Size([10, 384])	 Training Loss: 0.8768521547317505
Step: 350	 Data: torch.Size([10, 384])	 Training Loss: 0.903518557548523
Step: 351	 Data: torch.Size([10, 384])	 Training Loss: 0.8703386187553406
Step: 352	 Data: torch.Size([10, 384])	 Training Loss: 0.9060565233230591
Step: 353	 Data: torch.Size([10, 384])	 Training Loss: 0.9698248505592346
Step: 354	 Data: torch.Size([10, 384])	 Training Loss: 0.9591484665870667
Step: 355	 Data: torch.Size([10, 384])	 Training Loss: 0.8673555254936218
Step: 356	 Data: torch.Size([10, 384])	 Training Loss: 1.0902764797210693
Step: 357	 Data: torch.Size([10, 384])	 Training Loss: 0.9806311130523682
Step: 358	 Data: torch.Size([10, 384])	 Training Loss: 1.0334031581878662
Step: 359	 Data: torch.Size([10, 384])	 Training Loss: 0.9655364155769348
Step: 360	 Data: torch.Size([10, 384])	 Training Loss: 0.9731614589691162
Step: 361	 Data: torch.Size([10, 384])	 Training Loss: 0.8233374953269958
Step: 362	 Data: torch.Size([10, 384])	 Training Loss: 0.8170732259750366
Step: 363	 Data: torch.Size([10, 384])	 Training Loss: 0.9328086376190186
Step: 364	 Data: torch.Size([10, 384])	 Training Loss: 0.9880378842353821
Step: 365	 Data: torch.Size([10, 384])	 Training Loss: 0.8196613192558289
Step: 366	 Data: torch.Size([10, 384])	 Training Loss: 0.7792924642562866
Step: 367	 Data: torch.Size([10, 384])	 Training Loss: 0.8964207172393799
Step: 368	 Data: torch.Size([10, 384])	 Training Loss: 1.0222378969192505
Step: 369	 Data: torch.Size([10, 384])	 Training Loss: 0.988613486289978
Step: 370	 Data: torch.Size([10, 384])	 Training Loss: 0.9126285910606384
Step: 371	 Data: torch.Size([10, 384])	 Training Loss: 0.8425037264823914
Step: 372	 Data: torch.Size([10, 384])	 Training Loss: 1.0046991109848022
Step: 373	 Data: torch.Size([10, 384])	 Training Loss: 0.9588009119033813
Step: 374	 Data: torch.Size([10, 384])	 Training Loss: 0.872692883014679
Step: 375	 Data: torch.Size([10, 384])	 Training Loss: 0.8421632647514343
Step: 376	 Data: torch.Size([10, 384])	 Training Loss: 0.8769375681877136
Step: 377	 Data: torch.Size([10, 384])	 Training Loss: 0.9768497943878174
Step: 378	 Data: torch.Size([10, 384])	 Training Loss: 0.9089385867118835
Step: 379	 Data: torch.Size([10, 384])	 Training Loss: 0.8464016318321228
Step: 380	 Data: torch.Size([10, 384])	 Training Loss: 1.008941650390625
Step: 381	 Data: torch.Size([10, 384])	 Training Loss: 0.8711336255073547
Step: 382	 Data: torch.Size([10, 384])	 Training Loss: 0.8924092650413513
Step: 383	 Data: torch.Size([10, 384])	 Training Loss: 0.9322888255119324
Step: 384	 Data: torch.Size([10, 384])	 Training Loss: 0.816365122795105
Step: 385	 Data: torch.Size([10, 384])	 Training Loss: 0.8371561169624329
Step: 386	 Data: torch.Size([10, 384])	 Training Loss: 0.9867092370986938
Step: 387	 Data: torch.Size([10, 384])	 Training Loss: 0.8554459810256958
Step: 388	 Data: torch.Size([10, 384])	 Training Loss: 0.9384774565696716
Step: 389	 Data: torch.Size([10, 384])	 Training Loss: 1.1440021991729736
Step: 390	 Data: torch.Size([10, 384])	 Training Loss: 0.8903571963310242
Step: 391	 Data: torch.Size([10, 384])	 Training Loss: 1.097967267036438
Step: 392	 Data: torch.Size([10, 384])	 Training Loss: 0.9522171020507812
Step: 393	 Data: torch.Size([10, 384])	 Training Loss: 0.9145636558532715
Step: 394	 Data: torch.Size([10, 270])	 Training Loss: 0.8550896644592285
Step: 395	 Data: torch.Size([10, 384])	 Training Loss: 0.94073486328125
Step: 396	 Data: torch.Size([10, 384])	 Training Loss: 0.8887181878089905
Step: 397	 Data: torch.Size([10, 384])	 Training Loss: 0.8952955007553101
Step: 398	 Data: torch.Size([10, 384])	 Training Loss: 0.9462364315986633
Step: 399	 Data: torch.Size([10, 384])	 Training Loss: 0.9956091046333313
Step: 400	 Data: torch.Size([10, 384])	 Training Loss: 0.9777233004570007
Step: 401	 Data: torch.Size([10, 384])	 Training Loss: 0.983321487903595
Step: 402	 Data: torch.Size([10, 384])	 Training Loss: 0.8328409790992737
Step: 403	 Data: torch.Size([10, 384])	 Training Loss: 0.9887540936470032
Step: 404	 Data: torch.Size([10, 384])	 Training Loss: 0.9670585989952087
Step: 405	 Data: torch.Size([10, 384])	 Training Loss: 1.1085718870162964
Step: 406	 Data: torch.Size([10, 384])	 Training Loss: 1.007659912109375
Step: 407	 Data: torch.Size([10, 384])	 Training Loss: 0.8666394948959351
Step: 408	 Data: torch.Size([10, 384])	 Training Loss: 0.9135905504226685
Step: 409	 Data: torch.Size([10, 384])	 Training Loss: 0.8206115365028381
Step: 410	 Data: torch.Size([10, 384])	 Training Loss: 0.8862650990486145
Step: 411	 Data: torch.Size([10, 384])	 Training Loss: 0.903246283531189
Step: 412	 Data: torch.Size([10, 384])	 Training Loss: 1.0066965818405151
Step: 413	 Data: torch.Size([10, 384])	 Training Loss: 0.9383162260055542
Step: 414	 Data: torch.Size([10, 384])	 Training Loss: 0.9637365341186523
Step: 415	 Data: torch.Size([10, 384])	 Training Loss: 0.8972477316856384
Step: 416	 Data: torch.Size([10, 384])	 Training Loss: 1.037858009338379
Step: 417	 Data: torch.Size([10, 384])	 Training Loss: 0.9222411513328552
Step: 418	 Data: torch.Size([10, 384])	 Training Loss: 1.0186597108840942
Step: 419	 Data: torch.Size([10, 384])	 Training Loss: 0.9353798031806946
Step: 420	 Data: torch.Size([10, 384])	 Training Loss: 0.7982318997383118
Step: 421	 Data: torch.Size([10, 384])	 Training Loss: 0.8224720358848572
Step: 422	 Data: torch.Size([10, 384])	 Training Loss: 0.908038854598999
Step: 423	 Data: torch.Size([10, 384])	 Training Loss: 0.8270935416221619
Step: 424	 Data: torch.Size([10, 384])	 Training Loss: 0.8364391326904297
Step: 425	 Data: torch.Size([10, 384])	 Training Loss: 0.8972423672676086
Step: 426	 Data: torch.Size([10, 384])	 Training Loss: 0.8500985503196716
Step: 427	 Data: torch.Size([10, 384])	 Training Loss: 0.9860526919364929
Step: 428	 Data: torch.Size([10, 384])	 Training Loss: 0.882072389125824
Step: 429	 Data: torch.Size([10, 384])	 Training Loss: 0.866618812084198
Step: 430	 Data: torch.Size([10, 384])	 Training Loss: 0.9565812945365906
Step: 431	 Data: torch.Size([10, 384])	 Training Loss: 0.8381765484809875
Step: 432	 Data: torch.Size([10, 384])	 Training Loss: 0.9673539400100708
Step: 433	 Data: torch.Size([10, 384])	 Training Loss: 0.8647324442863464
Step: 434	 Data: torch.Size([10, 384])	 Training Loss: 0.9786658883094788
Step: 435	 Data: torch.Size([10, 384])	 Training Loss: 0.7613485455513
Step: 436	 Data: torch.Size([10, 384])	 Training Loss: 0.836923360824585
Step: 437	 Data: torch.Size([10, 384])	 Training Loss: 0.9913251399993896
Step: 438	 Data: torch.Size([10, 384])	 Training Loss: 0.9910225868225098
Step: 439	 Data: torch.Size([10, 384])	 Training Loss: 1.119966745376587
Step: 440	 Data: torch.Size([10, 384])	 Training Loss: 0.8733285069465637
Step: 441	 Data: torch.Size([10, 384])	 Training Loss: 0.9256796836853027
Step: 442	 Data: torch.Size([10, 384])	 Training Loss: 1.0042372941970825
Step: 443	 Data: torch.Size([10, 384])	 Training Loss: 0.859278678894043
Step: 444	 Data: torch.Size([10, 384])	 Training Loss: 0.92534339427948
Step: 445	 Data: torch.Size([10, 384])	 Training Loss: 1.0101549625396729
Step: 446	 Data: torch.Size([10, 384])	 Training Loss: 0.975891649723053
Step: 447	 Data: torch.Size([10, 384])	 Training Loss: 0.9790918827056885
Step: 448	 Data: torch.Size([10, 384])	 Training Loss: 0.8007011413574219
Step: 449	 Data: torch.Size([10, 384])	 Training Loss: 1.081108808517456
Step: 450	 Data: torch.Size([10, 384])	 Training Loss: 0.8799380660057068
Step: 451	 Data: torch.Size([10, 384])	 Training Loss: 0.9331752061843872
Step: 452	 Data: torch.Size([10, 384])	 Training Loss: 0.8655176162719727
Step: 453	 Data: torch.Size([10, 384])	 Training Loss: 0.9283691048622131
Step: 454	 Data: torch.Size([10, 384])	 Training Loss: 1.0970510244369507
Step: 455	 Data: torch.Size([10, 384])	 Training Loss: 0.9772037267684937
Step: 456	 Data: torch.Size([10, 384])	 Training Loss: 0.88255375623703
Step: 457	 Data: torch.Size([10, 384])	 Training Loss: 0.954484224319458
Step: 458	 Data: torch.Size([10, 384])	 Training Loss: 0.9232277870178223
Step: 459	 Data: torch.Size([10, 384])	 Training Loss: 1.0377631187438965
Step: 460	 Data: torch.Size([10, 384])	 Training Loss: 0.921271026134491
Step: 461	 Data: torch.Size([10, 384])	 Training Loss: 0.9691796898841858
Step: 462	 Data: torch.Size([10, 384])	 Training Loss: 1.0784409046173096
Step: 463	 Data: torch.Size([10, 384])	 Training Loss: 0.8857760429382324
Step: 464	 Data: torch.Size([10, 306])	 Training Loss: 1.0570828914642334
Step: 465	 Data: torch.Size([10, 249])	 Training Loss: 0.9698087573051453
Step: 466	 Data: torch.Size([10, 384])	 Training Loss: 0.9494179487228394
Step: 467	 Data: torch.Size([10, 384])	 Training Loss: 0.9658634066581726
Step: 468	 Data: torch.Size([10, 384])	 Training Loss: 1.056284785270691
Step: 469	 Data: torch.Size([10, 384])	 Training Loss: 0.9941219091415405
Step: 470	 Data: torch.Size([10, 384])	 Training Loss: 0.9998940825462341
Step: 471	 Data: torch.Size([10, 384])	 Training Loss: 0.8879281282424927
Step: 472	 Data: torch.Size([10, 384])	 Training Loss: 0.8758330941200256
Step: 473	 Data: torch.Size([10, 384])	 Training Loss: 1.0712405443191528
Step: 474	 Data: torch.Size([10, 384])	 Training Loss: 1.0130707025527954
Step: 475	 Data: torch.Size([10, 384])	 Training Loss: 0.941166877746582
Step: 476	 Data: torch.Size([10, 384])	 Training Loss: 1.1223878860473633
Step: 477	 Data: torch.Size([10, 384])	 Training Loss: 0.8397433757781982
Step: 478	 Data: torch.Size([10, 384])	 Training Loss: 0.960034191608429
Step: 479	 Data: torch.Size([10, 384])	 Training Loss: 0.9706986546516418
Step: 480	 Data: torch.Size([10, 384])	 Training Loss: 0.9812653064727783
Step: 481	 Data: torch.Size([10, 384])	 Training Loss: 0.7904308438301086
Step: 482	 Data: torch.Size([10, 384])	 Training Loss: 1.017665982246399
Step: 483	 Data: torch.Size([10, 384])	 Training Loss: 1.033867597579956
Step: 484	 Data: torch.Size([10, 384])	 Training Loss: 0.8289136290550232
Step: 485	 Data: torch.Size([10, 384])	 Training Loss: 0.8394110798835754
Step: 486	 Data: torch.Size([10, 384])	 Training Loss: 0.9866129755973816
Step: 487	 Data: torch.Size([10, 384])	 Training Loss: 0.8098122477531433
Step: 488	 Data: torch.Size([10, 384])	 Training Loss: 0.9803860783576965
Step: 489	 Data: torch.Size([10, 384])	 Training Loss: 0.8941314220428467
Step: 490	 Data: torch.Size([10, 384])	 Training Loss: 0.8382161259651184
Step: 491	 Data: torch.Size([10, 384])	 Training Loss: 0.7665486335754395
Step: 492	 Data: torch.Size([10, 384])	 Training Loss: 0.8487727046012878
Step: 493	 Data: torch.Size([10, 384])	 Training Loss: 0.8952633738517761
Step: 494	 Data: torch.Size([10, 384])	 Training Loss: 0.8131685853004456
Step: 495	 Data: torch.Size([10, 384])	 Training Loss: 1.0575151443481445
Step: 496	 Data: torch.Size([10, 384])	 Training Loss: 0.9459593296051025
Step: 497	 Data: torch.Size([10, 384])	 Training Loss: 1.022026777267456
Step: 498	 Data: torch.Size([10, 384])	 Training Loss: 1.0082366466522217
Step: 499	 Data: torch.Size([10, 384])	 Training Loss: 0.8979932069778442
Step: 500	 Data: torch.Size([10, 384])	 Training Loss: 0.8678804636001587
Step: 501	 Data: torch.Size([10, 384])	 Training Loss: 0.8674010634422302
Step: 502	 Data: torch.Size([10, 384])	 Training Loss: 0.944920003414154
Step: 503	 Data: torch.Size([10, 384])	 Training Loss: 0.8301331400871277
Step: 504	 Data: torch.Size([10, 384])	 Training Loss: 0.8558375239372253
Step: 505	 Data: torch.Size([10, 384])	 Training Loss: 1.0313931703567505
Step: 506	 Data: torch.Size([10, 384])	 Training Loss: 0.7971199750900269
Step: 507	 Data: torch.Size([10, 384])	 Training Loss: 0.8163549304008484
Step: 508	 Data: torch.Size([10, 384])	 Training Loss: 0.9526837468147278
Step: 509	 Data: torch.Size([10, 384])	 Training Loss: 0.8712260127067566
Step: 510	 Data: torch.Size([10, 384])	 Training Loss: 0.9620794653892517
Step: 511	 Data: torch.Size([10, 384])	 Training Loss: 0.7627288103103638
Step: 512	 Data: torch.Size([10, 384])	 Training Loss: 1.173298954963684
Step: 513	 Data: torch.Size([10, 384])	 Training Loss: 1.1819169521331787
Step: 514	 Data: torch.Size([10, 384])	 Training Loss: 0.8719882369041443
Step: 515	 Data: torch.Size([10, 302])	 Training Loss: 0.8436066508293152
Step: 516	 Data: torch.Size([10, 384])	 Training Loss: 1.0646406412124634
Step: 517	 Data: torch.Size([10, 384])	 Training Loss: 0.9128806591033936
Step: 518	 Data: torch.Size([10, 384])	 Training Loss: 0.8928070068359375
Step: 519	 Data: torch.Size([10, 384])	 Training Loss: 1.0258393287658691
Step: 520	 Data: torch.Size([10, 384])	 Training Loss: 0.7844629287719727
Step: 521	 Data: torch.Size([10, 384])	 Training Loss: 0.9576979279518127
Step: 522	 Data: torch.Size([10, 384])	 Training Loss: 1.1106822490692139
Step: 523	 Data: torch.Size([10, 384])	 Training Loss: 0.9225035309791565
Step: 524	 Data: torch.Size([10, 384])	 Training Loss: 1.001348614692688
Step: 525	 Data: torch.Size([10, 384])	 Training Loss: 0.9695723652839661
Step: 526	 Data: torch.Size([10, 384])	 Training Loss: 0.9675160646438599
Step: 527	 Data: torch.Size([10, 384])	 Training Loss: 0.836919903755188
Step: 528	 Data: torch.Size([10, 384])	 Training Loss: 0.8597784042358398
Step: 529	 Data: torch.Size([10, 384])	 Training Loss: 0.8961962461471558
Step: 530	 Data: torch.Size([10, 384])	 Training Loss: 0.9803294539451599
Step: 531	 Data: torch.Size([10, 384])	 Training Loss: 0.9965048432350159
Step: 532	 Data: torch.Size([10, 384])	 Training Loss: 0.8054284453392029
Step: 533	 Data: torch.Size([10, 384])	 Training Loss: 1.0666699409484863
Step: 534	 Data: torch.Size([10, 384])	 Training Loss: 0.9555422067642212
Step: 535	 Data: torch.Size([10, 384])	 Training Loss: 0.878985583782196
Step: 536	 Data: torch.Size([10, 384])	 Training Loss: 0.891927182674408
Step: 537	 Data: torch.Size([10, 384])	 Training Loss: 0.9039627909660339
Step: 538	 Data: torch.Size([10, 384])	 Training Loss: 1.0267096757888794
Step: 539	 Data: torch.Size([10, 384])	 Training Loss: 0.7985208034515381
Step: 540	 Data: torch.Size([10, 384])	 Training Loss: 0.9415075778961182
Step: 541	 Data: torch.Size([10, 384])	 Training Loss: 0.9482601284980774
Step: 542	 Data: torch.Size([10, 384])	 Training Loss: 0.8761836886405945
Step: 543	 Data: torch.Size([10, 384])	 Training Loss: 0.8777530789375305
Step: 544	 Data: torch.Size([10, 384])	 Training Loss: 1.0139952898025513
Step: 545	 Data: torch.Size([10, 384])	 Training Loss: 0.868851363658905
Step: 546	 Data: torch.Size([10, 384])	 Training Loss: 0.8653673529624939
Step: 547	 Data: torch.Size([10, 384])	 Training Loss: 0.8428680300712585
Step: 548	 Data: torch.Size([10, 384])	 Training Loss: 0.9506145119667053
Step: 549	 Data: torch.Size([10, 384])	 Training Loss: 0.921615719795227
Step: 550	 Data: torch.Size([10, 384])	 Training Loss: 0.9748470783233643
Step: 551	 Data: torch.Size([10, 384])	 Training Loss: 0.9485090970993042
Step: 552	 Data: torch.Size([10, 384])	 Training Loss: 1.1612778902053833
Step: 553	 Data: torch.Size([10, 384])	 Training Loss: 0.8468664884567261
Step: 554	 Data: torch.Size([10, 384])	 Training Loss: 0.8893688321113586
Step: 555	 Data: torch.Size([10, 384])	 Training Loss: 0.9055463075637817
Step: 556	 Data: torch.Size([10, 384])	 Training Loss: 0.9609981775283813
Step: 557	 Data: torch.Size([10, 384])	 Training Loss: 1.048933744430542
Step: 558	 Data: torch.Size([10, 384])	 Training Loss: 0.9194759130477905
Step: 559	 Data: torch.Size([10, 384])	 Training Loss: 1.011263370513916
Step: 560	 Data: torch.Size([10, 384])	 Training Loss: 1.134667992591858
Step: 561	 Data: torch.Size([10, 384])	 Training Loss: 0.917209267616272
Step: 562	 Data: torch.Size([10, 384])	 Training Loss: 0.9763935804367065
Step: 563	 Data: torch.Size([10, 384])	 Training Loss: 0.8744487762451172
Step: 564	 Data: torch.Size([10, 384])	 Training Loss: 1.0766388177871704
Step: 565	 Data: torch.Size([10, 384])	 Training Loss: 0.8685671091079712
Step: 566	 Data: torch.Size([10, 384])	 Training Loss: 1.0628222227096558
Step: 567	 Data: torch.Size([10, 374])	 Training Loss: 0.737997829914093
Step: 568	 Data: torch.Size([10, 384])	 Training Loss: 1.040566325187683
Step: 569	 Data: torch.Size([10, 384])	 Training Loss: 1.002012848854065
Step: 570	 Data: torch.Size([10, 384])	 Training Loss: 0.8211396336555481
Step: 571	 Data: torch.Size([10, 384])	 Training Loss: 0.8837243318557739
Step: 572	 Data: torch.Size([10, 384])	 Training Loss: 0.7767361998558044
Step: 573	 Data: torch.Size([10, 384])	 Training Loss: 0.8366966843605042
Step: 574	 Data: torch.Size([10, 384])	 Training Loss: 0.7785874009132385
Step: 575	 Data: torch.Size([10, 384])	 Training Loss: 0.9684780240058899
Step: 576	 Data: torch.Size([10, 384])	 Training Loss: 0.8006352782249451
Step: 577	 Data: torch.Size([10, 384])	 Training Loss: 1.115277647972107
Step: 578	 Data: torch.Size([10, 384])	 Training Loss: 0.8525403141975403
Step: 579	 Data: torch.Size([10, 384])	 Training Loss: 0.7354555726051331
Step: 580	 Data: torch.Size([10, 384])	 Training Loss: 1.0809978246688843
Step: 581	 Data: torch.Size([10, 384])	 Training Loss: 0.9889731407165527
Step: 582	 Data: torch.Size([10, 384])	 Training Loss: 0.8651317954063416
Step: 583	 Data: torch.Size([10, 359])	 Training Loss: 1.0294442176818848
Step: 584	 Data: torch.Size([10, 287])	 Training Loss: 1.0177454948425293
Step: 585	 Data: torch.Size([10, 384])	 Training Loss: 0.8420760035514832
Step: 586	 Data: torch.Size([10, 384])	 Training Loss: 0.7818896174430847
Step: 587	 Data: torch.Size([10, 384])	 Training Loss: 0.943609356880188
Step: 588	 Data: torch.Size([10, 384])	 Training Loss: 0.8637463450431824
Step: 589	 Data: torch.Size([10, 384])	 Training Loss: 0.8837757110595703
Step: 590	 Data: torch.Size([10, 384])	 Training Loss: 0.8589811325073242
Step: 591	 Data: torch.Size([10, 384])	 Training Loss: 0.9540231823921204
Step: 592	 Data: torch.Size([10, 384])	 Training Loss: 0.7952379584312439
Step: 593	 Data: torch.Size([10, 384])	 Training Loss: 0.9702927470207214
Step: 594	 Data: torch.Size([10, 384])	 Training Loss: 0.8539650440216064
Step: 595	 Data: torch.Size([10, 384])	 Training Loss: 1.0460216999053955
Step: 596	 Data: torch.Size([10, 384])	 Training Loss: 0.8822035789489746
Step: 597	 Data: torch.Size([10, 384])	 Training Loss: 0.8468360900878906
Step: 598	 Data: torch.Size([10, 384])	 Training Loss: 0.8687734007835388
Step: 599	 Data: torch.Size([10, 384])	 Training Loss: 0.9093892574310303
Step: 600	 Data: torch.Size([10, 384])	 Training Loss: 0.9574641585350037
