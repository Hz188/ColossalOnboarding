[2024-05-07 06:04:14,615] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-05-07 06:04:14,615] torch.distributed.run: [WARNING] 
[2024-05-07 06:04:14,615] torch.distributed.run: [WARNING] *****************************************
[2024-05-07 06:04:14,615] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-07 06:04:14,615] torch.distributed.run: [WARNING] *****************************************
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56735 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56735 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-199]:56735 (errno: 22 - Invalid argument).
====================initialize the distributed env====================
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:17<00:17, 17.20s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.46s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:16<00:16, 16.84s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00,  9.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00, 10.65s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 10.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 11.98s/it]
====================get the model with lora====================
Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00,  9.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.47s/it]
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 10.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 11.84s/it]
====================Use gradient checkpoint====================
====================get the dataset====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
====================get the dataloader====================
====================start train====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Step: 1	 Data: torch.Size([10, 384])	 Training Loss: 1.0653092861175537
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/genghaozhe/.pyenv/versions/3.10.14/envs/colossalai-py310/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Step: 2	 Data: torch.Size([10, 384])	 Training Loss: 1.0278429985046387
Step: 3	 Data: torch.Size([10, 384])	 Training Loss: 0.9651218056678772
Step: 4	 Data: torch.Size([10, 384])	 Training Loss: 1.1959102153778076
Step: 5	 Data: torch.Size([10, 384])	 Training Loss: 1.2690505981445312
Step: 6	 Data: torch.Size([10, 302])	 Training Loss: 1.2422505617141724
Step: 7	 Data: torch.Size([10, 384])	 Training Loss: 1.2205052375793457
Step: 8	 Data: torch.Size([10, 384])	 Training Loss: 1.107346534729004
Step: 9	 Data: torch.Size([10, 384])	 Training Loss: 1.114519715309143
Step: 10	 Data: torch.Size([10, 384])	 Training Loss: 1.0365967750549316
Step: 11	 Data: torch.Size([10, 384])	 Training Loss: 1.3831335306167603
Step: 12	 Data: torch.Size([10, 319])	 Training Loss: 1.194999098777771
Step: 13	 Data: torch.Size([10, 384])	 Training Loss: 1.19422447681427
Step: 14	 Data: torch.Size([10, 384])	 Training Loss: 0.9865618348121643
Step: 15	 Data: torch.Size([10, 384])	 Training Loss: 0.9891955256462097
Step: 16	 Data: torch.Size([10, 384])	 Training Loss: 1.2221966981887817
Step: 17	 Data: torch.Size([10, 384])	 Training Loss: 1.1428720951080322
Step: 18	 Data: torch.Size([10, 384])	 Training Loss: 1.2005760669708252
Step: 19	 Data: torch.Size([10, 384])	 Training Loss: 1.1268420219421387
Step: 20	 Data: torch.Size([10, 384])	 Training Loss: 1.1288299560546875
Step: 21	 Data: torch.Size([10, 384])	 Training Loss: 1.2492588758468628
Step: 22	 Data: torch.Size([10, 384])	 Training Loss: 1.050816535949707
Step: 23	 Data: torch.Size([10, 384])	 Training Loss: 1.1553096771240234
Step: 24	 Data: torch.Size([10, 384])	 Training Loss: 1.080373764038086
Step: 25	 Data: torch.Size([10, 384])	 Training Loss: 1.1559845209121704
Step: 26	 Data: torch.Size([10, 384])	 Training Loss: 1.0846683979034424
Step: 27	 Data: torch.Size([10, 384])	 Training Loss: 1.3653889894485474
Step: 28	 Data: torch.Size([10, 384])	 Training Loss: 1.1509933471679688
Step: 29	 Data: torch.Size([10, 384])	 Training Loss: 1.1187849044799805
Step: 30	 Data: torch.Size([10, 384])	 Training Loss: 1.1614456176757812
Step: 31	 Data: torch.Size([10, 384])	 Training Loss: 0.9880155920982361
Step: 32	 Data: torch.Size([10, 384])	 Training Loss: 1.061606526374817
Step: 33	 Data: torch.Size([10, 384])	 Training Loss: 1.0280447006225586
Step: 34	 Data: torch.Size([10, 384])	 Training Loss: 1.1567519903182983
Step: 35	 Data: torch.Size([10, 384])	 Training Loss: 1.188761591911316
Step: 36	 Data: torch.Size([10, 384])	 Training Loss: 0.9823852777481079
Step: 37	 Data: torch.Size([10, 384])	 Training Loss: 1.1752289533615112
Step: 38	 Data: torch.Size([10, 384])	 Training Loss: 1.4689892530441284
Step: 39	 Data: torch.Size([10, 384])	 Training Loss: 1.297648310661316
Step: 40	 Data: torch.Size([10, 384])	 Training Loss: 1.1350562572479248
Step: 41	 Data: torch.Size([10, 384])	 Training Loss: 1.1640318632125854
Step: 42	 Data: torch.Size([10, 384])	 Training Loss: 1.0525684356689453
Step: 43	 Data: torch.Size([10, 384])	 Training Loss: 1.1551353931427002
Step: 44	 Data: torch.Size([10, 384])	 Training Loss: 1.0011711120605469
Step: 45	 Data: torch.Size([10, 384])	 Training Loss: 0.960288941860199
Step: 46	 Data: torch.Size([10, 384])	 Training Loss: 1.1806645393371582
Step: 47	 Data: torch.Size([10, 384])	 Training Loss: 1.2872377634048462
Step: 48	 Data: torch.Size([10, 384])	 Training Loss: 1.0257360935211182
Step: 49	 Data: torch.Size([10, 384])	 Training Loss: 1.0614253282546997
Step: 50	 Data: torch.Size([10, 384])	 Training Loss: 1.0674760341644287
Step: 51	 Data: torch.Size([10, 384])	 Training Loss: 0.9830498695373535
Step: 52	 Data: torch.Size([10, 384])	 Training Loss: 0.9805925488471985
Step: 53	 Data: torch.Size([10, 384])	 Training Loss: 1.043236255645752
Step: 54	 Data: torch.Size([10, 384])	 Training Loss: 1.1065914630889893
Step: 55	 Data: torch.Size([10, 384])	 Training Loss: 1.3503031730651855
Step: 56	 Data: torch.Size([10, 384])	 Training Loss: 1.2549314498901367
Step: 57	 Data: torch.Size([10, 384])	 Training Loss: 1.0746349096298218
Step: 58	 Data: torch.Size([10, 384])	 Training Loss: 1.2749288082122803
Step: 59	 Data: torch.Size([10, 384])	 Training Loss: 1.0846188068389893
Step: 60	 Data: torch.Size([10, 384])	 Training Loss: 1.1233936548233032
Step: 61	 Data: torch.Size([10, 384])	 Training Loss: 1.0337598323822021
Step: 62	 Data: torch.Size([10, 384])	 Training Loss: 1.017722249031067
Step: 63	 Data: torch.Size([10, 384])	 Training Loss: 1.0155141353607178
Step: 64	 Data: torch.Size([10, 384])	 Training Loss: 1.0913845300674438
Step: 65	 Data: torch.Size([10, 384])	 Training Loss: 1.0585857629776
Step: 66	 Data: torch.Size([10, 384])	 Training Loss: 1.1808521747589111
Step: 67	 Data: torch.Size([10, 384])	 Training Loss: 1.0114073753356934
Step: 68	 Data: torch.Size([10, 384])	 Training Loss: 1.0945876836776733
Step: 69	 Data: torch.Size([10, 384])	 Training Loss: 1.165457010269165
Step: 70	 Data: torch.Size([10, 384])	 Training Loss: 1.0912460088729858
Step: 71	 Data: torch.Size([10, 384])	 Training Loss: 1.0789943933486938
Step: 72	 Data: torch.Size([10, 384])	 Training Loss: 0.9829636812210083
Step: 73	 Data: torch.Size([10, 384])	 Training Loss: 0.971741795539856
Step: 74	 Data: torch.Size([10, 384])	 Training Loss: 0.9967336654663086
Step: 75	 Data: torch.Size([10, 384])	 Training Loss: 1.1974068880081177
Step: 76	 Data: torch.Size([10, 384])	 Training Loss: 0.9605802893638611
Step: 77	 Data: torch.Size([10, 384])	 Training Loss: 1.123692512512207
Step: 78	 Data: torch.Size([10, 384])	 Training Loss: 1.118935227394104
Step: 79	 Data: torch.Size([10, 384])	 Training Loss: 1.2882299423217773
Step: 80	 Data: torch.Size([10, 384])	 Training Loss: 1.0847125053405762
Step: 81	 Data: torch.Size([10, 384])	 Training Loss: 1.1063337326049805
Step: 82	 Data: torch.Size([10, 384])	 Training Loss: 1.115229606628418
Step: 83	 Data: torch.Size([10, 384])	 Training Loss: 1.206398367881775
Step: 84	 Data: torch.Size([10, 384])	 Training Loss: 1.175794243812561
Step: 85	 Data: torch.Size([10, 384])	 Training Loss: 1.1422957181930542
Step: 86	 Data: torch.Size([10, 384])	 Training Loss: 1.2846897840499878
Step: 87	 Data: torch.Size([10, 384])	 Training Loss: 1.128890872001648
Step: 88	 Data: torch.Size([10, 384])	 Training Loss: 1.2271955013275146
Step: 89	 Data: torch.Size([10, 384])	 Training Loss: 1.0350651741027832
Step: 90	 Data: torch.Size([10, 384])	 Training Loss: 1.222094178199768
Step: 91	 Data: torch.Size([10, 384])	 Training Loss: 0.974824070930481
Step: 92	 Data: torch.Size([10, 384])	 Training Loss: 0.9954119324684143
Step: 93	 Data: torch.Size([10, 384])	 Training Loss: 0.9967303276062012
Step: 94	 Data: torch.Size([10, 384])	 Training Loss: 0.9267263412475586
Step: 95	 Data: torch.Size([10, 384])	 Training Loss: 0.9881711006164551
Step: 96	 Data: torch.Size([10, 384])	 Training Loss: 1.0938833951950073
Step: 97	 Data: torch.Size([10, 384])	 Training Loss: 1.1020512580871582
Step: 98	 Data: torch.Size([10, 384])	 Training Loss: 1.2194898128509521
Step: 99	 Data: torch.Size([10, 384])	 Training Loss: 1.0196168422698975
Step: 100	 Data: torch.Size([10, 384])	 Training Loss: 1.050872564315796
Step: 101	 Data: torch.Size([10, 384])	 Training Loss: 1.175194263458252
Step: 102	 Data: torch.Size([10, 384])	 Training Loss: 1.1320393085479736
Step: 103	 Data: torch.Size([10, 384])	 Training Loss: 1.1043990850448608
Step: 104	 Data: torch.Size([10, 384])	 Training Loss: 1.2100332975387573
Step: 105	 Data: torch.Size([10, 384])	 Training Loss: 1.1366932392120361
Step: 106	 Data: torch.Size([10, 384])	 Training Loss: 1.0751694440841675
Step: 107	 Data: torch.Size([10, 384])	 Training Loss: 1.1390037536621094
Step: 108	 Data: torch.Size([10, 384])	 Training Loss: 0.9417579770088196
Step: 109	 Data: torch.Size([10, 384])	 Training Loss: 1.1859550476074219
Step: 110	 Data: torch.Size([10, 384])	 Training Loss: 1.1349503993988037
Step: 111	 Data: torch.Size([10, 384])	 Training Loss: 0.9548419117927551
Step: 112	 Data: torch.Size([10, 384])	 Training Loss: 1.1444026231765747
Step: 113	 Data: torch.Size([10, 384])	 Training Loss: 1.0744118690490723
Step: 114	 Data: torch.Size([10, 349])	 Training Loss: 1.0854429006576538
Step: 115	 Data: torch.Size([10, 384])	 Training Loss: 0.9367682933807373
Step: 116	 Data: torch.Size([10, 384])	 Training Loss: 1.0750885009765625
Step: 117	 Data: torch.Size([10, 384])	 Training Loss: 1.3307974338531494
Step: 118	 Data: torch.Size([10, 384])	 Training Loss: 1.0040216445922852
Step: 119	 Data: torch.Size([10, 384])	 Training Loss: 1.0107725858688354
Step: 120	 Data: torch.Size([10, 384])	 Training Loss: 1.0165674686431885
Step: 121	 Data: torch.Size([10, 384])	 Training Loss: 1.0061917304992676
Step: 122	 Data: torch.Size([10, 384])	 Training Loss: 1.0940518379211426
Step: 123	 Data: torch.Size([10, 384])	 Training Loss: 1.0846822261810303
Step: 124	 Data: torch.Size([10, 384])	 Training Loss: 1.125714898109436
Step: 125	 Data: torch.Size([10, 384])	 Training Loss: 1.1015450954437256
Step: 126	 Data: torch.Size([10, 384])	 Training Loss: 1.2393338680267334
Step: 127	 Data: torch.Size([10, 384])	 Training Loss: 0.997559130191803
Step: 128	 Data: torch.Size([10, 384])	 Training Loss: 1.0009009838104248
Step: 129	 Data: torch.Size([10, 384])	 Training Loss: 1.045358657836914
Step: 130	 Data: torch.Size([10, 384])	 Training Loss: 0.9722476601600647
Step: 131	 Data: torch.Size([10, 384])	 Training Loss: 1.1365647315979004
Step: 132	 Data: torch.Size([10, 384])	 Training Loss: 1.1431487798690796
Step: 133	 Data: torch.Size([10, 384])	 Training Loss: 1.0716567039489746
Step: 134	 Data: torch.Size([10, 384])	 Training Loss: 0.95770663022995
Step: 135	 Data: torch.Size([10, 384])	 Training Loss: 1.1653071641921997
Step: 136	 Data: torch.Size([10, 384])	 Training Loss: 1.0225696563720703
Step: 137	 Data: torch.Size([10, 384])	 Training Loss: 1.1228916645050049
Step: 138	 Data: torch.Size([10, 384])	 Training Loss: 1.0523289442062378
Step: 139	 Data: torch.Size([10, 384])	 Training Loss: 1.1286040544509888
Step: 140	 Data: torch.Size([10, 384])	 Training Loss: 1.0958503484725952
Step: 141	 Data: torch.Size([10, 384])	 Training Loss: 1.184993863105774
Step: 142	 Data: torch.Size([10, 384])	 Training Loss: 1.116309642791748
Step: 143	 Data: torch.Size([10, 384])	 Training Loss: 1.1571389436721802
Step: 144	 Data: torch.Size([10, 384])	 Training Loss: 1.1496330499649048
Step: 145	 Data: torch.Size([10, 384])	 Training Loss: 1.028813123703003
Step: 146	 Data: torch.Size([10, 384])	 Training Loss: 0.9361956119537354
Step: 147	 Data: torch.Size([10, 384])	 Training Loss: 1.075331687927246
Step: 148	 Data: torch.Size([10, 384])	 Training Loss: 1.0112903118133545
Step: 149	 Data: torch.Size([10, 384])	 Training Loss: 1.2281683683395386
Step: 150	 Data: torch.Size([10, 384])	 Training Loss: 0.9845470786094666
Step: 151	 Data: torch.Size([10, 384])	 Training Loss: 0.9287893176078796
Step: 152	 Data: torch.Size([10, 384])	 Training Loss: 1.0738840103149414
Step: 153	 Data: torch.Size([10, 384])	 Training Loss: 1.3226573467254639
Step: 154	 Data: torch.Size([10, 384])	 Training Loss: 1.0202319622039795
Step: 155	 Data: torch.Size([10, 384])	 Training Loss: 1.111000657081604
Step: 156	 Data: torch.Size([10, 384])	 Training Loss: 1.1442925930023193
Step: 157	 Data: torch.Size([10, 384])	 Training Loss: 1.0281293392181396
Step: 158	 Data: torch.Size([10, 384])	 Training Loss: 0.9715533256530762
Step: 159	 Data: torch.Size([10, 384])	 Training Loss: 1.2535672187805176
Step: 160	 Data: torch.Size([10, 384])	 Training Loss: 1.1286882162094116
Step: 161	 Data: torch.Size([10, 384])	 Training Loss: 1.004845142364502
Step: 162	 Data: torch.Size([10, 384])	 Training Loss: 1.0206574201583862
Step: 163	 Data: torch.Size([10, 384])	 Training Loss: 1.1426336765289307
Step: 164	 Data: torch.Size([10, 384])	 Training Loss: 0.9924020171165466
Step: 165	 Data: torch.Size([10, 384])	 Training Loss: 1.0756123065948486
Step: 166	 Data: torch.Size([10, 384])	 Training Loss: 1.1652213335037231
Step: 167	 Data: torch.Size([10, 384])	 Training Loss: 0.9406943917274475
Step: 168	 Data: torch.Size([10, 384])	 Training Loss: 1.1563682556152344
Step: 169	 Data: torch.Size([10, 384])	 Training Loss: 1.068638563156128
Step: 170	 Data: torch.Size([10, 384])	 Training Loss: 1.0490775108337402
Step: 171	 Data: torch.Size([10, 384])	 Training Loss: 1.0704489946365356
Step: 172	 Data: torch.Size([10, 384])	 Training Loss: 1.0256481170654297
Step: 173	 Data: torch.Size([10, 384])	 Training Loss: 1.2580236196517944
Step: 174	 Data: torch.Size([10, 384])	 Training Loss: 1.0928444862365723
Step: 175	 Data: torch.Size([10, 384])	 Training Loss: 1.2145607471466064
Step: 176	 Data: torch.Size([10, 384])	 Training Loss: 0.9465382099151611
Step: 177	 Data: torch.Size([10, 346])	 Training Loss: 1.1325494050979614
Step: 178	 Data: torch.Size([10, 384])	 Training Loss: 0.9649801254272461
Step: 179	 Data: torch.Size([10, 384])	 Training Loss: 0.9931496977806091
Step: 180	 Data: torch.Size([10, 384])	 Training Loss: 1.0606638193130493
Step: 181	 Data: torch.Size([10, 384])	 Training Loss: 1.087026834487915
Step: 182	 Data: torch.Size([10, 384])	 Training Loss: 1.0920442342758179
Step: 183	 Data: torch.Size([10, 384])	 Training Loss: 1.0126750469207764
Step: 184	 Data: torch.Size([10, 384])	 Training Loss: 1.3103444576263428
Step: 185	 Data: torch.Size([10, 384])	 Training Loss: 1.2274259328842163
Step: 186	 Data: torch.Size([10, 384])	 Training Loss: 1.112246036529541
Step: 187	 Data: torch.Size([10, 384])	 Training Loss: 1.1960127353668213
Step: 188	 Data: torch.Size([10, 384])	 Training Loss: 1.0438097715377808
Step: 189	 Data: torch.Size([10, 384])	 Training Loss: 1.1189926862716675
Step: 190	 Data: torch.Size([10, 384])	 Training Loss: 1.1318846940994263
Step: 191	 Data: torch.Size([10, 384])	 Training Loss: 1.156636118888855
Step: 192	 Data: torch.Size([10, 384])	 Training Loss: 0.9797350168228149
Step: 193	 Data: torch.Size([10, 384])	 Training Loss: 1.0237735509872437
Step: 194	 Data: torch.Size([10, 384])	 Training Loss: 1.1724509000778198
Step: 195	 Data: torch.Size([10, 384])	 Training Loss: 1.067172646522522
Step: 196	 Data: torch.Size([10, 384])	 Training Loss: 1.1082450151443481
Step: 197	 Data: torch.Size([10, 384])	 Training Loss: 1.1602752208709717
Step: 198	 Data: torch.Size([10, 384])	 Training Loss: 1.0563308000564575
Step: 199	 Data: torch.Size([10, 384])	 Training Loss: 1.1131751537322998
Step: 200	 Data: torch.Size([10, 384])	 Training Loss: 1.0136306285858154
Step: 201	 Data: torch.Size([10, 384])	 Training Loss: 1.122441291809082
Step: 202	 Data: torch.Size([10, 277])	 Training Loss: 1.3522469997406006
Step: 203	 Data: torch.Size([10, 384])	 Training Loss: 1.1895866394042969
Step: 204	 Data: torch.Size([10, 384])	 Training Loss: 1.1673306226730347
Step: 205	 Data: torch.Size([10, 384])	 Training Loss: 1.235917568206787
Step: 206	 Data: torch.Size([10, 356])	 Training Loss: 1.1469018459320068
Step: 207	 Data: torch.Size([10, 384])	 Training Loss: 1.0512385368347168
Step: 208	 Data: torch.Size([10, 384])	 Training Loss: 0.9309384822845459
Step: 209	 Data: torch.Size([10, 384])	 Training Loss: 1.0275133848190308
Step: 210	 Data: torch.Size([10, 384])	 Training Loss: 1.1812045574188232
Step: 211	 Data: torch.Size([10, 355])	 Training Loss: 1.1715383529663086
Step: 212	 Data: torch.Size([10, 384])	 Training Loss: 1.0052469968795776
Step: 213	 Data: torch.Size([10, 384])	 Training Loss: 1.2458586692810059
Step: 214	 Data: torch.Size([10, 384])	 Training Loss: 1.1116485595703125
Step: 215	 Data: torch.Size([10, 384])	 Training Loss: 0.9839335680007935
Step: 216	 Data: torch.Size([10, 384])	 Training Loss: 1.000235915184021
Step: 217	 Data: torch.Size([10, 384])	 Training Loss: 1.067276120185852
Step: 218	 Data: torch.Size([10, 384])	 Training Loss: 1.1676862239837646
Step: 219	 Data: torch.Size([10, 384])	 Training Loss: 1.1413789987564087
Step: 220	 Data: torch.Size([10, 384])	 Training Loss: 1.0371290445327759
Step: 221	 Data: torch.Size([10, 384])	 Training Loss: 1.1254098415374756
Step: 222	 Data: torch.Size([10, 384])	 Training Loss: 1.1138558387756348
Step: 223	 Data: torch.Size([10, 384])	 Training Loss: 1.07245671749115
Step: 224	 Data: torch.Size([10, 384])	 Training Loss: 1.0316286087036133
Step: 225	 Data: torch.Size([10, 384])	 Training Loss: 1.073906421661377
Step: 226	 Data: torch.Size([10, 384])	 Training Loss: 1.207476019859314
Step: 227	 Data: torch.Size([10, 384])	 Training Loss: 1.1920077800750732
Step: 228	 Data: torch.Size([10, 384])	 Training Loss: 0.9279270172119141
Step: 229	 Data: torch.Size([10, 384])	 Training Loss: 1.0646905899047852
Step: 230	 Data: torch.Size([10, 384])	 Training Loss: 1.1471399068832397
Step: 231	 Data: torch.Size([10, 384])	 Training Loss: 0.9095152020454407
Step: 232	 Data: torch.Size([10, 384])	 Training Loss: 1.133684515953064
Step: 233	 Data: torch.Size([10, 384])	 Training Loss: 1.0180484056472778
Step: 234	 Data: torch.Size([10, 384])	 Training Loss: 1.3049544095993042
Step: 235	 Data: torch.Size([10, 384])	 Training Loss: 1.1219686269760132
Step: 236	 Data: torch.Size([10, 384])	 Training Loss: 1.1809862852096558
Step: 237	 Data: torch.Size([10, 384])	 Training Loss: 1.0912494659423828
Step: 238	 Data: torch.Size([10, 384])	 Training Loss: 1.1740562915802002
Step: 239	 Data: torch.Size([10, 384])	 Training Loss: 1.1656794548034668
Step: 240	 Data: torch.Size([10, 384])	 Training Loss: 1.098803162574768
Step: 241	 Data: torch.Size([10, 384])	 Training Loss: 1.2694534063339233
Step: 242	 Data: torch.Size([10, 384])	 Training Loss: 1.1532163619995117
Step: 243	 Data: torch.Size([10, 384])	 Training Loss: 1.1435199975967407
Step: 244	 Data: torch.Size([10, 384])	 Training Loss: 1.0514566898345947
Step: 245	 Data: torch.Size([10, 384])	 Training Loss: 1.1489912271499634
Step: 246	 Data: torch.Size([10, 384])	 Training Loss: 1.2397966384887695
Step: 247	 Data: torch.Size([10, 384])	 Training Loss: 1.1505206823349
Step: 248	 Data: torch.Size([10, 384])	 Training Loss: 1.16852605342865
Step: 249	 Data: torch.Size([10, 384])	 Training Loss: 1.2590943574905396
Step: 250	 Data: torch.Size([10, 340])	 Training Loss: 1.4066293239593506
Step: 251	 Data: torch.Size([10, 384])	 Training Loss: 1.1916924715042114
Step: 252	 Data: torch.Size([10, 384])	 Training Loss: 1.0191770792007446
Step: 253	 Data: torch.Size([10, 384])	 Training Loss: 1.1569923162460327
Step: 254	 Data: torch.Size([10, 384])	 Training Loss: 1.0402140617370605
Step: 255	 Data: torch.Size([10, 384])	 Training Loss: 1.186305284500122
Step: 256	 Data: torch.Size([10, 384])	 Training Loss: 1.1095457077026367
Step: 257	 Data: torch.Size([10, 384])	 Training Loss: 1.1364113092422485
Step: 258	 Data: torch.Size([10, 384])	 Training Loss: 1.055233120918274
Step: 259	 Data: torch.Size([10, 384])	 Training Loss: 1.037274956703186
Step: 260	 Data: torch.Size([10, 384])	 Training Loss: 1.0276060104370117
Step: 261	 Data: torch.Size([10, 384])	 Training Loss: 0.999177873134613
Step: 262	 Data: torch.Size([10, 384])	 Training Loss: 1.0979173183441162
Step: 263	 Data: torch.Size([10, 384])	 Training Loss: 1.0685274600982666
Step: 264	 Data: torch.Size([10, 384])	 Training Loss: 0.9838491678237915
Step: 265	 Data: torch.Size([10, 384])	 Training Loss: 1.0124876499176025
Step: 266	 Data: torch.Size([10, 384])	 Training Loss: 1.215683937072754
Step: 267	 Data: torch.Size([10, 384])	 Training Loss: 1.034942626953125
Step: 268	 Data: torch.Size([10, 384])	 Training Loss: 1.0515494346618652
Step: 269	 Data: torch.Size([10, 384])	 Training Loss: 1.143166422843933
Step: 270	 Data: torch.Size([10, 384])	 Training Loss: 1.0439687967300415
Step: 271	 Data: torch.Size([10, 384])	 Training Loss: 1.02975332736969
Step: 272	 Data: torch.Size([10, 384])	 Training Loss: 1.1755681037902832
Step: 273	 Data: torch.Size([10, 384])	 Training Loss: 1.0856804847717285
Step: 274	 Data: torch.Size([10, 384])	 Training Loss: 1.257680892944336
Step: 275	 Data: torch.Size([10, 384])	 Training Loss: 1.0892696380615234
Step: 276	 Data: torch.Size([10, 384])	 Training Loss: 1.123671531677246
Step: 277	 Data: torch.Size([10, 384])	 Training Loss: 1.0652238130569458
Step: 278	 Data: torch.Size([10, 384])	 Training Loss: 1.0639995336532593
Step: 279	 Data: torch.Size([10, 384])	 Training Loss: 1.0694690942764282
Step: 280	 Data: torch.Size([10, 384])	 Training Loss: 0.9822126626968384
Step: 281	 Data: torch.Size([10, 384])	 Training Loss: 1.263249158859253
Step: 282	 Data: torch.Size([10, 384])	 Training Loss: 1.0543643236160278
Step: 283	 Data: torch.Size([10, 384])	 Training Loss: 1.0376567840576172
Step: 284	 Data: torch.Size([10, 384])	 Training Loss: 1.232978343963623
Step: 285	 Data: torch.Size([10, 384])	 Training Loss: 1.0241519212722778
Step: 286	 Data: torch.Size([10, 384])	 Training Loss: 1.1197084188461304
Step: 287	 Data: torch.Size([10, 384])	 Training Loss: 1.1049398183822632
Step: 288	 Data: torch.Size([10, 384])	 Training Loss: 1.1592671871185303
Step: 289	 Data: torch.Size([10, 384])	 Training Loss: 1.1078211069107056
Step: 290	 Data: torch.Size([10, 384])	 Training Loss: 1.1207969188690186
Step: 291	 Data: torch.Size([10, 384])	 Training Loss: 1.0984220504760742
Step: 292	 Data: torch.Size([10, 384])	 Training Loss: 0.9371644258499146
Step: 293	 Data: torch.Size([10, 372])	 Training Loss: 1.0967156887054443
Step: 294	 Data: torch.Size([10, 384])	 Training Loss: 1.2206894159317017
Step: 295	 Data: torch.Size([10, 384])	 Training Loss: 1.031589150428772
Step: 296	 Data: torch.Size([10, 384])	 Training Loss: 1.0895495414733887
Step: 297	 Data: torch.Size([10, 213])	 Training Loss: 1.4386199712753296
Step: 298	 Data: torch.Size([10, 384])	 Training Loss: 1.133093237876892
Step: 299	 Data: torch.Size([10, 384])	 Training Loss: 1.0013126134872437
Step: 300	 Data: torch.Size([10, 384])	 Training Loss: 1.2453973293304443
Step: 301	 Data: torch.Size([10, 384])	 Training Loss: 1.2564877271652222
Step: 302	 Data: torch.Size([10, 384])	 Training Loss: 1.0524965524673462
Step: 303	 Data: torch.Size([10, 384])	 Training Loss: 1.1146109104156494
Step: 304	 Data: torch.Size([10, 384])	 Training Loss: 1.0497831106185913
Step: 305	 Data: torch.Size([10, 384])	 Training Loss: 1.021508812904358
Step: 306	 Data: torch.Size([10, 384])	 Training Loss: 1.2082778215408325
Step: 307	 Data: torch.Size([10, 384])	 Training Loss: 1.1450636386871338
Step: 308	 Data: torch.Size([10, 384])	 Training Loss: 1.2877964973449707
Step: 309	 Data: torch.Size([10, 384])	 Training Loss: 1.111948847770691
Step: 310	 Data: torch.Size([10, 384])	 Training Loss: 1.1463899612426758
Step: 311	 Data: torch.Size([10, 384])	 Training Loss: 1.1129283905029297
Step: 312	 Data: torch.Size([10, 384])	 Training Loss: 1.0292071104049683
Step: 313	 Data: torch.Size([10, 384])	 Training Loss: 1.1280876398086548
Step: 314	 Data: torch.Size([10, 384])	 Training Loss: 1.0977596044540405
Step: 315	 Data: torch.Size([10, 384])	 Training Loss: 1.134063482284546
Step: 316	 Data: torch.Size([10, 384])	 Training Loss: 0.9669108390808105
Step: 317	 Data: torch.Size([10, 384])	 Training Loss: 1.0448729991912842
Step: 318	 Data: torch.Size([10, 384])	 Training Loss: 1.334202527999878
Step: 319	 Data: torch.Size([10, 384])	 Training Loss: 1.1512784957885742
Step: 320	 Data: torch.Size([10, 384])	 Training Loss: 1.3955620527267456
Step: 321	 Data: torch.Size([10, 384])	 Training Loss: 1.1572744846343994
Step: 322	 Data: torch.Size([10, 384])	 Training Loss: 1.3262909650802612
Step: 323	 Data: torch.Size([10, 384])	 Training Loss: 1.1075609922409058
Step: 324	 Data: torch.Size([10, 384])	 Training Loss: 1.043452501296997
Step: 325	 Data: torch.Size([10, 384])	 Training Loss: 0.9924442768096924
Step: 326	 Data: torch.Size([10, 384])	 Training Loss: 0.9543129801750183
Step: 327	 Data: torch.Size([10, 384])	 Training Loss: 1.1406241655349731
Step: 328	 Data: torch.Size([10, 384])	 Training Loss: 1.33137047290802
Step: 329	 Data: torch.Size([10, 384])	 Training Loss: 1.3079488277435303
Step: 330	 Data: torch.Size([10, 384])	 Training Loss: 1.0940643548965454
Step: 331	 Data: torch.Size([10, 384])	 Training Loss: 0.9296151995658875
Step: 332	 Data: torch.Size([10, 384])	 Training Loss: 1.133939504623413
Step: 333	 Data: torch.Size([10, 384])	 Training Loss: 1.127663493156433
Step: 334	 Data: torch.Size([10, 384])	 Training Loss: 1.2035551071166992
Step: 335	 Data: torch.Size([10, 384])	 Training Loss: 0.9950271248817444
Step: 336	 Data: torch.Size([10, 384])	 Training Loss: 0.9715834259986877
Step: 337	 Data: torch.Size([10, 384])	 Training Loss: 1.2300881147384644
Step: 338	 Data: torch.Size([10, 384])	 Training Loss: 1.234562873840332
Step: 339	 Data: torch.Size([10, 384])	 Training Loss: 1.0994548797607422
Step: 340	 Data: torch.Size([10, 384])	 Training Loss: 0.9842334389686584
Step: 341	 Data: torch.Size([10, 384])	 Training Loss: 0.963503897190094
Step: 342	 Data: torch.Size([10, 384])	 Training Loss: 1.1275634765625
Step: 343	 Data: torch.Size([10, 384])	 Training Loss: 1.1977474689483643
Step: 344	 Data: torch.Size([10, 384])	 Training Loss: 1.255901575088501
Step: 345	 Data: torch.Size([10, 384])	 Training Loss: 1.1407994031906128
Step: 346	 Data: torch.Size([10, 384])	 Training Loss: 1.089868426322937
Step: 347	 Data: torch.Size([10, 384])	 Training Loss: 1.2364295721054077
Step: 348	 Data: torch.Size([10, 384])	 Training Loss: 1.1669068336486816
Step: 349	 Data: torch.Size([10, 384])	 Training Loss: 1.0310959815979004
Step: 350	 Data: torch.Size([10, 384])	 Training Loss: 1.0386838912963867
Step: 351	 Data: torch.Size([10, 384])	 Training Loss: 1.008263111114502
Step: 352	 Data: torch.Size([10, 384])	 Training Loss: 1.1651644706726074
Step: 353	 Data: torch.Size([10, 384])	 Training Loss: 1.2005195617675781
Step: 354	 Data: torch.Size([10, 384])	 Training Loss: 1.104580044746399
Step: 355	 Data: torch.Size([10, 384])	 Training Loss: 1.010470986366272
Step: 356	 Data: torch.Size([10, 384])	 Training Loss: 1.2487186193466187
Step: 357	 Data: torch.Size([10, 384])	 Training Loss: 1.1249762773513794
Step: 358	 Data: torch.Size([10, 384])	 Training Loss: 1.230216145515442
Step: 359	 Data: torch.Size([10, 384])	 Training Loss: 1.1045503616333008
Step: 360	 Data: torch.Size([10, 384])	 Training Loss: 1.2063677310943604
Step: 361	 Data: torch.Size([10, 384])	 Training Loss: 1.0121612548828125
Step: 362	 Data: torch.Size([10, 384])	 Training Loss: 1.0471924543380737
Step: 363	 Data: torch.Size([10, 384])	 Training Loss: 1.0708717107772827
Step: 364	 Data: torch.Size([10, 384])	 Training Loss: 1.1609328985214233
Step: 365	 Data: torch.Size([10, 384])	 Training Loss: 0.9289223551750183
Step: 366	 Data: torch.Size([10, 384])	 Training Loss: 0.9127047061920166
Step: 367	 Data: torch.Size([10, 384])	 Training Loss: 1.0888155698776245
Step: 368	 Data: torch.Size([10, 384])	 Training Loss: 1.1970399618148804
Step: 369	 Data: torch.Size([10, 384])	 Training Loss: 1.2036465406417847
Step: 370	 Data: torch.Size([10, 384])	 Training Loss: 1.0298603773117065
Step: 371	 Data: torch.Size([10, 384])	 Training Loss: 0.9657808542251587
Step: 372	 Data: torch.Size([10, 384])	 Training Loss: 1.1618390083312988
Step: 373	 Data: torch.Size([10, 384])	 Training Loss: 1.1326996088027954
Step: 374	 Data: torch.Size([10, 384])	 Training Loss: 1.0223255157470703
Step: 375	 Data: torch.Size([10, 384])	 Training Loss: 1.030268907546997
Step: 376	 Data: torch.Size([10, 384])	 Training Loss: 1.0775123834609985
Step: 377	 Data: torch.Size([10, 384])	 Training Loss: 1.0968199968338013
Step: 378	 Data: torch.Size([10, 384])	 Training Loss: 1.167988657951355
Step: 379	 Data: torch.Size([10, 384])	 Training Loss: 0.9888374209403992
Step: 380	 Data: torch.Size([10, 384])	 Training Loss: 1.2520294189453125
Step: 381	 Data: torch.Size([10, 384])	 Training Loss: 1.0188074111938477
Step: 382	 Data: torch.Size([10, 384])	 Training Loss: 0.9945027828216553
Step: 383	 Data: torch.Size([10, 384])	 Training Loss: 1.1071009635925293
Step: 384	 Data: torch.Size([10, 384])	 Training Loss: 0.9518366456031799
Step: 385	 Data: torch.Size([10, 384])	 Training Loss: 0.995418131351471
Step: 386	 Data: torch.Size([10, 384])	 Training Loss: 1.173377513885498
Step: 387	 Data: torch.Size([10, 384])	 Training Loss: 1.0004991292953491
Step: 388	 Data: torch.Size([10, 384])	 Training Loss: 1.1264063119888306
Step: 389	 Data: torch.Size([10, 384])	 Training Loss: 1.3396222591400146
Step: 390	 Data: torch.Size([10, 384])	 Training Loss: 1.0756168365478516
Step: 391	 Data: torch.Size([10, 384])	 Training Loss: 1.3160459995269775
Step: 392	 Data: torch.Size([10, 384])	 Training Loss: 1.0831595659255981
Step: 393	 Data: torch.Size([10, 384])	 Training Loss: 1.0884034633636475
Step: 394	 Data: torch.Size([10, 270])	 Training Loss: 1.124871015548706
Step: 395	 Data: torch.Size([10, 384])	 Training Loss: 1.1395010948181152
Step: 396	 Data: torch.Size([10, 384])	 Training Loss: 1.0497057437896729
Step: 397	 Data: torch.Size([10, 384])	 Training Loss: 1.0439821481704712
Step: 398	 Data: torch.Size([10, 384])	 Training Loss: 1.1088838577270508
Step: 399	 Data: torch.Size([10, 384])	 Training Loss: 1.1306341886520386
Step: 400	 Data: torch.Size([10, 384])	 Training Loss: 1.1481010913848877
Step: 401	 Data: torch.Size([10, 384])	 Training Loss: 1.122170090675354
Step: 402	 Data: torch.Size([10, 384])	 Training Loss: 1.0143390893936157
Step: 403	 Data: torch.Size([10, 384])	 Training Loss: 1.1806113719940186
Step: 404	 Data: torch.Size([10, 384])	 Training Loss: 1.1190077066421509
Step: 405	 Data: torch.Size([10, 384])	 Training Loss: 1.2957206964492798
Step: 406	 Data: torch.Size([10, 384])	 Training Loss: 1.1559690237045288
Step: 407	 Data: torch.Size([10, 384])	 Training Loss: 1.0599879026412964
Step: 408	 Data: torch.Size([10, 384])	 Training Loss: 1.0813270807266235
Step: 409	 Data: torch.Size([10, 384])	 Training Loss: 0.964604914188385
Step: 410	 Data: torch.Size([10, 384])	 Training Loss: 1.0734355449676514
Step: 411	 Data: torch.Size([10, 384])	 Training Loss: 1.0356626510620117
Step: 412	 Data: torch.Size([10, 384])	 Training Loss: 1.158257246017456
Step: 413	 Data: torch.Size([10, 384])	 Training Loss: 1.0778419971466064
Step: 414	 Data: torch.Size([10, 384])	 Training Loss: 1.1018388271331787
Step: 415	 Data: torch.Size([10, 384])	 Training Loss: 1.0264720916748047
Step: 416	 Data: torch.Size([10, 384])	 Training Loss: 1.216475009918213
Step: 417	 Data: torch.Size([10, 384])	 Training Loss: 1.1558682918548584
Step: 418	 Data: torch.Size([10, 384])	 Training Loss: 1.2526363134384155
Step: 419	 Data: torch.Size([10, 384])	 Training Loss: 1.0785630941390991
Step: 420	 Data: torch.Size([10, 384])	 Training Loss: 0.9648898243904114
Step: 421	 Data: torch.Size([10, 384])	 Training Loss: 0.9869276285171509
Step: 422	 Data: torch.Size([10, 384])	 Training Loss: 1.0899120569229126
Step: 423	 Data: torch.Size([10, 384])	 Training Loss: 0.9849095940589905
Step: 424	 Data: torch.Size([10, 384])	 Training Loss: 0.9750775694847107
Step: 425	 Data: torch.Size([10, 384])	 Training Loss: 1.0430482625961304
Step: 426	 Data: torch.Size([10, 384])	 Training Loss: 0.9876843690872192
Step: 427	 Data: torch.Size([10, 384])	 Training Loss: 1.124820590019226
Step: 428	 Data: torch.Size([10, 384])	 Training Loss: 1.0408246517181396
Step: 429	 Data: torch.Size([10, 384])	 Training Loss: 1.0000395774841309
Step: 430	 Data: torch.Size([10, 384])	 Training Loss: 1.1386579275131226
Step: 431	 Data: torch.Size([10, 384])	 Training Loss: 1.0139836072921753
Step: 432	 Data: torch.Size([10, 384])	 Training Loss: 1.1423437595367432
Step: 433	 Data: torch.Size([10, 384])	 Training Loss: 1.0192478895187378
Step: 434	 Data: torch.Size([10, 384])	 Training Loss: 1.1472617387771606
Step: 435	 Data: torch.Size([10, 384])	 Training Loss: 0.8901835680007935
Step: 436	 Data: torch.Size([10, 384])	 Training Loss: 1.016470193862915
Step: 437	 Data: torch.Size([10, 384])	 Training Loss: 1.1458755731582642
Step: 438	 Data: torch.Size([10, 384])	 Training Loss: 1.2396131753921509
Step: 439	 Data: torch.Size([10, 384])	 Training Loss: 1.2955322265625
Step: 440	 Data: torch.Size([10, 384])	 Training Loss: 1.0847333669662476
Step: 441	 Data: torch.Size([10, 384])	 Training Loss: 1.0995491743087769
Step: 442	 Data: torch.Size([10, 384])	 Training Loss: 1.1825916767120361
Step: 443	 Data: torch.Size([10, 384])	 Training Loss: 1.0160057544708252
Step: 444	 Data: torch.Size([10, 384])	 Training Loss: 1.0932846069335938
Step: 445	 Data: torch.Size([10, 384])	 Training Loss: 1.1572332382202148
Step: 446	 Data: torch.Size([10, 384])	 Training Loss: 1.2357759475708008
Step: 447	 Data: torch.Size([10, 384])	 Training Loss: 1.1928021907806396
Step: 448	 Data: torch.Size([10, 384])	 Training Loss: 0.9901397824287415
Step: 449	 Data: torch.Size([10, 384])	 Training Loss: 1.2160332202911377
Step: 450	 Data: torch.Size([10, 384])	 Training Loss: 1.0357940196990967
Step: 451	 Data: torch.Size([10, 384])	 Training Loss: 1.0930262804031372
Step: 452	 Data: torch.Size([10, 384])	 Training Loss: 1.034604549407959
Step: 453	 Data: torch.Size([10, 384])	 Training Loss: 1.11708402633667
Step: 454	 Data: torch.Size([10, 384])	 Training Loss: 1.3144627809524536
Step: 455	 Data: torch.Size([10, 384])	 Training Loss: 1.1288248300552368
Step: 456	 Data: torch.Size([10, 384])	 Training Loss: 1.0412404537200928
Step: 457	 Data: torch.Size([10, 384])	 Training Loss: 1.112004280090332
Step: 458	 Data: torch.Size([10, 384])	 Training Loss: 1.0811361074447632
Step: 459	 Data: torch.Size([10, 384])	 Training Loss: 1.2364675998687744
Step: 460	 Data: torch.Size([10, 384])	 Training Loss: 1.055151343345642
Step: 461	 Data: torch.Size([10, 384])	 Training Loss: 1.131569266319275
Step: 462	 Data: torch.Size([10, 384])	 Training Loss: 1.2650597095489502
Step: 463	 Data: torch.Size([10, 384])	 Training Loss: 1.0797176361083984
Step: 464	 Data: torch.Size([10, 306])	 Training Loss: 1.3501468896865845
Step: 465	 Data: torch.Size([10, 249])	 Training Loss: 1.3195350170135498
Step: 466	 Data: torch.Size([10, 384])	 Training Loss: 1.1078801155090332
Step: 467	 Data: torch.Size([10, 384])	 Training Loss: 1.1007275581359863
Step: 468	 Data: torch.Size([10, 384])	 Training Loss: 1.1922607421875
Step: 469	 Data: torch.Size([10, 384])	 Training Loss: 1.1835455894470215
Step: 470	 Data: torch.Size([10, 384])	 Training Loss: 1.1638237237930298
Step: 471	 Data: torch.Size([10, 384])	 Training Loss: 1.094720482826233
Step: 472	 Data: torch.Size([10, 384])	 Training Loss: 1.0478155612945557
Step: 473	 Data: torch.Size([10, 384])	 Training Loss: 1.3488210439682007
Step: 474	 Data: torch.Size([10, 384])	 Training Loss: 1.169134497642517
Step: 475	 Data: torch.Size([10, 384])	 Training Loss: 1.0866307020187378
Step: 476	 Data: torch.Size([10, 384])	 Training Loss: 1.2625731229782104
Step: 477	 Data: torch.Size([10, 384])	 Training Loss: 1.0387647151947021
Step: 478	 Data: torch.Size([10, 384])	 Training Loss: 1.072426199913025
Step: 479	 Data: torch.Size([10, 384])	 Training Loss: 1.1801650524139404
Step: 480	 Data: torch.Size([10, 384])	 Training Loss: 1.154854416847229
Step: 481	 Data: torch.Size([10, 384])	 Training Loss: 0.979267954826355
Step: 482	 Data: torch.Size([10, 384])	 Training Loss: 1.174474835395813
Step: 483	 Data: torch.Size([10, 384])	 Training Loss: 1.2389631271362305
Step: 484	 Data: torch.Size([10, 384])	 Training Loss: 0.9892584681510925
Step: 485	 Data: torch.Size([10, 384])	 Training Loss: 0.971145510673523
Step: 486	 Data: torch.Size([10, 384])	 Training Loss: 1.1334086656570435
Step: 487	 Data: torch.Size([10, 384])	 Training Loss: 0.9450998306274414
Step: 488	 Data: torch.Size([10, 384])	 Training Loss: 1.1249103546142578
Step: 489	 Data: torch.Size([10, 384])	 Training Loss: 1.0758565664291382
Step: 490	 Data: torch.Size([10, 384])	 Training Loss: 1.0839632749557495
Step: 491	 Data: torch.Size([10, 384])	 Training Loss: 0.939222514629364
Step: 492	 Data: torch.Size([10, 384])	 Training Loss: 0.991614043712616
Step: 493	 Data: torch.Size([10, 384])	 Training Loss: 1.1214079856872559
Step: 494	 Data: torch.Size([10, 384])	 Training Loss: 1.0021380186080933
Step: 495	 Data: torch.Size([10, 384])	 Training Loss: 1.2290645837783813
Step: 496	 Data: torch.Size([10, 384])	 Training Loss: 1.0977647304534912
Step: 497	 Data: torch.Size([10, 384])	 Training Loss: 1.2226487398147583
Step: 498	 Data: torch.Size([10, 384])	 Training Loss: 1.2268450260162354
Step: 499	 Data: torch.Size([10, 384])	 Training Loss: 1.1719801425933838
Step: 500	 Data: torch.Size([10, 384])	 Training Loss: 1.1596945524215698
Step: 501	 Data: torch.Size([10, 384])	 Training Loss: 1.0190166234970093
Step: 502	 Data: torch.Size([10, 384])	 Training Loss: 1.099888563156128
Step: 503	 Data: torch.Size([10, 384])	 Training Loss: 1.0624295473098755
Step: 504	 Data: torch.Size([10, 384])	 Training Loss: 1.0376063585281372
Step: 505	 Data: torch.Size([10, 384])	 Training Loss: 1.351531744003296
Step: 506	 Data: torch.Size([10, 384])	 Training Loss: 0.9392232298851013
Step: 507	 Data: torch.Size([10, 384])	 Training Loss: 1.0130393505096436
Step: 508	 Data: torch.Size([10, 384])	 Training Loss: 1.2320597171783447
Step: 509	 Data: torch.Size([10, 384])	 Training Loss: 1.1108109951019287
Step: 510	 Data: torch.Size([10, 384])	 Training Loss: 1.1377017498016357
Step: 511	 Data: torch.Size([10, 384])	 Training Loss: 0.8858194351196289
Step: 512	 Data: torch.Size([10, 384])	 Training Loss: 1.4403637647628784
Step: 513	 Data: torch.Size([10, 384])	 Training Loss: 1.3401840925216675
Step: 514	 Data: torch.Size([10, 384])	 Training Loss: 1.0154709815979004
Step: 515	 Data: torch.Size([10, 302])	 Training Loss: 1.1670210361480713
Step: 516	 Data: torch.Size([10, 384])	 Training Loss: 1.2509398460388184
Step: 517	 Data: torch.Size([10, 384])	 Training Loss: 1.1082746982574463
Step: 518	 Data: torch.Size([10, 384])	 Training Loss: 1.0614370107650757
Step: 519	 Data: torch.Size([10, 384])	 Training Loss: 1.1834064722061157
Step: 520	 Data: torch.Size([10, 384])	 Training Loss: 0.9515829086303711
Step: 521	 Data: torch.Size([10, 384])	 Training Loss: 1.1466375589370728
Step: 522	 Data: torch.Size([10, 384])	 Training Loss: 1.2995500564575195
Step: 523	 Data: torch.Size([10, 384])	 Training Loss: 1.0817219018936157
Step: 524	 Data: torch.Size([10, 384])	 Training Loss: 1.1326078176498413
Step: 525	 Data: torch.Size([10, 384])	 Training Loss: 1.238794207572937
Step: 526	 Data: torch.Size([10, 384])	 Training Loss: 1.1333160400390625
Step: 527	 Data: torch.Size([10, 384])	 Training Loss: 1.0060808658599854
Step: 528	 Data: torch.Size([10, 384])	 Training Loss: 0.9952690005302429
Step: 529	 Data: torch.Size([10, 384])	 Training Loss: 1.039292335510254
Step: 530	 Data: torch.Size([10, 384])	 Training Loss: 1.175113320350647
Step: 531	 Data: torch.Size([10, 384])	 Training Loss: 1.2081754207611084
Step: 532	 Data: torch.Size([10, 384])	 Training Loss: 1.049594521522522
Step: 533	 Data: torch.Size([10, 384])	 Training Loss: 1.253489375114441
Step: 534	 Data: torch.Size([10, 384])	 Training Loss: 1.125341534614563
Step: 535	 Data: torch.Size([10, 384])	 Training Loss: 1.0659656524658203
Step: 536	 Data: torch.Size([10, 384])	 Training Loss: 1.0523418188095093
Step: 537	 Data: torch.Size([10, 384])	 Training Loss: 1.0827242136001587
Step: 538	 Data: torch.Size([10, 384])	 Training Loss: 1.1655091047286987
Step: 539	 Data: torch.Size([10, 384])	 Training Loss: 1.0125372409820557
Step: 540	 Data: torch.Size([10, 384])	 Training Loss: 1.1087665557861328
Step: 541	 Data: torch.Size([10, 384])	 Training Loss: 1.1846375465393066
Step: 542	 Data: torch.Size([10, 384])	 Training Loss: 1.0652718544006348
Step: 543	 Data: torch.Size([10, 384])	 Training Loss: 1.052384614944458
Step: 544	 Data: torch.Size([10, 384])	 Training Loss: 1.1541224718093872
Step: 545	 Data: torch.Size([10, 384])	 Training Loss: 1.0295127630233765
Step: 546	 Data: torch.Size([10, 384])	 Training Loss: 1.026423454284668
Step: 547	 Data: torch.Size([10, 384])	 Training Loss: 1.0128947496414185
Step: 548	 Data: torch.Size([10, 384])	 Training Loss: 1.1569222211837769
Step: 549	 Data: torch.Size([10, 384])	 Training Loss: 1.077802300453186
Step: 550	 Data: torch.Size([10, 384])	 Training Loss: 1.1918237209320068
Step: 551	 Data: torch.Size([10, 384])	 Training Loss: 1.0953266620635986
Step: 552	 Data: torch.Size([10, 384])	 Training Loss: 1.3312458992004395
Step: 553	 Data: torch.Size([10, 384])	 Training Loss: 1.0073012113571167
Step: 554	 Data: torch.Size([10, 384])	 Training Loss: 1.0565617084503174
Step: 555	 Data: torch.Size([10, 384])	 Training Loss: 1.0619916915893555
Step: 556	 Data: torch.Size([10, 384])	 Training Loss: 1.170501708984375
Step: 557	 Data: torch.Size([10, 384])	 Training Loss: 1.2374811172485352
Step: 558	 Data: torch.Size([10, 384])	 Training Loss: 1.0681984424591064
Step: 559	 Data: torch.Size([10, 384])	 Training Loss: 1.2103192806243896
Step: 560	 Data: torch.Size([10, 384])	 Training Loss: 1.3590474128723145
Step: 561	 Data: torch.Size([10, 384])	 Training Loss: 1.1450212001800537
Step: 562	 Data: torch.Size([10, 384])	 Training Loss: 1.2019727230072021
Step: 563	 Data: torch.Size([10, 384])	 Training Loss: 1.0374436378479004
Step: 564	 Data: torch.Size([10, 384])	 Training Loss: 1.244837760925293
Step: 565	 Data: torch.Size([10, 384])	 Training Loss: 1.0302380323410034
Step: 566	 Data: torch.Size([10, 384])	 Training Loss: 1.2826138734817505
Step: 567	 Data: torch.Size([10, 374])	 Training Loss: 0.9887213110923767
Step: 568	 Data: torch.Size([10, 384])	 Training Loss: 1.2159528732299805
Step: 569	 Data: torch.Size([10, 384])	 Training Loss: 1.212851643562317
Step: 570	 Data: torch.Size([10, 384])	 Training Loss: 0.9812331795692444
Step: 571	 Data: torch.Size([10, 384])	 Training Loss: 1.0809868574142456
Step: 572	 Data: torch.Size([10, 384])	 Training Loss: 0.9776613712310791
Step: 573	 Data: torch.Size([10, 384])	 Training Loss: 1.0068893432617188
Step: 574	 Data: torch.Size([10, 384])	 Training Loss: 0.9209282994270325
Step: 575	 Data: torch.Size([10, 384])	 Training Loss: 1.1458981037139893
Step: 576	 Data: torch.Size([10, 384])	 Training Loss: 0.9987097382545471
Step: 577	 Data: torch.Size([10, 384])	 Training Loss: 1.406724452972412
Step: 578	 Data: torch.Size([10, 384])	 Training Loss: 1.041853427886963
Step: 579	 Data: torch.Size([10, 384])	 Training Loss: 0.9073691964149475
Step: 580	 Data: torch.Size([10, 384])	 Training Loss: 1.2329336404800415
Step: 581	 Data: torch.Size([10, 384])	 Training Loss: 1.1653958559036255
Step: 582	 Data: torch.Size([10, 384])	 Training Loss: 1.0489497184753418
Step: 583	 Data: torch.Size([10, 359])	 Training Loss: 1.2685555219650269
Step: 584	 Data: torch.Size([10, 287])	 Training Loss: 1.2325241565704346
Step: 585	 Data: torch.Size([10, 384])	 Training Loss: 0.9630840420722961
Step: 586	 Data: torch.Size([10, 384])	 Training Loss: 0.931620717048645
Step: 587	 Data: torch.Size([10, 384])	 Training Loss: 1.134419322013855
Step: 588	 Data: torch.Size([10, 384])	 Training Loss: 1.0390812158584595
Step: 589	 Data: torch.Size([10, 384])	 Training Loss: 1.0797336101531982
Step: 590	 Data: torch.Size([10, 384])	 Training Loss: 1.018390417098999
Step: 591	 Data: torch.Size([10, 384])	 Training Loss: 1.100823163986206
Step: 592	 Data: torch.Size([10, 384])	 Training Loss: 0.9694764018058777
Step: 593	 Data: torch.Size([10, 384])	 Training Loss: 1.1486151218414307
Step: 594	 Data: torch.Size([10, 384])	 Training Loss: 1.0688267946243286
Step: 595	 Data: torch.Size([10, 384])	 Training Loss: 1.1997462511062622
Step: 596	 Data: torch.Size([10, 384])	 Training Loss: 1.0599576234817505
Step: 597	 Data: torch.Size([10, 384])	 Training Loss: 1.0165046453475952
Step: 598	 Data: torch.Size([10, 384])	 Training Loss: 1.0505151748657227
Step: 599	 Data: torch.Size([10, 384])	 Training Loss: 1.1030100584030151
Step: 600	 Data: torch.Size([10, 384])	 Training Loss: 1.1563808917999268
