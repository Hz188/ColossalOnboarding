[2024-05-07 07:14:14,720] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-05-07 07:14:14,720] torch.distributed.run: [WARNING] 
[2024-05-07 07:14:14,720] torch.distributed.run: [WARNING] *****************************************
[2024-05-07 07:14:14,720] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-07 07:14:14,720] torch.distributed.run: [WARNING] *****************************************
====================initialize the distributed env====================
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.42s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.75s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.86s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  8.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.24s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.95s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  8.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.73s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00,  9.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.28s/it]
====================Use tensor parallel====================
====================convert origin mlp to parallel mlp====================
====================get the model with lora====================
trainable params: 4,194,304 || all params: 4,578,349,056 || trainable%: 0.09161171305851609
====================Use auto mixed precision training====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
====================Use distributed data parallel====================
====================get the dataset====================
====================get the dataloader====================
====================start train====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Step: 1	 Data: torch.Size([10, 384])	 Training Loss: 1.0071676969528198
Step: 2	 Data: torch.Size([10, 384])	 Training Loss: 1.0456933975219727
Step: 3	 Data: torch.Size([10, 384])	 Training Loss: 1.1254514455795288
Step: 4	 Data: torch.Size([10, 384])	 Training Loss: 1.0780746936798096
Step: 5	 Data: torch.Size([10, 384])	 Training Loss: 1.0079350471496582
Step: 6	 Data: torch.Size([10, 384])	 Training Loss: 1.144666314125061
Step: 7	 Data: torch.Size([10, 384])	 Training Loss: 1.0279358625411987
Step: 8	 Data: torch.Size([10, 384])	 Training Loss: 1.2212482690811157
Step: 9	 Data: torch.Size([10, 384])	 Training Loss: 1.0828622579574585
Step: 10	 Data: torch.Size([10, 384])	 Training Loss: 1.0872328281402588
Step: 11	 Data: torch.Size([10, 384])	 Training Loss: 1.0139939785003662
Step: 12	 Data: torch.Size([10, 384])	 Training Loss: 1.0506513118743896
Step: 13	 Data: torch.Size([10, 384])	 Training Loss: 1.089441180229187
Step: 14	 Data: torch.Size([10, 384])	 Training Loss: 1.2323752641677856
Step: 15	 Data: torch.Size([10, 384])	 Training Loss: 1.037771224975586
Step: 16	 Data: torch.Size([10, 384])	 Training Loss: 1.1248531341552734
Step: 17	 Data: torch.Size([10, 384])	 Training Loss: 1.1549097299575806
Step: 18	 Data: torch.Size([10, 384])	 Training Loss: 1.0540251731872559
Step: 19	 Data: torch.Size([10, 384])	 Training Loss: 1.2138150930404663
Step: 20	 Data: torch.Size([10, 384])	 Training Loss: 1.0162326097488403
Step: 21	 Data: torch.Size([10, 384])	 Training Loss: 1.02297043800354
Step: 22	 Data: torch.Size([10, 384])	 Training Loss: 1.0416219234466553
Step: 23	 Data: torch.Size([10, 384])	 Training Loss: 1.134427547454834
Step: 24	 Data: torch.Size([10, 384])	 Training Loss: 1.1641359329223633
Step: 25	 Data: torch.Size([10, 384])	 Training Loss: 0.9763954281806946
Step: 26	 Data: torch.Size([10, 384])	 Training Loss: 0.9521308541297913
Step: 27	 Data: torch.Size([10, 384])	 Training Loss: 1.212331771850586
Step: 28	 Data: torch.Size([10, 384])	 Training Loss: 1.105424165725708
Step: 29	 Data: torch.Size([10, 384])	 Training Loss: 1.1104825735092163
Step: 30	 Data: torch.Size([10, 384])	 Training Loss: 0.9715714454650879
Step: 31	 Data: torch.Size([10, 384])	 Training Loss: 1.1116763353347778
Step: 32	 Data: torch.Size([10, 384])	 Training Loss: 1.1110347509384155
Step: 33	 Data: torch.Size([10, 384])	 Training Loss: 1.016101598739624
Step: 34	 Data: torch.Size([10, 384])	 Training Loss: 0.8906257152557373
Step: 35	 Data: torch.Size([10, 384])	 Training Loss: 1.0210415124893188
Step: 36	 Data: torch.Size([10, 384])	 Training Loss: 1.048309564590454
Step: 37	 Data: torch.Size([10, 384])	 Training Loss: 1.0961949825286865
Step: 38	 Data: torch.Size([10, 384])	 Training Loss: 0.9481995105743408
Step: 39	 Data: torch.Size([10, 384])	 Training Loss: 0.9945040941238403
Step: 40	 Data: torch.Size([10, 384])	 Training Loss: 1.0220842361450195
Step: 41	 Data: torch.Size([10, 384])	 Training Loss: 1.1545342206954956
Step: 42	 Data: torch.Size([10, 384])	 Training Loss: 0.9950820207595825
Step: 43	 Data: torch.Size([10, 384])	 Training Loss: 1.0805473327636719
Step: 44	 Data: torch.Size([10, 384])	 Training Loss: 1.2317333221435547
Step: 45	 Data: torch.Size([10, 384])	 Training Loss: 1.082122802734375
Step: 46	 Data: torch.Size([10, 384])	 Training Loss: 0.9612624645233154
Step: 47	 Data: torch.Size([10, 384])	 Training Loss: 0.9651351571083069
Step: 48	 Data: torch.Size([10, 384])	 Training Loss: 1.1899582147598267
Step: 49	 Data: torch.Size([10, 384])	 Training Loss: 1.1349793672561646
Step: 50	 Data: torch.Size([10, 384])	 Training Loss: 1.1857261657714844
Step: 51	 Data: torch.Size([10, 384])	 Training Loss: 0.9991785883903503
Step: 52	 Data: torch.Size([10, 384])	 Training Loss: 1.0049110651016235
Step: 53	 Data: torch.Size([10, 384])	 Training Loss: 1.0794074535369873
Step: 54	 Data: torch.Size([10, 384])	 Training Loss: 1.0612632036209106
Step: 55	 Data: torch.Size([10, 384])	 Training Loss: 0.9643524885177612
Step: 56	 Data: torch.Size([10, 384])	 Training Loss: 1.1032311916351318
Step: 57	 Data: torch.Size([10, 384])	 Training Loss: 0.9597874879837036
Step: 58	 Data: torch.Size([10, 384])	 Training Loss: 0.8884677886962891
Step: 59	 Data: torch.Size([10, 384])	 Training Loss: 1.1143748760223389
Step: 60	 Data: torch.Size([10, 384])	 Training Loss: 1.1060980558395386
Step: 61	 Data: torch.Size([10, 384])	 Training Loss: 0.9412434697151184
Step: 62	 Data: torch.Size([10, 384])	 Training Loss: 1.1781758069992065
Step: 63	 Data: torch.Size([10, 384])	 Training Loss: 1.0580034255981445
Step: 64	 Data: torch.Size([10, 384])	 Training Loss: 0.9932801723480225
Step: 65	 Data: torch.Size([10, 384])	 Training Loss: 0.9826858639717102
Step: 66	 Data: torch.Size([10, 384])	 Training Loss: 1.008594036102295
Step: 67	 Data: torch.Size([10, 384])	 Training Loss: 1.0121912956237793
Step: 68	 Data: torch.Size([10, 384])	 Training Loss: 1.1456396579742432
Step: 69	 Data: torch.Size([10, 384])	 Training Loss: 1.1719789505004883
Step: 70	 Data: torch.Size([10, 384])	 Training Loss: 0.9290751218795776
Step: 71	 Data: torch.Size([10, 384])	 Training Loss: 0.945567786693573
Step: 72	 Data: torch.Size([10, 350])	 Training Loss: 1.4270597696304321
Step: 73	 Data: torch.Size([10, 384])	 Training Loss: 0.9290809631347656
Step: 74	 Data: torch.Size([10, 384])	 Training Loss: 1.0663408041000366
Step: 75	 Data: torch.Size([10, 384])	 Training Loss: 0.9779018759727478
Step: 76	 Data: torch.Size([10, 384])	 Training Loss: 0.8624662160873413
Step: 77	 Data: torch.Size([10, 384])	 Training Loss: 1.1110570430755615
Step: 78	 Data: torch.Size([10, 384])	 Training Loss: 1.0221619606018066
Step: 79	 Data: torch.Size([10, 384])	 Training Loss: 1.2313848733901978
Step: 80	 Data: torch.Size([10, 384])	 Training Loss: 1.0609694719314575
Step: 81	 Data: torch.Size([10, 384])	 Training Loss: 1.032524824142456
Step: 82	 Data: torch.Size([10, 384])	 Training Loss: 1.063801646232605
Step: 83	 Data: torch.Size([10, 384])	 Training Loss: 1.039209246635437
Step: 84	 Data: torch.Size([10, 384])	 Training Loss: 0.8615733981132507
Step: 85	 Data: torch.Size([10, 384])	 Training Loss: 0.9665197134017944
Step: 86	 Data: torch.Size([10, 384])	 Training Loss: 1.1016168594360352
Step: 87	 Data: torch.Size([10, 384])	 Training Loss: 1.0235397815704346
Step: 88	 Data: torch.Size([10, 384])	 Training Loss: 0.8792417049407959
Step: 89	 Data: torch.Size([10, 384])	 Training Loss: 1.076108694076538
Step: 90	 Data: torch.Size([10, 384])	 Training Loss: 1.047570824623108
Step: 91	 Data: torch.Size([10, 384])	 Training Loss: 0.9002620577812195
Step: 92	 Data: torch.Size([10, 384])	 Training Loss: 0.8829861283302307
Step: 93	 Data: torch.Size([10, 384])	 Training Loss: 0.9976792335510254
Step: 94	 Data: torch.Size([10, 384])	 Training Loss: 1.096695065498352
Step: 95	 Data: torch.Size([10, 384])	 Training Loss: 0.9560789465904236
Step: 96	 Data: torch.Size([10, 384])	 Training Loss: 0.8942998647689819
Step: 97	 Data: torch.Size([10, 384])	 Training Loss: 1.0494720935821533
Step: 98	 Data: torch.Size([10, 384])	 Training Loss: 0.9111596345901489
Step: 99	 Data: torch.Size([10, 384])	 Training Loss: 0.9783846735954285
Step: 100	 Data: torch.Size([10, 384])	 Training Loss: 1.1385310888290405
Step: 101	 Data: torch.Size([10, 384])	 Training Loss: 0.9600647687911987
Step: 102	 Data: torch.Size([10, 384])	 Training Loss: 0.9705557227134705
Step: 103	 Data: torch.Size([10, 384])	 Training Loss: 0.9969625473022461
Step: 104	 Data: torch.Size([10, 384])	 Training Loss: 0.9383255243301392
Step: 105	 Data: torch.Size([10, 384])	 Training Loss: 0.9848040342330933
Step: 106	 Data: torch.Size([10, 384])	 Training Loss: 1.113407850265503
Step: 107	 Data: torch.Size([10, 384])	 Training Loss: 0.9334202408790588
Step: 108	 Data: torch.Size([10, 384])	 Training Loss: 0.9058370590209961
Step: 109	 Data: torch.Size([10, 384])	 Training Loss: 0.9997327923774719
Step: 110	 Data: torch.Size([10, 384])	 Training Loss: 0.9129108786582947
Step: 111	 Data: torch.Size([10, 384])	 Training Loss: 1.1972732543945312
Step: 112	 Data: torch.Size([10, 384])	 Training Loss: 1.1935265064239502
Step: 113	 Data: torch.Size([10, 384])	 Training Loss: 1.060560941696167
Step: 114	 Data: torch.Size([10, 384])	 Training Loss: 0.9725404977798462
Step: 115	 Data: torch.Size([10, 384])	 Training Loss: 0.8925968408584595
Step: 116	 Data: torch.Size([10, 384])	 Training Loss: 0.9144799113273621
Step: 117	 Data: torch.Size([10, 384])	 Training Loss: 0.8942087888717651
Step: 118	 Data: torch.Size([10, 384])	 Training Loss: 0.937657356262207
Step: 119	 Data: torch.Size([10, 384])	 Training Loss: 1.3171911239624023
Step: 120	 Data: torch.Size([10, 384])	 Training Loss: 0.8715652227401733
Step: 121	 Data: torch.Size([10, 307])	 Training Loss: 1.0778168439865112
Step: 122	 Data: torch.Size([10, 384])	 Training Loss: 1.1295500993728638
Step: 123	 Data: torch.Size([10, 384])	 Training Loss: 0.9746773838996887
Step: 124	 Data: torch.Size([10, 384])	 Training Loss: 0.865757405757904
Step: 125	 Data: torch.Size([10, 384])	 Training Loss: 0.8866021037101746
Step: 126	 Data: torch.Size([10, 384])	 Training Loss: 0.9121236205101013
Step: 127	 Data: torch.Size([10, 384])	 Training Loss: 1.038445234298706
Step: 128	 Data: torch.Size([10, 384])	 Training Loss: 0.833547055721283
Step: 129	 Data: torch.Size([10, 384])	 Training Loss: 1.0796191692352295
Step: 130	 Data: torch.Size([10, 384])	 Training Loss: 0.9663775563240051
Step: 131	 Data: torch.Size([10, 384])	 Training Loss: 0.9647441506385803
Step: 132	 Data: torch.Size([10, 384])	 Training Loss: 0.9533243179321289
Step: 133	 Data: torch.Size([10, 384])	 Training Loss: 0.9947413802146912
Step: 134	 Data: torch.Size([10, 384])	 Training Loss: 1.060953974723816
Step: 135	 Data: torch.Size([10, 384])	 Training Loss: 0.9765807390213013
Step: 136	 Data: torch.Size([10, 384])	 Training Loss: 0.9296696782112122
Step: 137	 Data: torch.Size([10, 384])	 Training Loss: 1.0552911758422852
Step: 138	 Data: torch.Size([10, 384])	 Training Loss: 0.9164184927940369
Step: 139	 Data: torch.Size([10, 384])	 Training Loss: 1.0012749433517456
Step: 140	 Data: torch.Size([10, 384])	 Training Loss: 0.9590082168579102
Step: 141	 Data: torch.Size([10, 384])	 Training Loss: 0.9847937822341919
Step: 142	 Data: torch.Size([10, 384])	 Training Loss: 0.9670097827911377
Step: 143	 Data: torch.Size([10, 384])	 Training Loss: 1.00785231590271
Step: 144	 Data: torch.Size([10, 384])	 Training Loss: 1.0083872079849243
Step: 145	 Data: torch.Size([10, 384])	 Training Loss: 0.9468865990638733
Step: 146	 Data: torch.Size([10, 384])	 Training Loss: 1.0048893690109253
Step: 147	 Data: torch.Size([10, 384])	 Training Loss: 0.9838299751281738
Step: 148	 Data: torch.Size([10, 384])	 Training Loss: 0.9351426362991333
Step: 149	 Data: torch.Size([10, 384])	 Training Loss: 0.8992157578468323
Step: 150	 Data: torch.Size([10, 384])	 Training Loss: 0.9673576951026917
Step: 151	 Data: torch.Size([10, 384])	 Training Loss: 1.054065465927124
Step: 152	 Data: torch.Size([10, 384])	 Training Loss: 0.8947058320045471
Step: 153	 Data: torch.Size([10, 384])	 Training Loss: 1.1095504760742188
Step: 154	 Data: torch.Size([10, 384])	 Training Loss: 1.0247447490692139
Step: 155	 Data: torch.Size([10, 384])	 Training Loss: 0.9321762323379517
Step: 156	 Data: torch.Size([10, 384])	 Training Loss: 0.8394724726676941
Step: 157	 Data: torch.Size([10, 384])	 Training Loss: 0.8603495955467224
Step: 158	 Data: torch.Size([10, 384])	 Training Loss: 0.9797800183296204
Step: 159	 Data: torch.Size([10, 384])	 Training Loss: 1.05575430393219
Step: 160	 Data: torch.Size([10, 384])	 Training Loss: 0.8697035908699036
Step: 161	 Data: torch.Size([10, 384])	 Training Loss: 1.0355126857757568
Step: 162	 Data: torch.Size([10, 384])	 Training Loss: 1.0009020566940308
Step: 163	 Data: torch.Size([10, 384])	 Training Loss: 0.9832876920700073
Step: 164	 Data: torch.Size([10, 384])	 Training Loss: 0.9492711424827576
Step: 165	 Data: torch.Size([10, 384])	 Training Loss: 0.9065650701522827
Step: 166	 Data: torch.Size([10, 384])	 Training Loss: 1.0816019773483276
Step: 167	 Data: torch.Size([10, 384])	 Training Loss: 0.9236304759979248
Step: 168	 Data: torch.Size([10, 384])	 Training Loss: 1.0211721658706665
Step: 169	 Data: torch.Size([10, 384])	 Training Loss: 0.964726984500885
Step: 170	 Data: torch.Size([10, 384])	 Training Loss: 1.0730856657028198
Step: 171	 Data: torch.Size([10, 384])	 Training Loss: 0.9120307564735413
Step: 172	 Data: torch.Size([10, 384])	 Training Loss: 0.8486273288726807
Step: 173	 Data: torch.Size([10, 384])	 Training Loss: 0.9160509705543518
Step: 174	 Data: torch.Size([10, 384])	 Training Loss: 0.9036428928375244
Step: 175	 Data: torch.Size([10, 384])	 Training Loss: 1.0374194383621216
Step: 176	 Data: torch.Size([10, 384])	 Training Loss: 0.9527041912078857
Step: 177	 Data: torch.Size([10, 384])	 Training Loss: 0.9935023188591003
Step: 178	 Data: torch.Size([10, 384])	 Training Loss: 0.9022671580314636
Step: 179	 Data: torch.Size([10, 384])	 Training Loss: 0.8370009064674377
Step: 180	 Data: torch.Size([10, 384])	 Training Loss: 1.0483940839767456
Step: 181	 Data: torch.Size([10, 384])	 Training Loss: 0.736988365650177
Step: 182	 Data: torch.Size([10, 384])	 Training Loss: 1.080762267112732
Step: 183	 Data: torch.Size([10, 384])	 Training Loss: 0.8665690422058105
Step: 184	 Data: torch.Size([10, 384])	 Training Loss: 0.9487879276275635
Step: 185	 Data: torch.Size([10, 384])	 Training Loss: 0.8506578803062439
Step: 186	 Data: torch.Size([10, 384])	 Training Loss: 0.9884937405586243
Step: 187	 Data: torch.Size([10, 384])	 Training Loss: 0.8686352372169495
Step: 188	 Data: torch.Size([10, 384])	 Training Loss: 0.9679767489433289
Step: 189	 Data: torch.Size([10, 384])	 Training Loss: 0.9303129315376282
Step: 190	 Data: torch.Size([10, 384])	 Training Loss: 1.0986144542694092
Step: 191	 Data: torch.Size([10, 384])	 Training Loss: 0.8915363550186157
Step: 192	 Data: torch.Size([10, 384])	 Training Loss: 1.0065553188323975
Step: 193	 Data: torch.Size([10, 384])	 Training Loss: 0.9370540380477905
Step: 194	 Data: torch.Size([10, 384])	 Training Loss: 0.8812716007232666
Step: 195	 Data: torch.Size([10, 384])	 Training Loss: 0.9393549561500549
Step: 196	 Data: torch.Size([10, 384])	 Training Loss: 0.9150791764259338
Step: 197	 Data: torch.Size([10, 384])	 Training Loss: 0.8399802446365356
Step: 198	 Data: torch.Size([10, 384])	 Training Loss: 1.017372727394104
Step: 199	 Data: torch.Size([10, 384])	 Training Loss: 1.006424903869629
Step: 200	 Data: torch.Size([10, 384])	 Training Loss: 0.9031535387039185
Step: 201	 Data: torch.Size([10, 384])	 Training Loss: 0.9712140560150146
Step: 202	 Data: torch.Size([10, 384])	 Training Loss: 0.8998826146125793
Step: 203	 Data: torch.Size([10, 384])	 Training Loss: 1.007778525352478
Step: 204	 Data: torch.Size([10, 384])	 Training Loss: 0.97609543800354
Step: 205	 Data: torch.Size([10, 384])	 Training Loss: 0.9962326288223267
Step: 206	 Data: torch.Size([10, 384])	 Training Loss: 0.900343120098114
Step: 207	 Data: torch.Size([10, 384])	 Training Loss: 0.874888002872467
Step: 208	 Data: torch.Size([10, 384])	 Training Loss: 0.9841821193695068
Step: 209	 Data: torch.Size([10, 384])	 Training Loss: 0.9534299373626709
Step: 210	 Data: torch.Size([10, 384])	 Training Loss: 0.9885437488555908
Step: 211	 Data: torch.Size([10, 384])	 Training Loss: 0.8965615630149841
Step: 212	 Data: torch.Size([10, 384])	 Training Loss: 0.8850589990615845
Step: 213	 Data: torch.Size([10, 384])	 Training Loss: 0.9305450320243835
Step: 214	 Data: torch.Size([10, 384])	 Training Loss: 1.0806615352630615
Step: 215	 Data: torch.Size([10, 384])	 Training Loss: 0.9055379629135132
Step: 216	 Data: torch.Size([10, 384])	 Training Loss: 0.9165029525756836
Step: 217	 Data: torch.Size([10, 384])	 Training Loss: 1.03760826587677
Step: 218	 Data: torch.Size([10, 384])	 Training Loss: 0.9835972189903259
Step: 219	 Data: torch.Size([10, 384])	 Training Loss: 1.0451843738555908
Step: 220	 Data: torch.Size([10, 384])	 Training Loss: 0.8742800354957581
Step: 221	 Data: torch.Size([10, 384])	 Training Loss: 1.0104602575302124
Step: 222	 Data: torch.Size([10, 384])	 Training Loss: 0.854227602481842
Step: 223	 Data: torch.Size([10, 384])	 Training Loss: 0.9323553442955017
Step: 224	 Data: torch.Size([10, 384])	 Training Loss: 0.9315385818481445
Step: 225	 Data: torch.Size([10, 384])	 Training Loss: 0.8146677613258362
Step: 226	 Data: torch.Size([10, 384])	 Training Loss: 0.858485221862793
Step: 227	 Data: torch.Size([10, 384])	 Training Loss: 0.9836238026618958
Step: 228	 Data: torch.Size([10, 384])	 Training Loss: 0.9075836539268494
Step: 229	 Data: torch.Size([10, 384])	 Training Loss: 0.8962556719779968
Step: 230	 Data: torch.Size([10, 384])	 Training Loss: 0.8237568736076355
Step: 231	 Data: torch.Size([10, 384])	 Training Loss: 0.9453745484352112
Step: 232	 Data: torch.Size([10, 384])	 Training Loss: 0.9860047698020935
Step: 233	 Data: torch.Size([10, 384])	 Training Loss: 0.9728007912635803
Step: 234	 Data: torch.Size([10, 384])	 Training Loss: 0.822117269039154
Step: 235	 Data: torch.Size([10, 384])	 Training Loss: 0.8219287395477295
Step: 236	 Data: torch.Size([10, 384])	 Training Loss: 0.94627445936203
Step: 237	 Data: torch.Size([10, 384])	 Training Loss: 1.0232586860656738
Step: 238	 Data: torch.Size([10, 384])	 Training Loss: 1.0366888046264648
Step: 239	 Data: torch.Size([10, 384])	 Training Loss: 0.9331629276275635
Step: 240	 Data: torch.Size([10, 384])	 Training Loss: 0.9469185471534729
Step: 241	 Data: torch.Size([10, 384])	 Training Loss: 1.0218744277954102
Step: 242	 Data: torch.Size([10, 384])	 Training Loss: 0.9066107869148254
Step: 243	 Data: torch.Size([10, 384])	 Training Loss: 1.061234951019287
Step: 244	 Data: torch.Size([10, 384])	 Training Loss: 1.002837896347046
Step: 245	 Data: torch.Size([10, 384])	 Training Loss: 0.957594096660614
Step: 246	 Data: torch.Size([10, 384])	 Training Loss: 1.0233808755874634
Step: 247	 Data: torch.Size([10, 384])	 Training Loss: 0.8974894881248474
Step: 248	 Data: torch.Size([10, 384])	 Training Loss: 0.8289993405342102
Step: 249	 Data: torch.Size([10, 384])	 Training Loss: 0.8982373476028442
Step: 250	 Data: torch.Size([10, 384])	 Training Loss: 1.0343353748321533
Step: 251	 Data: torch.Size([10, 384])	 Training Loss: 1.000345230102539
Step: 252	 Data: torch.Size([10, 384])	 Training Loss: 0.994922935962677
Step: 253	 Data: torch.Size([10, 384])	 Training Loss: 0.971875011920929
Step: 254	 Data: torch.Size([10, 384])	 Training Loss: 0.930874764919281
Step: 255	 Data: torch.Size([10, 384])	 Training Loss: 0.855675458908081
Step: 256	 Data: torch.Size([10, 384])	 Training Loss: 0.9465815424919128
Step: 257	 Data: torch.Size([10, 384])	 Training Loss: 0.8982227444648743
Step: 258	 Data: torch.Size([10, 384])	 Training Loss: 0.8982863426208496
Step: 259	 Data: torch.Size([10, 384])	 Training Loss: 0.8406550288200378
Step: 260	 Data: torch.Size([10, 384])	 Training Loss: 0.8969045281410217
Step: 261	 Data: torch.Size([10, 384])	 Training Loss: 1.0288947820663452
Step: 262	 Data: torch.Size([10, 384])	 Training Loss: 0.9752891659736633
Step: 263	 Data: torch.Size([10, 384])	 Training Loss: 1.0489590167999268
Step: 264	 Data: torch.Size([10, 384])	 Training Loss: 1.0515109300613403
Step: 265	 Data: torch.Size([10, 384])	 Training Loss: 0.9413926005363464
Step: 266	 Data: torch.Size([10, 384])	 Training Loss: 0.8848750591278076
Step: 267	 Data: torch.Size([10, 384])	 Training Loss: 0.8793174028396606
Step: 268	 Data: torch.Size([10, 384])	 Training Loss: 0.901475191116333
Step: 269	 Data: torch.Size([10, 384])	 Training Loss: 0.8838851451873779
Step: 270	 Data: torch.Size([10, 384])	 Training Loss: 0.9892835021018982
Step: 271	 Data: torch.Size([10, 384])	 Training Loss: 0.9541043043136597
Step: 272	 Data: torch.Size([10, 384])	 Training Loss: 0.9073061347007751
Step: 273	 Data: torch.Size([10, 384])	 Training Loss: 0.8209351897239685
Step: 274	 Data: torch.Size([10, 384])	 Training Loss: 0.9704825282096863
Step: 275	 Data: torch.Size([10, 384])	 Training Loss: 1.0089305639266968
Step: 276	 Data: torch.Size([10, 384])	 Training Loss: 0.9414670467376709
Step: 277	 Data: torch.Size([10, 384])	 Training Loss: 0.9098834991455078
Step: 278	 Data: torch.Size([10, 384])	 Training Loss: 1.0226002931594849
Step: 279	 Data: torch.Size([10, 384])	 Training Loss: 0.9746801853179932
Step: 280	 Data: torch.Size([10, 384])	 Training Loss: 0.9654757976531982
Step: 281	 Data: torch.Size([10, 384])	 Training Loss: 0.993855357170105
Step: 282	 Data: torch.Size([10, 384])	 Training Loss: 0.9301689863204956
Step: 283	 Data: torch.Size([10, 384])	 Training Loss: 1.0495668649673462
Step: 284	 Data: torch.Size([10, 384])	 Training Loss: 1.2736213207244873
Step: 285	 Data: torch.Size([10, 384])	 Training Loss: 0.927001416683197
Step: 286	 Data: torch.Size([10, 384])	 Training Loss: 1.058861255645752
Step: 287	 Data: torch.Size([10, 384])	 Training Loss: 0.908921480178833
Step: 288	 Data: torch.Size([10, 384])	 Training Loss: 0.7758253216743469
Step: 289	 Data: torch.Size([10, 384])	 Training Loss: 0.9320217967033386
Step: 290	 Data: torch.Size([10, 384])	 Training Loss: 0.9157063961029053
Step: 291	 Data: torch.Size([10, 384])	 Training Loss: 0.9472126960754395
Step: 292	 Data: torch.Size([10, 384])	 Training Loss: 1.028740406036377
Step: 293	 Data: torch.Size([10, 384])	 Training Loss: 0.8553928136825562
Step: 294	 Data: torch.Size([10, 384])	 Training Loss: 0.8536518216133118
Step: 295	 Data: torch.Size([10, 384])	 Training Loss: 0.9858455657958984
Step: 296	 Data: torch.Size([10, 384])	 Training Loss: 1.0071913003921509
Step: 297	 Data: torch.Size([10, 384])	 Training Loss: 0.9413570761680603
Step: 298	 Data: torch.Size([10, 384])	 Training Loss: 0.9404617547988892
Step: 299	 Data: torch.Size([10, 384])	 Training Loss: 1.0084383487701416
Step: 300	 Data: torch.Size([10, 384])	 Training Loss: 1.0470380783081055
