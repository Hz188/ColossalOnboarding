[2024-05-08 02:08:38,980] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
[2024-05-08 02:08:38,980] torch.distributed.run: [WARNING] 
[2024-05-08 02:08:38,980] torch.distributed.run: [WARNING] *****************************************
[2024-05-08 02:08:38,980] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-05-08 02:08:38,980] torch.distributed.run: [WARNING] *****************************************
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-200]:42625 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-200]:42625 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-200]:42625 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [H100-200]:42625 (errno: 22 - Invalid argument).
====================initialize the distributed env====================
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:16<00:16, 16.02s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:16<00:16, 16.36s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:16<00:16, 16.39s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:16<00:16, 16.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 10.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 10.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.32s/it]
====================Use tensor parallel====================
====================convert origin mlp to parallel mlp====================
====================get the model with lora====================
Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 10.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.35s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 10.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.34s/it]
trainable params: 4,194,304 || all params: 4,578,349,056 || trainable%: 0.09161171305851609
====================Use distributed data parallel====================
====================get the dataset====================
====================get the dataloader====================
====================start train====================
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Step: 1	 Data: torch.Size([10, 384])	 Training Loss: 1.0071995258331299
Step: 2	 Data: torch.Size([10, 384])	 Training Loss: 1.0454994440078735
Step: 3	 Data: torch.Size([10, 384])	 Training Loss: 1.1251885890960693
Step: 4	 Data: torch.Size([10, 384])	 Training Loss: 1.0779013633728027
Step: 5	 Data: torch.Size([10, 384])	 Training Loss: 1.0075266361236572
Step: 6	 Data: torch.Size([10, 384])	 Training Loss: 1.1444844007492065
Step: 7	 Data: torch.Size([10, 384])	 Training Loss: 1.0274653434753418
Step: 8	 Data: torch.Size([10, 384])	 Training Loss: 1.2209542989730835
Step: 9	 Data: torch.Size([10, 384])	 Training Loss: 1.082501769065857
Step: 10	 Data: torch.Size([10, 384])	 Training Loss: 1.086734652519226
Step: 11	 Data: torch.Size([10, 384])	 Training Loss: 1.0137908458709717
Step: 12	 Data: torch.Size([10, 384])	 Training Loss: 1.0503711700439453
Step: 13	 Data: torch.Size([10, 384])	 Training Loss: 1.0889493227005005
Step: 14	 Data: torch.Size([10, 384])	 Training Loss: 1.2321486473083496
Step: 15	 Data: torch.Size([10, 384])	 Training Loss: 1.0376815795898438
Step: 16	 Data: torch.Size([10, 384])	 Training Loss: 1.1248540878295898
Step: 17	 Data: torch.Size([10, 384])	 Training Loss: 1.154625415802002
Step: 18	 Data: torch.Size([10, 384])	 Training Loss: 1.0534908771514893
Step: 19	 Data: torch.Size([10, 384])	 Training Loss: 1.212921380996704
Step: 20	 Data: torch.Size([10, 384])	 Training Loss: 1.0160245895385742
Step: 21	 Data: torch.Size([10, 384])	 Training Loss: 1.022684097290039
Step: 22	 Data: torch.Size([10, 384])	 Training Loss: 1.0417296886444092
Step: 23	 Data: torch.Size([10, 384])	 Training Loss: 1.1337651014328003
Step: 24	 Data: torch.Size([10, 384])	 Training Loss: 1.164349913597107
Step: 25	 Data: torch.Size([10, 384])	 Training Loss: 0.9764332175254822
Step: 26	 Data: torch.Size([10, 384])	 Training Loss: 0.9522954821586609
Step: 27	 Data: torch.Size([10, 384])	 Training Loss: 1.2121104001998901
Step: 28	 Data: torch.Size([10, 384])	 Training Loss: 1.1051441431045532
Step: 29	 Data: torch.Size([10, 384])	 Training Loss: 1.1106798648834229
Step: 30	 Data: torch.Size([10, 384])	 Training Loss: 0.9712355136871338
Step: 31	 Data: torch.Size([10, 384])	 Training Loss: 1.1123178005218506
Step: 32	 Data: torch.Size([10, 384])	 Training Loss: 1.1110678911209106
Step: 33	 Data: torch.Size([10, 384])	 Training Loss: 1.016272783279419
Step: 34	 Data: torch.Size([10, 384])	 Training Loss: 0.8910983800888062
Step: 35	 Data: torch.Size([10, 384])	 Training Loss: 1.0211257934570312
Step: 36	 Data: torch.Size([10, 384])	 Training Loss: 1.048714518547058
Step: 37	 Data: torch.Size([10, 384])	 Training Loss: 1.0971449613571167
Step: 38	 Data: torch.Size([10, 384])	 Training Loss: 0.9491850137710571
Step: 39	 Data: torch.Size([10, 384])	 Training Loss: 0.9959468841552734
Step: 40	 Data: torch.Size([10, 384])	 Training Loss: 1.0219886302947998
Step: 41	 Data: torch.Size([10, 384])	 Training Loss: 1.1547703742980957
Step: 42	 Data: torch.Size([10, 384])	 Training Loss: 0.9958669543266296
Step: 43	 Data: torch.Size([10, 384])	 Training Loss: 1.081329584121704
Step: 44	 Data: torch.Size([10, 384])	 Training Loss: 1.2310880422592163
Step: 45	 Data: torch.Size([10, 384])	 Training Loss: 1.0824393033981323
Step: 46	 Data: torch.Size([10, 384])	 Training Loss: 0.9617785215377808
Step: 47	 Data: torch.Size([10, 384])	 Training Loss: 0.9656181931495667
Step: 48	 Data: torch.Size([10, 384])	 Training Loss: 1.1917979717254639
Step: 49	 Data: torch.Size([10, 384])	 Training Loss: 1.1348952054977417
Step: 50	 Data: torch.Size([10, 384])	 Training Loss: 1.1873290538787842
Step: 51	 Data: torch.Size([10, 384])	 Training Loss: 1.000248908996582
Step: 52	 Data: torch.Size([10, 384])	 Training Loss: 1.005767822265625
Step: 53	 Data: torch.Size([10, 384])	 Training Loss: 1.081243634223938
Step: 54	 Data: torch.Size([10, 384])	 Training Loss: 1.0618129968643188
Step: 55	 Data: torch.Size([10, 384])	 Training Loss: 0.9657588601112366
Step: 56	 Data: torch.Size([10, 384])	 Training Loss: 1.1052016019821167
Step: 57	 Data: torch.Size([10, 384])	 Training Loss: 0.9607481360435486
Step: 58	 Data: torch.Size([10, 384])	 Training Loss: 0.8886874914169312
Step: 59	 Data: torch.Size([10, 384])	 Training Loss: 1.1164131164550781
Step: 60	 Data: torch.Size([10, 384])	 Training Loss: 1.107102394104004
Step: 61	 Data: torch.Size([10, 384])	 Training Loss: 0.941963255405426
Step: 62	 Data: torch.Size([10, 384])	 Training Loss: 1.1787118911743164
Step: 63	 Data: torch.Size([10, 384])	 Training Loss: 1.0594791173934937
Step: 64	 Data: torch.Size([10, 384])	 Training Loss: 0.9937009811401367
Step: 65	 Data: torch.Size([10, 384])	 Training Loss: 0.9829436540603638
Step: 66	 Data: torch.Size([10, 384])	 Training Loss: 1.009698510169983
Step: 67	 Data: torch.Size([10, 384])	 Training Loss: 1.014054536819458
Step: 68	 Data: torch.Size([10, 384])	 Training Loss: 1.147204041481018
Step: 69	 Data: torch.Size([10, 384])	 Training Loss: 1.1724717617034912
Step: 70	 Data: torch.Size([10, 384])	 Training Loss: 0.9297283291816711
Step: 71	 Data: torch.Size([10, 384])	 Training Loss: 0.9460841417312622
Step: 72	 Data: torch.Size([10, 350])	 Training Loss: 1.4287389516830444
Step: 73	 Data: torch.Size([10, 384])	 Training Loss: 0.9304078221321106
Step: 74	 Data: torch.Size([10, 384])	 Training Loss: 1.0661451816558838
Step: 75	 Data: torch.Size([10, 384])	 Training Loss: 0.9787231683731079
Step: 76	 Data: torch.Size([10, 384])	 Training Loss: 0.8633727431297302
Step: 77	 Data: torch.Size([10, 384])	 Training Loss: 1.1118755340576172
Step: 78	 Data: torch.Size([10, 384])	 Training Loss: 1.0246104001998901
Step: 79	 Data: torch.Size([10, 384])	 Training Loss: 1.2326843738555908
Step: 80	 Data: torch.Size([10, 384])	 Training Loss: 1.0607024431228638
Step: 81	 Data: torch.Size([10, 384])	 Training Loss: 1.033677339553833
Step: 82	 Data: torch.Size([10, 384])	 Training Loss: 1.0628504753112793
Step: 83	 Data: torch.Size([10, 384])	 Training Loss: 1.0392178297042847
Step: 84	 Data: torch.Size([10, 384])	 Training Loss: 0.8616170287132263
Step: 85	 Data: torch.Size([10, 384])	 Training Loss: 0.9650067090988159
Step: 86	 Data: torch.Size([10, 384])	 Training Loss: 1.102640986442566
Step: 87	 Data: torch.Size([10, 384])	 Training Loss: 1.0224473476409912
Step: 88	 Data: torch.Size([10, 384])	 Training Loss: 0.8800415396690369
Step: 89	 Data: torch.Size([10, 384])	 Training Loss: 1.0756837129592896
Step: 90	 Data: torch.Size([10, 384])	 Training Loss: 1.0472599267959595
Step: 91	 Data: torch.Size([10, 384])	 Training Loss: 0.900070071220398
Step: 92	 Data: torch.Size([10, 384])	 Training Loss: 0.884066104888916
Step: 93	 Data: torch.Size([10, 384])	 Training Loss: 0.9974496364593506
Step: 94	 Data: torch.Size([10, 384])	 Training Loss: 1.0971403121948242
Step: 95	 Data: torch.Size([10, 384])	 Training Loss: 0.9559791088104248
Step: 96	 Data: torch.Size([10, 384])	 Training Loss: 0.8921837210655212
Step: 97	 Data: torch.Size([10, 384])	 Training Loss: 1.0496907234191895
Step: 98	 Data: torch.Size([10, 384])	 Training Loss: 0.9113745093345642
Step: 99	 Data: torch.Size([10, 384])	 Training Loss: 0.9797722101211548
Step: 100	 Data: torch.Size([10, 384])	 Training Loss: 1.1399447917938232
Step: 101	 Data: torch.Size([10, 384])	 Training Loss: 0.9600669741630554
Step: 102	 Data: torch.Size([10, 384])	 Training Loss: 0.9700726270675659
Step: 103	 Data: torch.Size([10, 384])	 Training Loss: 0.9956439137458801
Step: 104	 Data: torch.Size([10, 384])	 Training Loss: 0.9366012215614319
Step: 105	 Data: torch.Size([10, 384])	 Training Loss: 0.982272744178772
Step: 106	 Data: torch.Size([10, 384])	 Training Loss: 1.1106078624725342
Step: 107	 Data: torch.Size([10, 384])	 Training Loss: 0.9314436316490173
Step: 108	 Data: torch.Size([10, 384])	 Training Loss: 0.9050103425979614
Step: 109	 Data: torch.Size([10, 384])	 Training Loss: 0.9980441927909851
Step: 110	 Data: torch.Size([10, 384])	 Training Loss: 0.9125060439109802
Step: 111	 Data: torch.Size([10, 384])	 Training Loss: 1.1975617408752441
Step: 112	 Data: torch.Size([10, 384])	 Training Loss: 1.191873550415039
Step: 113	 Data: torch.Size([10, 384])	 Training Loss: 1.059484601020813
Step: 114	 Data: torch.Size([10, 384])	 Training Loss: 0.9711048007011414
Step: 115	 Data: torch.Size([10, 384])	 Training Loss: 0.8900494575500488
Step: 116	 Data: torch.Size([10, 384])	 Training Loss: 0.9147237539291382
Step: 117	 Data: torch.Size([10, 384])	 Training Loss: 0.892989993095398
Step: 118	 Data: torch.Size([10, 384])	 Training Loss: 0.9342676401138306
Step: 119	 Data: torch.Size([10, 384])	 Training Loss: 1.3160842657089233
Step: 120	 Data: torch.Size([10, 384])	 Training Loss: 0.8697027564048767
Step: 121	 Data: torch.Size([10, 307])	 Training Loss: 1.0755864381790161
Step: 122	 Data: torch.Size([10, 384])	 Training Loss: 1.128719449043274
Step: 123	 Data: torch.Size([10, 384])	 Training Loss: 0.9716743230819702
Step: 124	 Data: torch.Size([10, 384])	 Training Loss: 0.8624788522720337
Step: 125	 Data: torch.Size([10, 384])	 Training Loss: 0.882666289806366
Step: 126	 Data: torch.Size([10, 384])	 Training Loss: 0.9097520709037781
Step: 127	 Data: torch.Size([10, 384])	 Training Loss: 1.0379502773284912
Step: 128	 Data: torch.Size([10, 384])	 Training Loss: 0.8332636952400208
Step: 129	 Data: torch.Size([10, 384])	 Training Loss: 1.0781590938568115
Step: 130	 Data: torch.Size([10, 384])	 Training Loss: 0.9664844274520874
Step: 131	 Data: torch.Size([10, 384])	 Training Loss: 0.9636818766593933
Step: 132	 Data: torch.Size([10, 384])	 Training Loss: 0.9533828496932983
Step: 133	 Data: torch.Size([10, 384])	 Training Loss: 0.9919056296348572
Step: 134	 Data: torch.Size([10, 384])	 Training Loss: 1.0589895248413086
Step: 135	 Data: torch.Size([10, 384])	 Training Loss: 0.9766036868095398
Step: 136	 Data: torch.Size([10, 384])	 Training Loss: 0.9303348064422607
Step: 137	 Data: torch.Size([10, 384])	 Training Loss: 1.0539575815200806
Step: 138	 Data: torch.Size([10, 384])	 Training Loss: 0.9148450493812561
Step: 139	 Data: torch.Size([10, 384])	 Training Loss: 1.0014089345932007
Step: 140	 Data: torch.Size([10, 384])	 Training Loss: 0.9567227363586426
Step: 141	 Data: torch.Size([10, 384])	 Training Loss: 0.9839998483657837
Step: 142	 Data: torch.Size([10, 384])	 Training Loss: 0.9682813882827759
Step: 143	 Data: torch.Size([10, 384])	 Training Loss: 1.0084375143051147
Step: 144	 Data: torch.Size([10, 384])	 Training Loss: 1.0092346668243408
Step: 145	 Data: torch.Size([10, 384])	 Training Loss: 0.9450279474258423
Step: 146	 Data: torch.Size([10, 384])	 Training Loss: 1.0046911239624023
Step: 147	 Data: torch.Size([10, 384])	 Training Loss: 0.9835300445556641
Step: 148	 Data: torch.Size([10, 384])	 Training Loss: 0.9330884218215942
Step: 149	 Data: torch.Size([10, 384])	 Training Loss: 0.8995556831359863
Step: 150	 Data: torch.Size([10, 384])	 Training Loss: 0.9679006338119507
Step: 151	 Data: torch.Size([10, 384])	 Training Loss: 1.0536164045333862
Step: 152	 Data: torch.Size([10, 384])	 Training Loss: 0.8951336741447449
Step: 153	 Data: torch.Size([10, 384])	 Training Loss: 1.10932195186615
Step: 154	 Data: torch.Size([10, 384])	 Training Loss: 1.0239397287368774
Step: 155	 Data: torch.Size([10, 384])	 Training Loss: 0.9310664534568787
Step: 156	 Data: torch.Size([10, 384])	 Training Loss: 0.8392770886421204
Step: 157	 Data: torch.Size([10, 384])	 Training Loss: 0.8588317632675171
Step: 158	 Data: torch.Size([10, 384])	 Training Loss: 0.9790041446685791
Step: 159	 Data: torch.Size([10, 384])	 Training Loss: 1.0544065237045288
Step: 160	 Data: torch.Size([10, 384])	 Training Loss: 0.8683789372444153
Step: 161	 Data: torch.Size([10, 384])	 Training Loss: 1.0347226858139038
Step: 162	 Data: torch.Size([10, 384])	 Training Loss: 1.0013482570648193
Step: 163	 Data: torch.Size([10, 384])	 Training Loss: 0.982386589050293
Step: 164	 Data: torch.Size([10, 384])	 Training Loss: 0.9495809078216553
Step: 165	 Data: torch.Size([10, 384])	 Training Loss: 0.9052842259407043
Step: 166	 Data: torch.Size([10, 384])	 Training Loss: 1.080507516860962
Step: 167	 Data: torch.Size([10, 384])	 Training Loss: 0.9231778383255005
Step: 168	 Data: torch.Size([10, 384])	 Training Loss: 1.0223008394241333
Step: 169	 Data: torch.Size([10, 384])	 Training Loss: 0.9639231562614441
Step: 170	 Data: torch.Size([10, 384])	 Training Loss: 1.0726662874221802
Step: 171	 Data: torch.Size([10, 384])	 Training Loss: 0.9120826721191406
Step: 172	 Data: torch.Size([10, 384])	 Training Loss: 0.8488167524337769
Step: 173	 Data: torch.Size([10, 384])	 Training Loss: 0.9154794812202454
Step: 174	 Data: torch.Size([10, 384])	 Training Loss: 0.9019696116447449
Step: 175	 Data: torch.Size([10, 384])	 Training Loss: 1.0372583866119385
Step: 176	 Data: torch.Size([10, 384])	 Training Loss: 0.9501156210899353
Step: 177	 Data: torch.Size([10, 384])	 Training Loss: 0.9915817975997925
Step: 178	 Data: torch.Size([10, 384])	 Training Loss: 0.9012832641601562
Step: 179	 Data: torch.Size([10, 384])	 Training Loss: 0.8367964029312134
Step: 180	 Data: torch.Size([10, 384])	 Training Loss: 1.0487079620361328
Step: 181	 Data: torch.Size([10, 384])	 Training Loss: 0.7360000014305115
Step: 182	 Data: torch.Size([10, 384])	 Training Loss: 1.08113694190979
Step: 183	 Data: torch.Size([10, 384])	 Training Loss: 0.8634130954742432
Step: 184	 Data: torch.Size([10, 384])	 Training Loss: 0.9478658437728882
Step: 185	 Data: torch.Size([10, 384])	 Training Loss: 0.8492393493652344
Step: 186	 Data: torch.Size([10, 384])	 Training Loss: 0.9865932464599609
Step: 187	 Data: torch.Size([10, 384])	 Training Loss: 0.8679920434951782
Step: 188	 Data: torch.Size([10, 384])	 Training Loss: 0.969833254814148
Step: 189	 Data: torch.Size([10, 384])	 Training Loss: 0.9290617108345032
Step: 190	 Data: torch.Size([10, 384])	 Training Loss: 1.0990053415298462
Step: 191	 Data: torch.Size([10, 384])	 Training Loss: 0.8915601968765259
Step: 192	 Data: torch.Size([10, 384])	 Training Loss: 1.0067558288574219
Step: 193	 Data: torch.Size([10, 384])	 Training Loss: 0.9370178580284119
Step: 194	 Data: torch.Size([10, 384])	 Training Loss: 0.8803895115852356
Step: 195	 Data: torch.Size([10, 384])	 Training Loss: 0.9398335814476013
Step: 196	 Data: torch.Size([10, 384])	 Training Loss: 0.9145545959472656
Step: 197	 Data: torch.Size([10, 384])	 Training Loss: 0.8392332196235657
Step: 198	 Data: torch.Size([10, 384])	 Training Loss: 1.01479172706604
Step: 199	 Data: torch.Size([10, 384])	 Training Loss: 1.0067776441574097
Step: 200	 Data: torch.Size([10, 384])	 Training Loss: 0.9040677547454834
Step: 201	 Data: torch.Size([10, 384])	 Training Loss: 0.971471905708313
Step: 202	 Data: torch.Size([10, 384])	 Training Loss: 0.8994835615158081
Step: 203	 Data: torch.Size([10, 384])	 Training Loss: 1.006981611251831
Step: 204	 Data: torch.Size([10, 384])	 Training Loss: 0.9772189855575562
Step: 205	 Data: torch.Size([10, 384])	 Training Loss: 0.9940996766090393
Step: 206	 Data: torch.Size([10, 384])	 Training Loss: 0.9004645943641663
Step: 207	 Data: torch.Size([10, 384])	 Training Loss: 0.8751352429389954
Step: 208	 Data: torch.Size([10, 384])	 Training Loss: 0.9843519926071167
Step: 209	 Data: torch.Size([10, 384])	 Training Loss: 0.9522078037261963
Step: 210	 Data: torch.Size([10, 384])	 Training Loss: 0.9887381792068481
Step: 211	 Data: torch.Size([10, 384])	 Training Loss: 0.8955901265144348
Step: 212	 Data: torch.Size([10, 384])	 Training Loss: 0.8840779662132263
Step: 213	 Data: torch.Size([10, 384])	 Training Loss: 0.928386926651001
Step: 214	 Data: torch.Size([10, 384])	 Training Loss: 1.08008873462677
Step: 215	 Data: torch.Size([10, 384])	 Training Loss: 0.9053184986114502
Step: 216	 Data: torch.Size([10, 384])	 Training Loss: 0.9153534770011902
Step: 217	 Data: torch.Size([10, 384])	 Training Loss: 1.0378444194793701
Step: 218	 Data: torch.Size([10, 384])	 Training Loss: 0.9834855198860168
Step: 219	 Data: torch.Size([10, 384])	 Training Loss: 1.0453970432281494
Step: 220	 Data: torch.Size([10, 384])	 Training Loss: 0.8759446740150452
Step: 221	 Data: torch.Size([10, 384])	 Training Loss: 1.0094759464263916
Step: 222	 Data: torch.Size([10, 384])	 Training Loss: 0.8534969091415405
Step: 223	 Data: torch.Size([10, 384])	 Training Loss: 0.9293972849845886
Step: 224	 Data: torch.Size([10, 384])	 Training Loss: 0.932080864906311
Step: 225	 Data: torch.Size([10, 384])	 Training Loss: 0.8142518401145935
Step: 226	 Data: torch.Size([10, 384])	 Training Loss: 0.8581354022026062
Step: 227	 Data: torch.Size([10, 384])	 Training Loss: 0.9824608564376831
Step: 228	 Data: torch.Size([10, 384])	 Training Loss: 0.907906711101532
Step: 229	 Data: torch.Size([10, 384])	 Training Loss: 0.8977799415588379
Step: 230	 Data: torch.Size([10, 384])	 Training Loss: 0.823936939239502
Step: 231	 Data: torch.Size([10, 384])	 Training Loss: 0.9446251392364502
Step: 232	 Data: torch.Size([10, 384])	 Training Loss: 0.9857156872749329
Step: 233	 Data: torch.Size([10, 384])	 Training Loss: 0.971335232257843
Step: 234	 Data: torch.Size([10, 384])	 Training Loss: 0.8219943046569824
Step: 235	 Data: torch.Size([10, 384])	 Training Loss: 0.8208908438682556
Step: 236	 Data: torch.Size([10, 384])	 Training Loss: 0.9458144903182983
Step: 237	 Data: torch.Size([10, 384])	 Training Loss: 1.0227973461151123
Step: 238	 Data: torch.Size([10, 384])	 Training Loss: 1.0367358922958374
Step: 239	 Data: torch.Size([10, 384])	 Training Loss: 0.9328484535217285
Step: 240	 Data: torch.Size([10, 384])	 Training Loss: 0.9460415840148926
Step: 241	 Data: torch.Size([10, 384])	 Training Loss: 1.0196590423583984
Step: 242	 Data: torch.Size([10, 384])	 Training Loss: 0.9068804383277893
Step: 243	 Data: torch.Size([10, 384])	 Training Loss: 1.061734676361084
Step: 244	 Data: torch.Size([10, 384])	 Training Loss: 1.0030064582824707
Step: 245	 Data: torch.Size([10, 384])	 Training Loss: 0.9567421674728394
Step: 246	 Data: torch.Size([10, 384])	 Training Loss: 1.0229260921478271
Step: 247	 Data: torch.Size([10, 384])	 Training Loss: 0.8974533081054688
Step: 248	 Data: torch.Size([10, 384])	 Training Loss: 0.8278882503509521
Step: 249	 Data: torch.Size([10, 384])	 Training Loss: 0.8988763689994812
Step: 250	 Data: torch.Size([10, 384])	 Training Loss: 1.0341320037841797
Step: 251	 Data: torch.Size([10, 384])	 Training Loss: 0.9989540576934814
Step: 252	 Data: torch.Size([10, 384])	 Training Loss: 0.9952637553215027
Step: 253	 Data: torch.Size([10, 384])	 Training Loss: 0.9725095629692078
Step: 254	 Data: torch.Size([10, 384])	 Training Loss: 0.9304457902908325
Step: 255	 Data: torch.Size([10, 384])	 Training Loss: 0.8548387289047241
Step: 256	 Data: torch.Size([10, 384])	 Training Loss: 0.9451634287834167
Step: 257	 Data: torch.Size([10, 384])	 Training Loss: 0.8983664512634277
Step: 258	 Data: torch.Size([10, 384])	 Training Loss: 0.8979380130767822
Step: 259	 Data: torch.Size([10, 384])	 Training Loss: 0.8401047587394714
Step: 260	 Data: torch.Size([10, 384])	 Training Loss: 0.8962457180023193
Step: 261	 Data: torch.Size([10, 384])	 Training Loss: 1.0292868614196777
Step: 262	 Data: torch.Size([10, 384])	 Training Loss: 0.9744319915771484
Step: 263	 Data: torch.Size([10, 384])	 Training Loss: 1.0484172105789185
Step: 264	 Data: torch.Size([10, 384])	 Training Loss: 1.0518230199813843
Step: 265	 Data: torch.Size([10, 384])	 Training Loss: 0.9412699341773987
Step: 266	 Data: torch.Size([10, 384])	 Training Loss: 0.8840701580047607
Step: 267	 Data: torch.Size([10, 384])	 Training Loss: 0.8794872760772705
Step: 268	 Data: torch.Size([10, 384])	 Training Loss: 0.9006356596946716
Step: 269	 Data: torch.Size([10, 384])	 Training Loss: 0.8835926055908203
Step: 270	 Data: torch.Size([10, 384])	 Training Loss: 0.9884479641914368
Step: 271	 Data: torch.Size([10, 384])	 Training Loss: 0.953656017780304
Step: 272	 Data: torch.Size([10, 384])	 Training Loss: 0.9072322845458984
Step: 273	 Data: torch.Size([10, 384])	 Training Loss: 0.8200469017028809
Step: 274	 Data: torch.Size([10, 384])	 Training Loss: 0.9712733030319214
Step: 275	 Data: torch.Size([10, 384])	 Training Loss: 1.0090893507003784
Step: 276	 Data: torch.Size([10, 384])	 Training Loss: 0.9413095116615295
Step: 277	 Data: torch.Size([10, 384])	 Training Loss: 0.9107022881507874
Step: 278	 Data: torch.Size([10, 384])	 Training Loss: 1.022605061531067
Step: 279	 Data: torch.Size([10, 384])	 Training Loss: 0.9734477400779724
Step: 280	 Data: torch.Size([10, 384])	 Training Loss: 0.9651773571968079
Step: 281	 Data: torch.Size([10, 384])	 Training Loss: 0.993827223777771
Step: 282	 Data: torch.Size([10, 384])	 Training Loss: 0.9307858347892761
Step: 283	 Data: torch.Size([10, 384])	 Training Loss: 1.0510798692703247
Step: 284	 Data: torch.Size([10, 384])	 Training Loss: 1.2734577655792236
Step: 285	 Data: torch.Size([10, 384])	 Training Loss: 0.9252442717552185
Step: 286	 Data: torch.Size([10, 384])	 Training Loss: 1.0579386949539185
Step: 287	 Data: torch.Size([10, 384])	 Training Loss: 0.9082175493240356
Step: 288	 Data: torch.Size([10, 384])	 Training Loss: 0.7761051654815674
Step: 289	 Data: torch.Size([10, 384])	 Training Loss: 0.9307255744934082
Step: 290	 Data: torch.Size([10, 384])	 Training Loss: 0.9167077541351318
Step: 291	 Data: torch.Size([10, 384])	 Training Loss: 0.9481291770935059
Step: 292	 Data: torch.Size([10, 384])	 Training Loss: 1.0283451080322266
Step: 293	 Data: torch.Size([10, 384])	 Training Loss: 0.8548790216445923
Step: 294	 Data: torch.Size([10, 384])	 Training Loss: 0.8526448011398315
Step: 295	 Data: torch.Size([10, 384])	 Training Loss: 0.9844611883163452
Step: 296	 Data: torch.Size([10, 384])	 Training Loss: 1.0070700645446777
Step: 297	 Data: torch.Size([10, 384])	 Training Loss: 0.9408518075942993
Step: 298	 Data: torch.Size([10, 384])	 Training Loss: 0.9397661089897156
Step: 299	 Data: torch.Size([10, 384])	 Training Loss: 1.0079305171966553
Step: 300	 Data: torch.Size([10, 384])	 Training Loss: 1.0451406240463257
